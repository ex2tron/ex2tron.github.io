{"meta":{"title":"噢，程序猿","subtitle":"生命不息，折腾不止，Excelsior!","description":"Codec42，生命不息，折腾不止～","author":"小强本强","url":"http://www.codec.wang"},"pages":[{"title":"About","date":"2017-12-20T07:06:25.000Z","updated":"2019-12-26T10:30:30.276Z","comments":true,"path":"about/index.html","permalink":"http://www.codec.wang/about/index.html","excerpt":"","text":"我 Codec42，生命不息，折腾不止～ 工科男一枚，但也非常喜欢艺术，不冲突 不喜欢没有意义的事和废话BB，直接“干”！！！ 职业 主业：@腾讯、程序猿（图像处理、全栈） 副业：啥都喜欢（电影、摄影、设计、艺术、科技、羽毛球、乒乓、鸡血……） Github"},{"title":"categories","date":"2017-12-20T07:06:09.000Z","updated":"2017-12-20T08:17:21.571Z","comments":true,"path":"categories/index.html","permalink":"http://www.codec.wang/categories/index.html","excerpt":"","text":""},{"title":"tags","date":"2017-12-20T07:06:09.000Z","updated":"2017-12-20T08:17:40.499Z","comments":true,"path":"tags/index.html","permalink":"http://www.codec.wang/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"【MightyPy】(l/r)strip函数的巨坑","slug":"【MightyPy】-l-r-strip函数的巨坑","date":"2019-06-30T14:26:41.000Z","updated":"2019-06-30T16:35:06.910Z","comments":true,"path":"mighty-py-strip/","link":"","permalink":"http://www.codec.wang/mighty-py-strip/","excerpt":"先来猜下Python中这句话的输出是啥","text":"先来猜下Python中这句话的输出是啥： 12&gt;&gt;&gt; filename = \"journey_p4.mp4\"&gt;&gt;&gt; filename.rstrip(\".mp4\") 答案是：journey_，那p4去哪了呢？怎么样，有兴趣看下去了吗？↓ I Am Iron Man. ——《钢铁侠》我就是钢铁侠。——《Iron Man》 友情广告：电影台词分享网站：MovieQuotes strip()函数Python中常用strip()从字符串的开头和结尾移除指定的字符，不指定参数的话，默认移除的是空格、制表符、换行符等。同样lstrip()和rstrip()分别表示单独从开头、结尾移除指定的字符。 函数原型：str.strip([chars])、str.lstrip([chars])、str.rstrip([chars]) 但很多人并不真正了解函数用法，胡乱使用就会导致开头的那种问题，包括之前的我( ╯□╰ )。 填坑其实官方文档上写的很清楚并举了几个例子： 1The chars argument is not a prefix or suffix; rather, all combinations of its values are stripped. 翻译过来就是： strip函数的参数并不是指前缀或后缀，而是所有其组合值都会被删除掉！ 啥意思呢？以开头问题为例，虽然我们指定了从尾部删除.mp4这个字符串，但它并不会老老实实只删除.mp4，而是包含.mp4所以组合值的字符串都会被删除，比如末尾包含了m/pm/mp/4p/p4/pm4等等都会被删除： 123&gt;&gt;&gt; filename = \"journey_p4mmp.mp4\"&gt;&gt;&gt; filename.rstrip(\".mp4\") journey_ 再来看些官方的例子： 12&gt;&gt;&gt; 'www.example.com'.strip('cmowz.')example 123&gt;&gt;&gt; comment_string = '#....... Section 3.2.1 Issue #32 .......'&gt;&gt;&gt; comment_string.strip('.#! ')Section 3.2.1 Issue #32 strip()函数会从开头和结尾开始检索，直到找到不满足要求的第一个字符为止。所以上面的例子从结尾检索时，遇到2不满足要求就结束了。 综上，strip()/lstrip()/rstrip()要慎用噢。 去扩展名p.s.开头那种去扩展名其实有很多实现方式： 123&gt;&gt;&gt; filename = \"journey_p4.mp4\"&gt;&gt;&gt; filename.split(\".\")[0]journey_p4 或者用os模块： 123&gt;&gt;&gt; import os&gt;&gt;&gt; os.path.splitext(filename)('journey_p4', '.mp4') 引用 str.strip([chars]) str.lstrip([chars]) str.rstrip([chars])","categories":[{"name":"Build篇","slug":"Build篇","permalink":"http://www.codec.wang/categories/Build%E7%AF%87/"}],"tags":[{"name":"Python","slug":"Python","permalink":"http://www.codec.wang/tags/Python/"},{"name":"strip","slug":"strip","permalink":"http://www.codec.wang/tags/strip/"},{"name":"lstrip","slug":"lstrip","permalink":"http://www.codec.wang/tags/lstrip/"},{"name":"rstrip","slug":"rstrip","permalink":"http://www.codec.wang/tags/rstrip/"}]},{"title":"【MightyPy】处理命令行参数和选项的几种方式","slug":"【MightyPy】处理命令行参数和选项的几种方式","date":"2019-05-03T02:30:18.000Z","updated":"2019-06-30T15:58:44.596Z","comments":true,"path":"mighty-py-command-line-arguments/","link":"","permalink":"http://www.codec.wang/mighty-py-command-line-arguments/","excerpt":"设计Python模块功能时，命令行参数是一个非常灵活且便捷的方法：从外部获取配置参量，而不是直接修改代码。Python内置几种命令行参数和选项的处理方式，当然也有更加强大的第三方的模块，如：click。","text":"设计Python模块功能时，命令行参数是一个非常灵活且便捷的方法：从外部获取配置参量，而不是直接修改代码。Python内置几种命令行参数和选项的处理方式，当然也有更加强大的第三方的模块，如：click。 一般来说内置就够用了，所以本节主要看下内置的三种方式。 Louis, I think this is the beginning of a beautiful friendship. ——《Casablanca》路易，我想这是美好友谊的开始。——《卡萨布兰卡》 友情广告：电影台词分享网站：MovieQuotes sys.argv这是最常用的一种方式，命令行传入的参数全部存储在sys.argv(argument values)这个列表中： 123import sysprint(type(sys.argv)) # list 需要注意的是，Python后面跟的第一个文本是第一个参数，所以一般脚本名是第一个参数。如下面脚本名为using_sys_argv.py： 12345print(\"参数个数：\\t%s\"%len(sys.argv))print('脚本名：\\t%s'%sys.argv[0])print('参数列表：')for i in range(1,len(sys.argv)): print('\\t\\t参数%s: %s'%(i,sys.argv[i])) 运行python using_sys_argv.py 123参数个数： 1脚本名： using_sys_argv.py参数列表： 运行python using_sys_argv.py tencent wang 12345参数个数： 3脚本名： using_sys_argv.py参数列表： 参数1: tencent 参数2: wang 这种方式虽然很简单，但不能很好地识别命令行选项，需要自己写额外代码，如： 运行python using_sys_argv.py -c tencent --name wang 1234567参数个数： 5脚本名： using_sys_argv.py参数列表： 参数1: -c 参数2: tencent 参数3: --name 参数4: wang 如上，sys.argv统一识别成了参数量。 argparseargparse是Python内置的模块，它会从sys.argv中正确解析出命令行选项和参数，并自动生成帮助和使用信息。 基本使用argparse使用基本是三个步骤： 创建ArgumentParser()解析器对象 使用add_argument()添加参数 使用parse_args()解析参数 12345678910import argparse# 1.定义解析器parser = argparse.ArgumentParser()# 2.添加参数parser.add_argument('integer',type=int,help='base number x')# 3.解析参数args = parser.parse_args()print(args.integer) 上面就是argparse的一个简单示例，运行下看看效果： 直接运行python using_argparse.py，会报错： 12usage: using_argparse.py [-h] integerusing_argparse.py: error: the following arguments are required: integer 提示通过-h获取帮助，并且integer这个参数是必须的。 运行python using_argparse.py -h，显示帮助文档： 1234567usage: using_argparse.py [-h] integerpositional arguments: integer base number xoptional arguments: -h, --help show this help message and exit 运行python using_argparse.py 100 1100 可选参数平常使用最多的应该是添加短选项-或长选项--的可选参数，比如要计算一个数的n次方： 123456789101112131415import argparse# 1.定义解析器parser = argparse.ArgumentParser()# 2.添加位置参数parser.add_argument('integer',type=int,help='base number x')# 添加可选参数parser.add_argument('--powern',type=int,help='n power of a number')# 3.解析参数args = parser.parse_args()if args.powern: # 判断可选参数 print(args.integer**args.powern)else: print(args.integer) 此时不加--powern的运行结果跟之前一样，添加后，会计算x^n： 运行python using_argparse.py 100 --powern 2 110000 更多用法虽说主要通过三个方法实现，但方法的参数很多，我们挑几个常用的说下，更多请参考接口文档。 ArgumentParser() 其中最常用的是description项，在脚本帮助文档中起说明作用，如前面代码更改为： 1parser = argparse.ArgumentParser(description='Basic Operations of an Integer.') 此时运行python using_argparse.py -h： 123456usage: using_argparse.py [-h] [--powern POWERN] integerBasic Operations of an Integer.positional arguments:…… add_argument() 其中参量类型type和帮助信息help不用多讲，其他几个常用的说明一下： name of flags，想让脚本同一个可选参数既支持短选项-又支持长选项--，可以： 1234parser.add_argument('--foo','-f')args = parser.parse_args()print(args.foo) # 注意不是args.f噢！ 这样的话，运行时python script.py -f param或python script.py --foo param都可以。 2.nargs，要读取的命令行参数个数 nargs=n，表示要读取n个参数，如 1parser.add_argument('--foo','-f',nargs=2) 运行时需要在-f后加两个参数：python script.py -f p1 p2 nargs=&#39;*&#39;/&#39;+&#39;，将所有参数合在一个列表中（*号和+号的区别：+号需至少1个参数）： 1parser.add_argument('--foo','-f',nargs='+') 运行python script.py -f p1 p2 p3结果为：foo=[&#39;p1&#39;, &#39;p2&#39;, &#39;p3&#39;] nargs=&#39;?&#39;，参数没提供时，使用默认值（可选参数是const，位置参数是default）： 12parser.add_argument('--foo','-f',nargs='?',const='param')parser.add_argument('integer',nargs='?',default='0') 运行python script.py -f，结果为：foo=&#39;param&#39;,integer=&#39;0&#39; 3.required，默认情况下，argparse会把-和--的参数作为可选的，如果需要指定成必须的话，可以将required设置为True： 1parser.add_argument('--foo','-f',required=True) 运行python script.py会提示：error: the following arguments are required: --foo/-f 4.choices，限定参数值的范围，如： 1parser.add_argument('--foo','-f',choices=['p1','p2','p3']) 运行python scipt.py -f param会提示：error: argument --foo/-f: invalid choice: &#39;param&#39; (choose from &#39;p1&#39;, &#39;p2&#39;, &#39;p3&#39;) parse_args() 这个方法没啥好讲的，主要是第一个参数args，默认是从sys.argv取值，调试时也可以把命令行参数加上去，这样就不用在命令行中设置了： 1234parser.add_argument('--foo','-f',choices=['p1','p2','p3'])parser.add_argument('integer',nargs='?',default='0')# 直接在代码中传入命令行参数args = parser.parse_args(['100','-f','p1']) 此时，在编辑器中直接运行或在命令行中不加参数运行：python scipt.py都能得到正确结果：integer=&#39;100&#39;,foo=&#39;p1&#39; getoptPython还有一个getopt模块，它的设计与C语言中的getopt类似。Python官方建议是你如果不熟悉C中的getopt或者想写更少的代码的话，更推荐用argparse，所以不再详述，感兴趣可参考接口文档： Note: The getopt module is a parser for command line options whose API is designed to be familiar to users of the C getopt() function. Users who are unfamiliar with the C getopt() function or who would like to write less code and get better help and error messages should consider using the argparse module instead. 接口文档 Python sys Python argparse Python getopt","categories":[{"name":"Build篇","slug":"Build篇","permalink":"http://www.codec.wang/categories/Build%E7%AF%87/"}],"tags":[{"name":"Python","slug":"Python","permalink":"http://www.codec.wang/tags/Python/"},{"name":"argv","slug":"argv","permalink":"http://www.codec.wang/tags/argv/"},{"name":"命令行参数","slug":"命令行参数","permalink":"http://www.codec.wang/tags/%E5%91%BD%E4%BB%A4%E8%A1%8C%E5%8F%82%E6%95%B0/"}]},{"title":"【MightyPy】Base64","slug":"【MightyPy】理解Base64","date":"2019-04-28T14:20:53.000Z","updated":"2019-06-30T15:58:50.058Z","comments":true,"path":"mighty-py-base64/","link":"","permalink":"http://www.codec.wang/mighty-py-base64/","excerpt":"我们知道日常的图片、视频、pdf、exe等等这些文件都是二进制文件，如果用文本编辑器打开它们，基本都是乱码，那么有没有一种简单的二进制转成字符串的方式呢？","text":"我们知道日常的图片、视频、pdf、exe等等这些文件都是二进制文件，如果用文本编辑器打开它们，基本都是乱码，那么有没有一种简单的二进制转成字符串的方式呢？ Valar Morghulis, Valar Dohaeris. ——《Game of Thrones》凡人皆有一死，凡人皆须侍奉。——《权力的游戏》 友情广告：电影台词分享网站：MovieQuotes Base64Base64是一种用64个可打印字符来表示二进制数据的一种方法。 原理其实很简单，首先定义一个长度为64的字符数组： 1base = ['A', 'B', ..., 'Z', 'a', 'b', ..., 'z', '0', '1', ..., '9', '+', '/'] 标准的Base64编码是由26个大写字母、26个小写字母、[0-9]10个数字、’+’、’/‘共64个字符组成的。你也可以自定义这些字符来实现自己的Base64编码。 将原二进制数据每3个字节为一组进行划分，一共3×8=24bit，划分成4组，也就是每组6bit，6bit可表示的长度为2^6=64，这就是Base64名称的由来。然后将每组6bit对应的值作为索引，在前面定义的数组中查表，就得到了编码后对应的4个字符。 比如，把”Man”进行Base64编码： Python中可以直接用内置的base64模块： 12345import base64print(base64.b64encode(b'Man')) # 'TWFu'# 或：base64.b64encode(b'\\x4D\\x61\\x6E')print(base64.b64decode('TWFu')) # 'man' 不是3的倍数Base64是每3个字节编码的，遇到不足3个字节的情况时，会在末尾补0，再在末尾加个1个或2个 ‘=’号表示补了多少个字节，解码时再将’=’去掉。 比如参考前面的’Man’，对’M’单独进行编码：第一组还是原有的6bit，结果是字符’T’；第二组只剩下’01’，补充4个0，即’010000’，索引值为16，对应的字符是’Q’；第三和第四组都是0了，所以再加两个’=’，最终结果是’TQ==’。 1print(base64.b64encode(b'M')) # 'TQ==' 总之，Base64编码后的长度永远是4的倍数！ URL中特殊字符的处理标准Base64编码中会出现’+’和’/‘字符，如果在url中使用，url编码器会转换成’%2B’和’%2F’，解码或数据库存储时需要将%再次转换。为避免出错并简化操作，提出了一种可用于url的改进Base64编码：将’+’和’/‘分别改成’-‘和’_’。 12print(base64.b64encode(b'\\xFB\\xfe')) # '+/4='print(base64.urlsafe_b64encode(b'\\xFB\\xfe')) # '-_4=' 图片Base64编码图片的Base64编码用的较多。Python打开文件时，指定’rb’参数，可以获取原始的二进制数据： 123456import base64with open('lena.jpg', 'rb') as pic: pic_str_data = base64.b64encode(pic.read())print(pic_str_data) 中文Base64编码Base64只跟二进制有关系，跟字符集无关。对于中文的话，按照你使用的字符集（比如utf-8）编码成二进制后再用Base64就可以了： 12345ch_bytes = '中'.encode('utf-8') # b'\\xe4\\xb8\\xad'# encode()默认是utf-8，可省略print(ch_bytes.decode()) # '中'print(base64.b64encode(ch_bytes)) 优缺点作为一种二进制到字符串的编码方式，Base64可以编码任意的二进制数据，便于文本显示和接口处理；但因为是将3个字节编码成4个字节，二进制数据长度相当于增加了1/3=33%左右。 手动实现Base64当然我们也可以实现自己的Base64编码，不过一般没有必要。比如下面是我自己实现的标准Base64编码，效率慢了8倍左右，仅供学习参考，网上也有其他方式。 123456789101112131415161718192021222324252627282930313233343536373839import string# 定义64字符base_charset = string.ascii_uppercase+string.ascii_lowercase+string.digits+\"+/\"def my_b64_encode(ori_bytes): ret, ori_len = \"\", len(ori_bytes) for i in range(0, ori_len, 3): # 第一组 first = (ori_bytes[i] &amp; 0xFC) &gt;&gt; 2 ret += base_charset[first] # 第二组 if i+1 &gt;= ori_len: second = (ori_bytes[i] &amp; 0x03)*16 ret += base_charset[second] + \"==\" break second = (ori_bytes[i] &amp; 0x03)*16 + ((ori_bytes[i+1] &amp; 0xF0) &gt;&gt; 4) ret += base_charset[second] # 第三组 if i+2 &gt;= ori_len: third = (ori_bytes[i+1] &amp; 0x0F)*4 ret += base_charset[third] + \"=\" break third = (ori_bytes[i+1] &amp; 0x0F)*4 + ((ori_bytes[i+2] &amp; 0xC0) &gt;&gt; 6) ret += base_charset[third] # 第四组 fourth = ori_bytes[i+2] &amp; 0x3F ret += base_charset[fourth] return retprint(my_b64_encode(b'ManM')) # TWFuTQ== 接口文档 Python base64 Python string 引用 本节源码 维基百科 Base64 廖雪峰Python教程","categories":[{"name":"Build篇","slug":"Build篇","permalink":"http://www.codec.wang/categories/Build%E7%AF%87/"}],"tags":[{"name":"Python","slug":"Python","permalink":"http://www.codec.wang/tags/Python/"},{"name":"Base64","slug":"Base64","permalink":"http://www.codec.wang/tags/Base64/"}]},{"title":"【树莓派】变身全能无线路由器(2/2B)","slug":"【树莓派】变身全能无线路由器(22B)","date":"2019-04-03T03:16:34.000Z","updated":"2019-04-04T08:57:04.880Z","comments":true,"path":"raspberrypi-as-router/","link":"","permalink":"http://www.codec.wang/raspberrypi-as-router/","excerpt":"树莓派能做的事情实在是太多了，今天我们就来把它改造成一台全能的无线路由器。要知道树莓派的Soc性能可比廉价路由器高出不少。","text":"树莓派能做的事情实在是太多了，今天我们就来把它改造成一台全能的无线路由器。要知道树莓派的Soc性能可比廉价路由器高出不少。 人在顺境时候的友谊，可能不是那么坚固的。 ——《飞驰人生》 友情广告：电影台词分享网站：MovieQuotes 硬件/软件版本说明我一开始是用3B+的，但官方的固件烧写后不断重启，有问题，网上很多人也遇到。虽然通过烧写开发版固件解决了，但本文还是先以官方固件为主，后续再写篇3B+的。 树莓派 2B OS：OpenWrt 18.06.2 TF卡：闪迪SanDisk 16GB C10 USB无线网卡：EDUP EP-N8508GS WAN、LAN、WLAN区别在开干之前，有几个小概念还是要了解一下： LAN：Local Area Network局域网 WAN：Wide Area Network广域网 WLAN：Wireless Local Area Networks无线局域网 简单来说，LAN就是用来组建有线局域网，而WLAN是用来组建无线局域网的。要使局域网内的设备访问外网，就需要WAN口接入网络运营商或者上层网络。感兴趣的可参考引用。 安装配置OpenWrtOpenWrt官网提供了树莓派系列的相关资料和最新固件下载： https://openwrt.org/toh/raspberry_pi_foundation/raspberry_pi 型号 SoC CPU MHz WLAN Hardware Raspberry Pi 2B Broadcom BCM2836 900 无 首先明确下我们要做的事情：将树莓派的有线网口作为新路由器的WAN口，由于2/2B不带无线网卡，所以将USB无线网卡作为WLAN产生WIFI。 下载固件安装固件和升级固件任意下载一个即可： 安装固件：openwrt-18.06.2-brcm2708-bcm2709-rpi-2-ext4-factory.img.gz 升级固件：openwrt-18.06.2-brcm2708-bcm2709-rpi-2-ext4-sysupgrade.img.gz 固件烧写Windows系统的话，可以使用Win32DiskImager或Etcher，操作都很简单，选择固件和TF卡，点击烧写就可以了。后者的颜值更高一些，我喜欢(●ˇ∀ˇ●) 进入系统现在跟玩传统树莓派一样，接上电源、显示屏和键盘后，正常开机，都是终端界面，不需要鼠标。 启动后，根据提示，按下回车，就可以进入终端界面： 12345678910111213141516Please press Enter to activate this console. _______ ________ __ | |.-----.-----.-----.| | | |.----.| |_ | - || _ | -__| || | | || _|| _| |_______|| __|_____|__|__||________||__| |____| |__| W I R E L E S S F R E E D O M ----------------------------------------------------- OpenWrt 18.06.2, r7676-cddd7b4c77 -----------------------------------------------------=== WARNING! ===================================== There is no root password defined on this device! Use the \"passwd\" command to set up a new password in order to prevent unauthorized SSH logins. -------------------------------------------------- root@OpenWrt:~# 进入路由器后台进入后台有多种方式，我归纳为两种：网线直连的方式和终端操作的方式。推荐终端操作，虽然看上去复杂了点，但其实更快捷。 方法1：网线直连将网线的一端插入树莓派，另一端插入电脑，断开电脑的其他有线或无线连接。待网络成功识别后，浏览器中访问192.168.1.1便可进入后台。 默认没有密码直接登录，进入之后，需要让树莓派连接到已有的网络中：点击 ‘Network’ - ‘Interface’ - ‘Add new interface’，这里我让树莓派接入家里路由器LAN口分出的有线网络，所以协议选择 ‘DHCP client’，点击 ‘Submit’提交。 如果你打算将树莓派接入网络运营商设备，可能需要输入宽带账号密码，协议选择’PPPoE’。 点击’Submit’提交之后再点击’Save &amp; Apply’，会弹出30s的配置应用时间。 此时拔掉树莓派与电脑的直连网线，插入有线网。编辑/etc/config/network网络配置文件，将lan配置的ifname一行注释掉： 1vim /etc/config/network 1234567config interface 'lan' option type 'bridge'# option ifname 'eth0' option proto 'static' option ipaddr '192.168.1.1' option netmask '255.255.255.0' option ip6assign '60' 用ifconfig查看树莓派的IP地址，如192.168.1.112，在局域网内的其他设备上访问此IP就可以进入树莓派的路由器后台。 方法2：终端操作其实方法1本身就是更改/etc/config/network文件，所以可以直接在终端编辑，添加一个广域网wan口配置，并将lan的ifname一行注释掉： 1vim /etc/config/network 1234567891011config interface 'lan' option type 'bridge'# option ifname 'eth0' option proto 'static' option ipaddr '192.168.1.1' option netmask '255.255.255.0' option ip6assign '60'config interface 'wan' option proto 'dhcp' option ifname 'eth0' 如果树莓派接的是家里路由器LAN口出来的网线，一般配置成DHCP协议就可以了。如果是直接从网络运营商设备出来的网线，则可能需要输入宽带账号密码： 12345config interface 'wan' option proto 'pppoe' option ifname 'eth0' option username 'xxxxxx' option password 'xxxxxx' 添加完之后，使用/etc/init.d/network restart重启网络服务，使用ifconfig查看ip地址：如192.168.1.112，然后在局域网内的其他设备上输入此IP便可以访问OpenWrt 的后台了。 如果访问有问题，可以关闭防火墙试下：/etc/init.d/firewall stop 不论使用哪种方法，进入之后，默认都是没有密码的。为安全起见，这里先设置个密码，点击 ‘Go to password configuration…’，输入密码后，直接点击 ‘Save &amp; Apply’，其他不用管。 更换源树莓派成功联网后，需要下载一些插件。一方面官方的源亲测是不包含USB网卡驱动和中文插件的，不知道什么原因，另一方面国内的源速度会快很多，所以这里统一换成中科大的源。 中国科学技术大学开源镜像站 LEDE：使用帮助 可以在终端操作，也可以在Web后台操作： Web后台操作进入路由器后台，依次点击 ‘System’ - ‘Software’ - ‘Configuration’，在 ‘Distribution feeds’下面我们更换成国内的源，注意版本噢（最好先将原有的备份下）： 123456src/gz openwrt_core http://mirrors.ustc.edu.cn/lede/releases/18.06.2/targets/brcm2708/bcm2709/packagessrc/gz openwrt_base http://mirrors.ustc.edu.cn/lede/releases/18.06.2/packages/arm_cortex-a7_neon-vfpv4/basesrc/gz openwrt_luci http://mirrors.ustc.edu.cn/lede/releases/18.06.2/packages/arm_cortex-a7_neon-vfpv4/lucisrc/gz openwrt_packages http://mirrors.ustc.edu.cn/lede/releases/18.06.2/packages/arm_cortex-a7_neon-vfpv4/packagessrc/gz openwrt_routing http://mirrors.ustc.edu.cn/lede/releases/18.06.2/packages/arm_cortex-a7_neon-vfpv4/routingsrc/gz openwrt_telephony http://mirrors.ustc.edu.cn/lede/releases/18.06.2/packages/arm_cortex-a7_neon-vfpv4/telephony 然后切换到 ‘Actions’标签下，点击 ‘Update lists’便可以获取所有可用的ipk包： 终端操作首先将原有的源配置文件备份： 1cp /etc/opkg/distfeeds.conf /etc/opkg/distfeeds.conf.bak 然后用sed命令替换掉源地址： 1sed -i 's|downloads.openwrt.org|mirrors.ustc.edu.cn/lede|g' /etc/opkg/distfeeds.conf 最后记得执行更新： 1opkg update 安装必要的软件包在路由器后台的 ‘System’ - ‘Software’下面的 ‘Filter’中搜索要安装的软件包，或者在终端输入： 1opkg install pkg_name 都可以安装，主要装3个包： 路由器后台中文插件：luci-i18n-base-zh-cn USB无线网卡驱动：kmod-rtl8192cu 无线配置工具：wireless-tools 配置无线安装中文包后，后台自动变成了中文。此时菜单栏’网络’中会多出个’无线’，点击进入： 默认情况下，无线并没有启用，只需点击启用就可以了： 不过还有点小问题，首先这个WiFi没密码，其次也没网。点击’编辑’，将网络来源选择为WAN： 其次在’无线安全’这里给WiFi设置个密码，最后保存就可以了： 现在手机或电脑可以连接上试试辣： 万能路由器之所以称之为’万能路由器’，是因为OpenWrt不仅完全开源，可玩性很高，而且第三方插件非常丰富，比如可以科学上网的shadowsocks，安装配置之后，全天24h出国旅游不成问题呀（有空写篇( $ _ $ )）。 引用 LAN、WAN、WLAN的区别 OpenWrt Raspberry Pi 树莓派安装 OpenWrt 打造超级路由器 VLOG丨树莓派(raspberrypi Pi1-Pi3)安装OPENWRT LEDE秒变xxx 生命不息，折腾不止，Excelsior!","categories":[{"name":"Build篇","slug":"Build篇","permalink":"http://www.codec.wang/categories/Build%E7%AF%87/"}],"tags":[{"name":"树莓派","slug":"树莓派","permalink":"http://www.codec.wang/tags/%E6%A0%91%E8%8E%93%E6%B4%BE/"},{"name":"OpenWrt","slug":"OpenWrt","permalink":"http://www.codec.wang/tags/OpenWrt/"}]},{"title":"【树莓派】用PLEX打造家庭影音中心！","slug":"【树莓派】用PLEX打造家庭影音中心！","date":"2019-03-27T14:43:35.000Z","updated":"2019-03-28T04:04:31.463Z","comments":true,"path":"raspberrypi-how-to-install-plex-server/","link":"","permalink":"http://www.codec.wang/raspberrypi-how-to-install-plex-server/","excerpt":"电脑下载了部电影，晚上想在手机上看，老婆也想看（啥？！），拷贝？想在手机上看以前的电影或者硬盘里存的视频/照片，拷贝？使用云盘存储呢？速度、容量、播放码率、重复占用本地容量都是问题。如果有一块存放资源的硬盘，家人都可以高速访问它，何乐而不为呢？我说的不是NAS噢~","text":"电脑下载了部电影，晚上想在手机上看，老婆也想看（啥？！），拷贝？想在手机上看以前的电影或者硬盘里存的视频/照片，拷贝？使用云盘存储呢？速度、容量、播放码率、重复占用本地容量都是问题。如果有一块存放资源的硬盘，家人都可以高速访问它，何乐而不为呢？我说的不是NAS噢~ May the force be with you. ——《Star Wars》愿原力与你同在！——《星球大战》 友情广告：电影台词分享网站：MovieQuotes 版本说明 树莓派 3B+ OS：Raspbian 9.4 (Stretch) TF卡：三星SAMSUNG 32GB EVO+ PMS：1.15.2.793 armhf 移动硬盘：1TB 什么是PlexPlex主打流媒体传输服务，简单来说，有一台放满资料的设备，通过安装 PMS(Plex Media Server)，就可以打通Windows/Linux/Mac电脑、电视TV、Android/IOS手机、PS/XBOX游戏主机等等设备。Plex是在服务端解码，然后实现串流，所以在树莓派上安装Plex服务的话，受性能限制，720P以下的感觉还行，流畅播放，再高就有点吃不消了。 相比Kodi，Plex的界面美观简单、交互优秀、服务完整，配置起来对新手也友好。p.s想了解更多Plex的东西可以看下引用，这篇我主要分享下树莓派上的安装和挂载U盘等技术问题。 安装PMS官网已经有了基于armhf/ARMv7并支持树莓派的安装包了，非常方便！ 之所以强调上面这句话，是因为网上大部分资料都是基于dev2day.de的版本，装起来略微麻烦一点，就连这个包的作者都表示： Plex now provides official packages. So, this project is considered EOL by me. 官方的版本装起来就很容易了，安装之前，大家需要到Plex官网先注册个账号。 第一步：更新树莓派到最新。可以更换成国内源，速度会快很多。 1234567# 更换清华大学源sudo sed -i 's|raspbian.raspberrypi.org|mirrors.tuna.tsinghua.edu.cn/raspbian|g' /etc/apt/sources.list# 更新系统sudo apt updatesudo apt upgrade# 最好重启一下reboot 更新后，最好重启一下，有时候也会提示重启。 第二步：下载官方包并安装。 1wget https://downloads.plex.tv/plex-media-server-new/1.15.2.793-782228f99/debian/plexmediaserver_1.15.2.793-782228f99_armhf.deb 下载慢的话，可以到官网下载离线版：https://www.plex.tv/media-server-downloads/，注意选择ARMv7版本（armhf与ARMv7、ARMv8等区别可参考引用）。 deb的包安装大家应该很熟悉了，一句话： 1sudo dpkg -i plexmediaserver_1.15.2.793-782228f99_armhf.deb 最后看下服务有没有启动： 1systemctl status plexmediaserver 如果出现running的提示 ，就说明服务运行正常： 123● plexmediaserver.service - Plex Media Server Loaded: loaded (/lib/systemd/system/plexmediaserver.service; enabled; vendor preset: enabled) Active: active (running) since Wed 2019-03-27 17:30:23 CST; 2h 51min ago 此时可以在菜单里面启动，或者直接在浏览器中输入：http://localhost:32400/web/ 首次启动需要你登录Plex账号： 设置服务器的名称： 在添加资料库这里，默认是不支持树莓派上挂载的U盘和移动硬盘（what？我的pian都在硬盘里啊），别担心，我们后续解决。现在先不添加，直接下一步： 点击完成就进入Plex的控制面板了，局域网内的任何设备在浏览器中访问https://app.plex.tv也可以。 外挂U盘或移动硬盘 现在总不能把电影、资料啥的都存在树莓派的TF卡里吧。解决方法也很简单：使用分区的唯一标识码（Universally Unique Identifier/UUID）在fstab文件中自动挂载分区。 首先在树莓派上插入移动硬盘，打印出其状态信息，比如我的设备地址是/dev/sda1： 12sudo cat /proc/mounts# /dev/sda1 /media/pi/ex2tronMovie fuseblk rw,nosuid,nodev,relatime,user_id=0,group_id=0,default_permissions,allow_other,blksize=4096 0 0 安装NTFS-3G驱动程序： 1sudo apt install ntfs-3g 使用id指令打印出User ID(UID)和Group ID(GID)： 12id -g pi # 1000id -u pi # 1000 再打印出硬盘分区的UUID，比如我的是：B6A28862A2882947 12ls -l /dev/disk/by-uuid# lrwxrwxrwx 1 root root 10 3月 27 16:13 B6A28862A2882947 -&gt; ../../sda1 现在创建一个挂载硬盘的目录： 1sudo mkdir /media/usb1 Linux系统开机时会读取/etc/fstab文件中的内容，然后根据配置挂载磁盘。所以编辑这个文件，在末尾新增一条配置： 1UUID=B6A28862A2882947 /media/usb1 auto nofail,uid=1000,gid=1000,noatime 0 0 其中三个id根据前面打印出来的实际情况填写。 接下来先卸载、再重新挂载硬盘，最后重启树莓派生效： 123sudo umount /dev/sda1sudo mount -asudo reboot 添加资源库重启后，打开Plex网页面板，在左侧点击”添加资源库”，选择usb1，哇啦，出来咯： 我里面放了几部电影，添加后，Plex会自动解码并检索影片的相关信息，比如影片封面/资料等： 一个字：爽~！ 最后，我测试了下在局域网内其他设备上的播放速度表现，如预期，720P 2G以下的流畅播放，表现不错。其他的嘛，”要什么自行车！！！” 关于Plex设置远程访问和更多配置玩法，大家自行探索啊，不是本文的重点，有时间我也会分享下我的经验。p.s.看看我这个”电影达人”的片(●ˇ∀ˇ●)： 引用 About Server ARMv7 and ARMv8 Ubuntu / Debian Plex Media Server on Debian armhf How to Install Plex on a Raspberry Pi – Raspberry Pi Plex Server HOWTO - Using Raspberry Pi 3+ as Plex Media Server 官方：更好的命名你的资源文件 树莓派实验室：浅析 fstab 与移动硬盘挂载方法 VLOG丨树莓派Raspberry Pi 3安装PLEX…] 如何设置Plex（并在任何设备上观看您的电影） 树莓派PI3的充分利用 篇三：搞定树莓派端的Plex服务端… 生命不息，折腾不止，Excelsior!","categories":[{"name":"Build篇","slug":"Build篇","permalink":"http://www.codec.wang/categories/Build%E7%AF%87/"}],"tags":[{"name":"树莓派","slug":"树莓派","permalink":"http://www.codec.wang/tags/%E6%A0%91%E8%8E%93%E6%B4%BE/"},{"name":"Plex","slug":"Plex","permalink":"http://www.codec.wang/tags/Plex/"}]},{"title":"串口传输中对float数据的处理","slug":"串口传输中对float数据的处理","date":"2019-03-25T08:16:35.000Z","updated":"2019-03-25T13:46:51.593Z","comments":true,"path":"float-data-in-serialport/","link":"","permalink":"http://www.codec.wang/float-data-in-serialport/","excerpt":"我本专业是搞控制的，软件上就是天天跟上/下位机、通讯协议打交道。一次，有个学弟问我，他单片机采集的温度是小数，串口应该怎么发，协议怎么设计。","text":"我本专业是搞控制的，软件上就是天天跟上/下位机、通讯协议打交道。一次，有个学弟问我，他单片机采集的温度是小数，串口应该怎么发，协议怎么设计。 爱你所爱，行你所行，听从你心，无问西东。——《无问西东》 友情广告：电影台词分享网站：MovieQuotes 他的想法是整数部分和小数部分分开发，比如100.3，1个字节代表整数部分，1个字节代表小数部分，那如果是300.421呢？超出了1个字节的表示范围，负数-3.14又该怎么发呢？当然可以设置多个字节表示数据，然后单独设置1个字节表示正负，但显然这种方式即麻烦又不合理。 其实，float类型数据，无论正负/大小，它都是占用4个字节的。因此，下位机可以将传感器数据转成4个字节，上位机再把四个字节转成float即可，并且转换在C和C#等语言中都是一句话的事。完整代码可到源码处下载。 IEE 754浮点数16进制在线转换 大小端模式大小端模式大家应该比较熟悉了，大端模式是高字节存放在低地址中，低字节存放在高地址中。类似我们正常的从左到右阅读，数据由小到大，小端模式反之。这里之所以提及，是因为有时候不同的系统/工具得到的结果是反的，此时不用在意，是没错的。 C语言/下位机 菜鸟C在线工具 下位机一般是C语言编写的，可以将传感器数据转成字节数组，C中也就是字符数组，有多种方式： 有的单片机芯片，当使用unsigned char时，串口发送不了，此时可以去掉unsigned试下。 方法一：强制指针类型转换12345// float -&gt; char []float sensorData = -3.14;unsigned char *arr = (unsigned char *)(&amp;sensorData);printf(\"%02X,%02X,%02X,%02X\\n\", arr[0], arr[1], arr[2], arr[3]);// 结果：C3,F5,48,C0 如果想保存到char数组中： 12unsigned char charArr[4], i;for (i = 0; i &lt; 4; i++) charArr[i] = *arr++; 接下来反向转换： 12345678// char [] -&gt; floatunsigned char sBuf[4];sBuf[0] = 0xC3;sBuf[1] = 0xF5;sBuf[2] = 0x48;sBuf[3] = 0xC0;float *data = (float*)(&amp;sBuf);printf(\"%f\\n\", *data); // 结果：-3.140000 方法二：使用联合体利用联合体共享内存的原理，可以在联合体内同时定义float和char数组类型： 1234union &#123; float data; unsigned char arr[4];&#125; dataFormat; 然后转换就比较简单了： 1234// float -&gt; char []dataFormat.data = -3.14;printf(\"%02X,%02X,%02X,%02X\\n\", dataFormat.arr[0], dataFormat.arr[1], dataFormat.arr[2], dataFormat.arr[3]);// 结果：C3,F5,48,C0 反向转： 123456// char [] -&gt; floatdataFormat.arr[0] = 0xC3;dataFormat.arr[1] = 0xF5;dataFormat.arr[2] = 0x48;dataFormat.arr[3] = 0xC0;printf(\"%f\\n\", dataFormat.data); // 结果：-3.140000 C语言还是很深奥的，上面两种是最通俗易懂的方式，更多牛逼的方式尽在Google…＞﹏＜ C#/上位机 菜鸟C#在线工具 我一般使用C#编写上位机，所以以它为例。一般这类语言中都有自带的函数可以一句解决，比如C#中用BitConverter.ToSingle()和BitConverter.GetBytes()便可实现转换： 1234// byte[] -&gt; floatbyte[] recData = &#123;0xC3,0XF5,0X48,0XC0&#125;;float sensorData = BitConverter.ToSingle(recData,0); Console.WriteLine(sensorData); // 结果：-3.14 123456// float -&gt; byte[]float sData = -3.14f;byte[] rData = BitConverter.GetBytes(sData);foreach (byte data in rData) Console.Write(\"&#123;0:X000&#125;,\", data);// 结果：C3,F5,48,C0,// 判断大小端：Console.WriteLine(BitConverter.IsLittleEndian); 思考 既然知道了float数据怎么处理，那int/double呢？（原理是一样的） 引用 本节源码 Microsoft float (C# Reference) 浮点型(FLOAT)与CHAR型转换 float型数据与字节数组的转化 生命不息，折腾不止，Excelsior!","categories":[{"name":"Build篇","slug":"Build篇","permalink":"http://www.codec.wang/categories/Build%E7%AF%87/"}],"tags":[{"name":"串口","slug":"串口","permalink":"http://www.codec.wang/tags/%E4%B8%B2%E5%8F%A3/"},{"name":"float","slug":"float","permalink":"http://www.codec.wang/tags/float/"}]},{"title":"速度UP！Python/Ubuntu/NodeJS/树莓派等更换国内源汇总","slug":"速度UP！PythonUbuntuNodeJS树莓派等更换国内源汇总","date":"2019-03-21T07:08:09.000Z","updated":"2019-05-27T02:12:58.442Z","comments":true,"path":"python-ubuntu-nodejs-change-sources/","link":"","permalink":"http://www.codec.wang/python-ubuntu-nodejs-change-sources/","excerpt":"在Python/Linux/Node.js开发中，要经常下载各种各样的的包，然而由于默认的安装源大部分是在国外的服务器上，所以下载速度嘛……","text":"在Python/Linux/Node.js开发中，要经常下载各种各样的的包，然而由于默认的安装源大部分是在国外的服务器上，所以下载速度嘛…… You‘ll never win with violence, Tony, you only win when you maintain your dignity. ——《Green Book》暴力永远无法取胜，托尼，只有坚守尊严才会赢。——《绿皮书》 友情广告：电影台词分享网站：MovieQuotes 有时真的是很捉急呀，所以学会更改安装源还是很有必要滴……Python默认源：https://pypi.org/，Ubuntu默认源：http://mirrors.ubuntu.com/，Node默认源：http://registry.npmjs.org。 Python/pip更换源更换前后速度对比具体速度提升跟网络也有关系，不过一般来说，提升还是相当明显的： 常用国内源 清华大学：https://pypi.tuna.tsinghua.edu.cn/simple/ | pypi镜像使用帮助 阿里巴巴：https://mirrors.aliyun.com/pypi/simple/ 腾讯云：http://mirrors.cloud.tencent.com/pypi/simple/ 豆瓣：https://pypi.doubanio.com/simple/ 临时更改临时更换源只需要多加一个-i参数（i表示index索引），比如这里更换成清华源： 1pip install pkg -i https://pypi.tuna.tsinghua.edu.cn/simple 永久更改如果不想每次都这么麻烦的话，可以写入配置文件。新版的pip(&gt;=10.0.0)直接用下面一句话就行： 12pip config set global.index-url https://pypi.tuna.tsinghua.edu.cn/simple# 查看pip版本：pip --version 执行后，Windows/Linux都会在用户目录生成pip配置文件，如我的Windows是在： C:\\Users\\ex2tron\\AppData\\Roaming\\pip\\pip.ini，Linux是在： /home/ex2tron/.config/pip/pip.conf。 如果是旧版的pip，可以手动新建上面两个文件，然后编辑内容为： 12[global]index-url &#x3D; https:&#x2F;&#x2F;pypi.tuna.tsinghua.edu.cn&#x2F;simple 配置文件也可以直接建在用户目录下，如Windows：C:\\Users\\ex2tron\\pip\\pip.ini，Linux：/home/ex2tron/.pip/pip.conf。保存后，照常pip install pkg即可。 Ubuntu/apt更换源图形界面配置（新手推荐）如果使用的是Ubuntu的Desktop版本，更换起来就比较容易了：打开’软件和更新’，’下载自’这里选择’其他站点’： 然后在弹出的界面中选择你要更换的服务器，比如这里更换为阿里云： 点击’选择服务器’后需要验证密码，执行更新操作就可以了。 手动配置如果是不带GUI的Ubuntu服务器，或是想装X，那么可以手动更换。更换源时跟Ubuntu系统的版本也有关系，这里我以Ubuntu 18.04和清华镜像为例，后面我写了个小脚本，方便不同版本的童鞋使用。 首先需要知道的是，Linux把源列表存在/etc/apt/sources.list里面，有兴趣可以看下其中内容： 1more /etc/apt/sources.list 接下来更换方法都一样，很多开源镜像站官方也有说明，比如： 清华大学Ubuntu镜像使用帮助 中国科学技术大学Ubuntu镜像使用帮助 阿里云Ubuntu镜像使用帮助 点Ubuntu项右侧的帮助 网易Ubuntu镜像使用帮助 第一步：先将原有的备份： 1sudo cp /etc/apt/sources.list /etc/apt/sources.list.bak 第二步：sudo编辑sources.list文件，修改其内容为镜像站提供的，如清华镜像站18.04： 123456789# 默认注释了源码镜像以提高 apt update 速度，如有需要可自行取消注释deb https:&#x2F;&#x2F;mirrors.tuna.tsinghua.edu.cn&#x2F;ubuntu&#x2F; bionic main restricted universe multiverse# deb-src https:&#x2F;&#x2F;mirrors.tuna.tsinghua.edu.cn&#x2F;ubuntu&#x2F; bionic main restricted universe multiversedeb https:&#x2F;&#x2F;mirrors.tuna.tsinghua.edu.cn&#x2F;ubuntu&#x2F; bionic-updates main restricted universe multiverse# deb-src https:&#x2F;&#x2F;mirrors.tuna.tsinghua.edu.cn&#x2F;ubuntu&#x2F; bionic-updates main restricted universe multiversedeb https:&#x2F;&#x2F;mirrors.tuna.tsinghua.edu.cn&#x2F;ubuntu&#x2F; bionic-backports main restricted universe multiverse# deb-src https:&#x2F;&#x2F;mirrors.tuna.tsinghua.edu.cn&#x2F;ubuntu&#x2F; bionic-backports main restricted universe multiversedeb https:&#x2F;&#x2F;mirrors.tuna.tsinghua.edu.cn&#x2F;ubuntu&#x2F; bionic-security main restricted universe multiverse# deb-src https:&#x2F;&#x2F;mirrors.tuna.tsinghua.edu.cn&#x2F;ubuntu&#x2F; bionic-security main restricted universe multiverse 第三步：保存关闭后，执行更新索引的操作就可以了： 1sudo apt update 其实只要Ubuntu系统的版本代号对应起来就行。Ubuntu X.XX，第一个X代表年份，后两个X代表月份，一般4月份会发布LTS(Long Term Support)长期支持版本，常见的版本号和代码如下： 感兴趣的可以看引用。 版本 代号 日期 14.04 LTS Trusty Tahr / 可靠的塔尔羊 2014年4月 16.04 LTS Xenial Xerus / 好客的非洲地松鼠 2016年4月 18.04 LTS Bionic Beaver / 仿生海狸 2018年4月 自动化脚本为了方便在Ubuntu常见的版本上更换源，我写了个自动化小脚本：UbuntuAutoChangeSource.sh。脚本会自动检测Ubuntu系统版本，然后选择你想更换的镜像源就可以了： 树莓派Raspbian常用源树莓派支持的OS很多，经常用的也是官方推荐的是Raspbian。官网上有个镜像列表：http://www.raspbian.org/RaspbianMirrors，国内常用： 清华大学：http://mirrors.tuna.tsinghua.edu.cn/raspbian/raspbian/ | 使用帮助 中国科学技术大学：http://mirrors.ustc.edu.cn/raspbian/raspbian/ | 使用帮助 更换方法源列表同样存储在 /etc/apt/sources.list中，所以最好先备份下： 1sudo cp /etc/apt/sources.list /etc/apt/sources.list.bak 更换时也跟版本有关，比如基于Debian 9 Stretch构建的Raspbian 2018-11-13版本修改成清华大学的源（可将原先的用#注释掉，也可以覆盖修改，反正已经备份了）： 12deb http:&#x2F;&#x2F;mirrors.tuna.tsinghua.edu.cn&#x2F;raspbian&#x2F;raspbian&#x2F; stretch main contrib non-free rpideb-src http:&#x2F;&#x2F;mirrors.tuna.tsinghua.edu.cn&#x2F;raspbian&#x2F;raspbian&#x2F; stretch main contrib non-free rpi 虽说跟版本有关，但基本上只要把源的地址改掉就好了。比如上面的修改方式也可以使用sed工具一键修改（针对Raspbian 2018-04-19后的版本）： 1sudo sed -i 's|raspbian.raspberrypi.org|mirrors.tuna.tsinghua.edu.cn/raspbian|g' /etc/apt/sources.list 最后记得更新一下就好了： 1sudo apt update Node.js/npm更换源临时更换国内最常用的npm镜像站是淘宝的：http://npm.taobao.org/ 。临时更换就是加上--registry选项： 1npm install pkg --registry=https://registry.npm.taobao.org 永久更改类似于pip，可以直接使用npm config设置： 1npm config set registry https://registry.npm.taobao.org 验证有无生效： 1npm config get registry 要恢复默认的话： 1npm config set registry http://registry.npmjs.org 速度对比我就不放了，总之，各类包管理器，更换为国内的源之后，速度都会大幅提升。 引用 清华大学开源镜像站 阿里巴巴开源镜像站 网易开源镜像站 浙江大学开源镜像站 中国科学技术大学开源镜像站 淘宝NPM镜像站 本节源码 Ubuntu官网版本号及代号说明：DevelopmentCodeNames 生命不息，折腾不止，Excelsior!","categories":[{"name":"Build篇","slug":"Build篇","permalink":"http://www.codec.wang/categories/Build%E7%AF%87/"}],"tags":[{"name":"Python","slug":"Python","permalink":"http://www.codec.wang/tags/Python/"},{"name":"Ubuntu","slug":"Ubuntu","permalink":"http://www.codec.wang/tags/Ubuntu/"},{"name":"NodeJS","slug":"NodeJS","permalink":"http://www.codec.wang/tags/NodeJS/"},{"name":"pip","slug":"pip","permalink":"http://www.codec.wang/tags/pip/"},{"name":"nmp","slug":"nmp","permalink":"http://www.codec.wang/tags/nmp/"},{"name":"apt","slug":"apt","permalink":"http://www.codec.wang/tags/apt/"}]},{"title":"Ubuntu上安装Windows10双系统步骤及常见问题","slug":"Ubuntu上安装Windows10双系统步骤及常见问题","date":"2019-03-17T12:42:59.000Z","updated":"2019-03-24T06:13:50.754Z","comments":true,"path":"install-windows10-on-ubuntu/","link":"","permalink":"http://www.codec.wang/install-windows10-on-ubuntu/","excerpt":"之前想装个Windows10+Ubuntu的双系统，网上有很多教程是Windows上怎么安装Ubuntu的，可我电脑TMD本身就是Ubuntu啊，在Ubuntu上安装Windows的资料相对较少，真是神坑。下面分享下我的教程：","text":"之前想装个Windows10+Ubuntu的双系统，网上有很多教程是Windows上怎么安装Ubuntu的，可我电脑TMD本身就是Ubuntu啊，在Ubuntu上安装Windows的资料相对较少，真是神坑。下面分享下我的教程： The world is full of lonely people waiting to make the first move. ——《Green Book》世界上有太多孤独的人害怕先踏出第一步。——《绿皮书》 友情广告：电影台词分享网站：MovieQuotes 分区和安装有风险，不熟悉的同学请提前备份数据并谨慎操作！！！ Ubuntu 16.04.5 Windows 10 1809 安装步骤分区分区是最为关键的步骤，一般有两种情况： 你的电脑上已经有一个单独的不用的分区，比如有的电脑上是SSD+HDD的，这种情况下你可以将Windows直接安装在这个分区上，最后只要添加下引导就行。 如果不是上面的情况，也就是整个硬盘都在为Ubuntu所使用，就要分出一个区来： 简单的分区方式（简单的不行可以看后面复杂的） Ubuntu上安装gparted图形化分区工具：sudo apt install gparted。打开之后，选择要分区的区域，比如我要从/dev/sda1中分区，然后点击菜单栏的调整分区大小按钮： 如果出来的界面某些项是灰色的（就像上图这样），说明不可以用这种方式分区。 略微复杂的方式 需要一个Ubuntu的U盘镜像（不必跟你原来的Ubuntu系统同版本），以普通的装机方式进入安装程序后，到安装类型这一步，千万不要乱选，一定要选其他选项： 然后选择你要分区的区域，点击下方的更改： 在弹出的更改区域大小中，输入新分区的大小，点击OK，成功之后，就退出安装，不要再安装一个Ubuntu了： 前面就实现了分区，但Windows的分区格式跟Ubuntu不一样，所以需要回到Ubuntu系统，打开gparted，将分区转换成ntfs格式，用于安装Windows： 安装Windows这一步就是正常的Windows安装流程（不赘述，安装的时候记得选择我们刚分好的区） 引导项修复安装完Windows后，Ubuntu的引导项就不见了。最简单的方法是在Windows上安装使用EasyBCD引导Ubuntu： 首先添加引导项，一定记得选Swap交换分区 然后点击“编辑引导菜单”并保存设置 这样就完成了全部安装流程。 常见问题问题1：如果开机选择Ubuntu系统时出现： 解决方案：进入Windows系统，使用EasyBCD重新引导即可，具体步骤： 先将原有的Ubuntu引导项删除 然后重复之前添加引导项的步骤即可。 问题2：使用刻录的Ubuntu U盘镜像安装系统时出现： 解决方案：按下tab键，会弹出如下提示： 按照提示，输入live live-install回车即可。 生命不息，折腾不止，Excelsior!","categories":[{"name":"Build篇","slug":"Build篇","permalink":"http://www.codec.wang/categories/Build%E7%AF%87/"}],"tags":[{"name":"Build","slug":"Build","permalink":"http://www.codec.wang/tags/Build/"},{"name":"Windows","slug":"Windows","permalink":"http://www.codec.wang/tags/Windows/"},{"name":"Ubuntu","slug":"Ubuntu","permalink":"http://www.codec.wang/tags/Ubuntu/"}]},{"title":"使用环境变量避免在代码中写明密码和密钥等重要信息","slug":"使用环境变量避免在代码中写明密码和密钥等重要信息","date":"2019-01-19T14:29:07.000Z","updated":"2019-03-24T06:13:50.746Z","comments":true,"path":"hiding-passwds-secret-keys-in-environment-variables/","link":"","permalink":"http://www.codec.wang/hiding-passwds-secret-keys-in-environment-variables/","excerpt":"很多人会在代码中直接明码写上数据库用户名/密码、API Key这些重要信息，这种方式很不安全，因为别人在看到代码后是可以直接使用这些信息的。","text":"很多人会在代码中直接明码写上数据库用户名/密码、API Key这些重要信息，这种方式很不安全，因为别人在看到代码后是可以直接使用这些信息的。有很多隐藏密码的技巧，环境变量便是其中之一。 使用环境变量的好处在于，你仍然可以完全共享你的代码而不用担心泄露重要信息。 测试代码以下面这段Python代码为例，代码中直接写明了数据库用户名和密码： 1234db_user = \"ex2tron\"db_passwd = \"ex2tron12345\"print(db_user, db_passwd) 我们看下如何使用环境变量隐藏这些信息： Linux下隐藏方式Linux系统的运行是以各种可自由编辑的配置文件为基础的，以Ubuntu为例，我们可以编辑当前用户的终端配置文件.bashrc。 大部分配置文件位于当前用户目录下，如果在其他目录的话，可以直接输入cd快速切换。 在.bashrc文件的末尾添加下面两句，注意等号左右无空格噢： 12export DB_USER=\"ex2tron\"export DB_PASSWD=\"ex2tron12345\" 可以在当前终端source ~/.bashrc或重启终端使环境变量生效。之后代码只需略作修改： 123456import osdb_user = os.environ.get(\"DB_USER\")db_passwd = os.environ.get(\"DB_PASSWD\")print(db_user, db_passwd) Windows下隐藏方式熟悉Windows配置软件的童鞋应该经常用到Path环境变量，同样，我们也可以建两个自己的环境变量。在开始菜单搜索环境变量，打开系统属性窗口并点击“环境变量”： 在环境变量界面，可以在用户环境变量下点击新建，新建两个变量用来存储数据库用户名和密码： 12DB_USER ex2tronDB_PASSWD ex2tron12345 编辑好之后，代码跟前面的修改方式一样。如果打印出来为空，说明环境变量没有生效，可以重启你的IDE。 生命不息，折腾不止，Excelsior!","categories":[{"name":"Build篇","slug":"Build篇","permalink":"http://www.codec.wang/categories/Build%E7%AF%87/"}],"tags":[{"name":"Build","slug":"Build","permalink":"http://www.codec.wang/tags/Build/"},{"name":"hiding-info","slug":"hiding-info","permalink":"http://www.codec.wang/tags/hiding-info/"},{"name":"environment-variables","slug":"environment-variables","permalink":"http://www.codec.wang/tags/environment-variables/"}]},{"title":"如何使用Windows 10的OpenSSH Client和Server","slug":"如何使用Windows 10的OpenSSH Client和Server","date":"2019-01-02T13:00:54.000Z","updated":"2019-03-24T06:13:50.747Z","comments":true,"path":"how-to-use-ssh-on-windows10/","link":"","permalink":"http://www.codec.wang/how-to-use-ssh-on-windows10/","excerpt":"SSH目前是Unix和Linux上用于加密连接远程服务器的命令行工具，微软也在最新的Windows10中集成了OpenSSH，下面就来看下怎么开启并使用。","text":"SSH目前是Unix和Linux上用于加密连接远程服务器的命令行工具，微软也在最新的Windows10中集成了OpenSSH，下面就来看下怎么开启并使用。 版本说明新版Windows 10（1803及以上）都已预装了OpenSSH Client，但默认并没有装SSH Server。要测试有没有安装的话，可以打开命令行cmd，输入： 12ssh -V# OpenSSH_for_Windows_7.6p1, LibreSSL 2.6.4 如果你的Win10版本较低的话，可能没有预装，也没有关系，下面来看。 安装Windows 10开始菜单搜索“管理可选功能”，或打开Windows 10的设置，找到应用和功能，并选择“管理可选功能”： 在管理可选功能页面，点击“添加功能”，找到OpenSSH 客户端和OpenSSH 服务器，客户端没有的话，说明已经安装了： 如果你只是想使用SSH连接服务器，而不是把自己的电脑当作服务器的话，Server是不需要安装的。安装路径是在C:\\Windows\\System32\\OpenSSH\\目录下，可以看到除了SSH，Windows 10也自带了scp，sftp等很实用的工具。 12345dir C:\\Windows\\System32\\OpenSSH# scp.exe# sftp.exe# ssh-keygen.exe# …… SSH Client的使用安装好之后，就和正常使用SSH没有区别了，比如局域网内有台服务器IP地址是192.168.1.110，那么在Win10 cmd下输入： 1ssh username@192.168.1.110 客户端的使用跟Linux下SSH的使用一致，就不赘述了。主要来看下Win10上Server的配置。 SSH Server的使用安装好OpenSSH Server后，Win10开始菜单搜索服务，打开服务，找到OpenSSH SSH Server，目前它的状态是手动并已停止服务： 我们可以右键启动服务，如果你经常用到它的话，可以在属性中设置为自动启动。 要检测SSH服务有没有运行的话，可以在cmd中输入： 12netstat -a | findstr 22# TCP 0.0.0.0:22 ex2tronSurface:0 LISTENING 确认开启后，本机Win10就可以接收外部SSH连接了。在cmd输入ipconfig，获取现在Win10的IP，比如是192.168.1.199，用另一台任意操作系统的电脑使用SSH便可连接： 1ssh username@192.168.1.199 注意此时用户名和密码是你Win10的用户名和密码。 sshd 配置文件SSH服务开启后，默认的配置文件在C:\\Windows\\System32\\OpenSSH\\目录下： 12dir C:\\Windows\\System32\\OpenSSH\\# sshd_config_default 但实际运行的配置文件是C:\\ProgramData\\ssh\\sshd_config，熟悉SSH的同学对里面的配置项应该都了解，比如ssh默认启动路径ChrootDirectory。默认情况下，ssh连接后，启动路径是Windows的个人文件夹，如C:\\Users\\ex2tron，我一般会更改到我的工作路径，如：D:\\Surface，就可以这样修改： 1ChrootDirectory D:\\Surface 其他配置项常用的有： 1234PermitRootLogin # 是否允许root登陆PasswordAuthentication # 是否运行使用密码登陆，如果你已经建立好ssh公钥的话，可以设置为no免密登陆，更安全PermitEmptyPasswords # 是否允许空密码AuthorizedKeysFile # ssh公钥目录 配置完之后一定记得重启ssh server，否则是不会生效的。一种方法是服务里面，右键选择重启： 还有一种就是在cmd下直接重启，cmd需以管理员权限打开： 12net stop sshdnet start sshd 生命不息，折腾不止，Excelsior!","categories":[{"name":"Build篇","slug":"Build篇","permalink":"http://www.codec.wang/categories/Build%E7%AF%87/"}],"tags":[{"name":"Build","slug":"Build","permalink":"http://www.codec.wang/tags/Build/"},{"name":"Windows10","slug":"Windows10","permalink":"http://www.codec.wang/tags/Windows10/"},{"name":"SSH","slug":"SSH","permalink":"http://www.codec.wang/tags/SSH/"},{"name":"SSH-Server","slug":"SSH-Server","permalink":"http://www.codec.wang/tags/SSH-Server/"}]},{"title":"2018最后一个工作日，一份小礼物","slug":"2018最后一个工作日，一份小礼物","date":"2018-12-29T10:00:31.000Z","updated":"2019-03-24T06:13:50.744Z","comments":true,"path":"a-gift-for-2019-moviequotes/","link":"","permalink":"http://www.codec.wang/a-gift-for-2019-moviequotes/","excerpt":"[**moviequotes.ex2tron.wang**](http://moviequotes.ex2tron.wang) 2018是感伤的一年，很多人离我们而去，太多的不开心…好在就要结束了。今天是最后一个工作日（其实在学校我每天都在放假(●ˇ∀ˇ●)），特送上一份小礼物给大家：MovieQuotes","text":"[**moviequotes.ex2tron.wang**](http://moviequotes.ex2tron.wang) 2018是感伤的一年，很多人离我们而去，太多的不开心…好在就要结束了。今天是最后一个工作日（其实在学校我每天都在放假(●ˇ∀ˇ●)），特送上一份小礼物给大家：MovieQuotes 这是个简单的电影经典台词网站，灵感来自我以前在腾讯学习Scrapy时的一个网站[quotes.toscrape.com](http://quotes.toscrape.com)，这上面是一些名人名句。因为我平常喜欢看电影，写博客的时候也经常在开头放一句经典台词，所以平时搜集了不少，于是就有了这个网站。网站本身很简单，用Python和Django搭的，没什么难的东西，下面是一些截图： 各位看官不要嫌UI丑啊，我是完全模仿原网站做的。后期如果有时间我会更换一套自己的UI。 其实每句电影台词配一张截图最好了，不过加上去有点丑，所以没放出来。另外，多用户登陆注册和分享的功能同样也没放出来，目前一切从简。有想要贡献词条的同学可以联系我噢，最后祝大家元旦快乐！(☆▽☆) 生命不息，折腾不止，Excelsior!","categories":[{"name":"Build篇","slug":"Build篇","permalink":"http://www.codec.wang/categories/Build%E7%AF%87/"}],"tags":[{"name":"Build","slug":"Build","permalink":"http://www.codec.wang/tags/Build/"},{"name":"Django","slug":"Django","permalink":"http://www.codec.wang/tags/Django/"},{"name":"电影台词","slug":"电影台词","permalink":"http://www.codec.wang/tags/%E7%94%B5%E5%BD%B1%E5%8F%B0%E8%AF%8D/"}]},{"title":"Python+OpenCV教程挑战任务：车道检测","slug":"Python-OpenCV教程挑战任务3：车道检测","date":"2017-12-28T03:38:11.000Z","updated":"2018-12-02T13:11:54.989Z","comments":true,"path":"opencv-python-lane-road-detection/","link":"","permalink":"http://www.codec.wang/opencv-python-lane-road-detection/","excerpt":"挑战任务：实际公路的车道线检测。","text":"挑战任务：实际公路的车道线检测。图片等可到源码处下载。 挑战内容 1. 在所提供的公路图片上检测出车道线并标记： 2. 在所提供的公路视频上检测出车道线并标记： &lt;video id=”video” controls=”” 本次挑战内容来自Udacity自动驾驶纳米学位课程，素材中车道保持不变，车道线清晰明确，易于检测，是车道检测的基础版本，网上也有很多针对复杂场景的高级实现，感兴趣的童鞋可以自行了解。 挑战题不会做也木有关系，但请务必在自行尝试后，再看下面的解答噢，不然…我也没办法(￣▽￣)” 挑战解答方案要检测出当前车道，就是要检测出左右两条车道直线。由于无人车一直保持在当前车道，那么无人车上的相机拍摄的视频中，车道线的位置应该基本固定在某一个范围内： 如果我们手动把这部分ROI区域抠出来，就会排除掉大部分干扰。接下来检测直线肯定是用霍夫变换，但ROI区域内的边缘直线信息还是很多，考虑到只有左右两条车道线，一条斜率为正，一条为负，可将所有的线分为两组，每组再通过均值或最小二乘法拟合的方式确定唯一一条线就可以完成检测。总体步骤如下： 灰度化 高斯模糊 Canny边缘检测 不规则ROI区域截取 霍夫直线检测 车道计算 对于视频来说，只要一幅图能检查出来，合成下就可以了，问题不大。 图像预处理灰度化和滤波操作是大部分图像处理的必要步骤。灰度化不必多说，因为不是基于色彩信息识别的任务，所以没有必要用彩色图，可以大大减少计算量。而滤波会削弱图像噪点，排除干扰信息。另外，根据前面学习的知识，边缘提取是基于图像梯度的，梯度对噪声很敏感，所以平滑滤波操作必不可少。 这次的代码我们分模块来写，规范一点。其中process_an_image()是主要的图像处理流程： 1234567891011121314151617181920import cv2import numpy as np# 高斯滤波核大小blur_ksize = 5# Canny边缘检测高低阈值canny_lth = 50canny_hth = 150def process_an_image(img): # 1. 灰度化、滤波和Canny gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY) blur_gray = cv2.GaussianBlur(gray, (blur_ksize, blur_ksize), 1) edges = cv2.Canny(blur_gray, canny_lth, canny_hth)if __name__ == \"__main__\": img = cv2.imread('test_pictures/lane.jpg') result = process_an_image(img) cv2.imshow(\"lane\", np.hstack((img, result))) cv2.waitKey(0) ROI截取按照前面描述的方案，只需保留边缘图中的红线部分区域用于后续的霍夫直线检测，其余都是无用的信息： 如何实现呢？还记得图像混合中的这张图吗？ 我们可以创建一个梯形的mask掩膜，然后与边缘检测结果图混合运算，掩膜中白色的部分保留，黑色的部分舍弃。梯形的四个坐标需要手动标记： 12345678910111213141516def process_an_image(img): # 1. 灰度化、滤波和Canny # 2. 标记四个坐标点用于ROI截取 rows, cols = edges.shape points = np.array([[(0, rows), (460, 325), (520, 325), (cols, rows)]]) # [[[0 540], [460 325], [520 325], [960 540]]] roi_edges = roi_mask(edges, points) def roi_mask(img, corner_points): # 创建掩膜 mask = np.zeros_like(img) cv2.fillPoly(mask, corner_points, 255) masked_img = cv2.bitwise_and(img, mask) return masked_img 这样，结果图”roi_edges”应该是： 霍夫直线提取为了方便后续计算直线的斜率，我们使用统计概率霍夫直线变换（因为它能直接得到直线的起点和终点坐标）。霍夫变换的参数比较多，可以放在代码开头，便于修改： 1234567891011121314151617181920212223242526272829# 霍夫变换参数rho = 1theta = np.pi / 180threshold = 15min_line_len = 40max_line_gap = 20def process_an_image(img): # 1. 灰度化、滤波和Canny # 2. 标记四个坐标点用于ROI截取 # 3. 霍夫直线提取 drawing, lines = hough_lines(roi_edges, rho, theta, threshold, min_line_len, max_line_gap)def hough_lines(img, rho, theta, threshold, min_line_len, max_line_gap): # 统计概率霍夫直线变换 lines = cv2.HoughLinesP(img, rho, theta, threshold, minLineLength=min_line_len, maxLineGap=max_line_gap) # 新建一副空白画布 drawing = np.zeros((img.shape[0], img.shape[1], 3), dtype=np.uint8) # draw_lines(drawing, lines) # 画出直线检测结果 return drawing, linesdef draw_lines(img, lines, color=[0, 0, 255], thickness=1): for line in lines: for x1, y1, x2, y2 in line: cv2.line(img, (x1, y1), (x2, y2), color, thickness) draw_lines()是用来画直线检测的结果，后面我们会接着处理直线，所以这里注释掉了，可以取消注释看下效果： 对本例的这张测试图来说，如果打印出直线的条数print(len(lines))，应该是有16条。 车道计算这部分应该算是本次挑战任务的核心内容了：前面通过霍夫变换得到了多条直线的起点和终点，我们的目的是通过某种算法只得到左右两条车道线。 第一步、根据斜率正负划分某条线是左车道还是右车道。$$斜率=\\frac{y_2-y_1}{x_2-x_1}(\\leq0:左,&gt;0:右)$$ 经验之谈：再次强调，斜率计算是在图像坐标系下，所以斜率正负/左右跟平面坐标有区别。 第二步、迭代计算各直线斜率与斜率均值的差，排除掉差值过大的异常数据。 注意这里迭代的含义，意思是第一次计算完斜率均值并排除掉异常值后，再在剩余的斜率中取均值，继续排除……这样迭代下去。 第三步、最小二乘法拟合左右车道线。 经过第二步的筛选，就只剩下可能的左右车道线了，这样只需从多条直线中拟合出一条就行。拟合方法有很多种，最常用的便是最小二乘法，它通过最小化误差的平方和来寻找数据的最佳匹配函数。 具体来说，假设目前可能的左车道线有6条，也就是12个坐标点，包括12个x和12个y，我们的目的是拟合出这样一条直线：$$f(x_i) = ax_i+b$$使得误差平方和最小：$$E=\\sum(f(x_i)-y_i)^2$$ Python中可以直接使用np.polyfit()进行最小二乘法拟合。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677def process_an_image(img): # 1. 灰度化、滤波和Canny # 2. 标记四个坐标点用于ROI截取 # 3. 霍夫直线提取 # 4. 车道拟合计算 draw_lanes(drawing, lines) # 5. 最终将结果合在原图上 result = cv2.addWeighted(img, 0.9, drawing, 0.2, 0) return resultdef draw_lanes(img, lines, color=[255, 0, 0], thickness=8): # a. 划分左右车道 left_lines, right_lines = [], [] for line in lines: for x1, y1, x2, y2 in line: k = (y2 - y1) / (x2 - x1) if k &lt; 0: left_lines.append(line) else: right_lines.append(line) if (len(left_lines) &lt;= 0 or len(right_lines) &lt;= 0): return # b. 清理异常数据 clean_lines(left_lines, 0.1) clean_lines(right_lines, 0.1) # c. 得到左右车道线点的集合，拟合直线 left_points = [(x1, y1) for line in left_lines for x1, y1, x2, y2 in line] left_points = left_points + [(x2, y2) for line in left_lines for x1, y1, x2, y2 in line] right_points = [(x1, y1) for line in right_lines for x1, y1, x2, y2 in line] right_points = right_points + [(x2, y2) for line in right_lines for x1, y1, x2, y2 in line] left_results = least_squares_fit(left_points, 325, img.shape[0]) right_results = least_squares_fit(right_points, 325, img.shape[0]) # 注意这里点的顺序 vtxs = np.array([[left_results[1], left_results[0], right_results[0], right_results[1]]]) # d. 填充车道区域 cv2.fillPoly(img, vtxs, (0, 255, 0)) # 或者只画车道线 # cv2.line(img, left_results[0], left_results[1], (0, 255, 0), thickness) # cv2.line(img, right_results[0], right_results[1], (0, 255, 0), thickness) def clean_lines(lines, threshold): # 迭代计算斜率均值，排除掉与差值差异较大的数据 slope = [(y2 - y1) / (x2 - x1) for line in lines for x1, y1, x2, y2 in line] while len(lines) &gt; 0: mean = np.mean(slope) diff = [abs(s - mean) for s in slope] idx = np.argmax(diff) if diff[idx] &gt; threshold: slope.pop(idx) lines.pop(idx) else: break def least_squares_fit(point_list, ymin, ymax): # 最小二乘法拟合 x = [p[0] for p in point_list] y = [p[1] for p in point_list] # polyfit第三个参数为拟合多项式的阶数，所以1代表线性 fit = np.polyfit(y, x, 1) fit_fn = np.poly1d(fit) # 获取拟合的结果 xmin = int(fit_fn(ymin)) xmax = int(fit_fn(ymax)) return [(xmin, ymin), (xmax, ymax)] 这段代码比较多，请每个步骤单独来看。最后得到的是左右两条车道线的起点和终点坐标，可以选择画出车道线，这里我直接填充了整个区域： 视频处理搞定了一张图，视频也就没什么问题了，关键就是视频帧的提取和合成，为此，我们要用到Python的视频编辑包moviepy： 1pip install moviepy 另外还需要ffmpeg，首次运行moviepy时会自动下载，也可手动下载。 只需在开头导入moviepy，然后将主函数改掉就可以了，其余代码不需要更改： 123456789# 开头导入moviepyfrom moviepy.editor import VideoFileClip# 主函数更改为：if __name__ == \"__main__\": output = 'test_videos/output.mp4' clip = VideoFileClip(\"test_videos/cv2_white_lane.mp4\") out_clip = clip.fl_image(process_an_image) out_clip.write_videofile(output, audio=False) 本文实现了车道检测的基础版本，如果你感兴趣的话，可以自行搜索或参考引用部分了解更多。 引用 图片和视频素材 本节源码 从零开始学习无人驾驶技术 — 车道检测 无人驾驶之高级车道线检测","categories":[{"name":"机器视觉","slug":"机器视觉","permalink":"http://www.codec.wang/categories/%E6%9C%BA%E5%99%A8%E8%A7%86%E8%A7%89/"}],"tags":[{"name":"OpenCV","slug":"OpenCV","permalink":"http://www.codec.wang/tags/OpenCV/"},{"name":"Python","slug":"Python","permalink":"http://www.codec.wang/tags/Python/"},{"name":"图像处理","slug":"图像处理","permalink":"http://www.codec.wang/tags/%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86/"},{"name":"车道检测","slug":"车道检测","permalink":"http://www.codec.wang/tags/%E8%BD%A6%E9%81%93%E6%A3%80%E6%B5%8B/"}]},{"title":"Python+OpenCV教程17：霍夫变换","slug":"Python-OpenCV教程17：霍夫变换","date":"2017-12-28T03:35:11.000Z","updated":"2018-11-27T12:01:37.467Z","comments":true,"path":"opencv-python-hough-transform/","link":"","permalink":"http://www.codec.wang/opencv-python-hough-transform/","excerpt":"学习使用霍夫变换识别出图像中的直线和圆。","text":"学习使用霍夫变换识别出图像中的直线和圆。图片等可到源码处下载。 目标 理解霍夫变换的实现 分别使用霍夫线变换和圆变换检测图像中的直线和圆 OpenCV函数：cv2.HoughLines(), cv2.HoughLinesP(), cv2.HoughCircles() 教程理解霍夫变换霍夫变换常用来在图像中提取直线和圆等几何形状，我来做个简易的解释： 学过几何的都知道，直线可以分别用直角坐标系和极坐标系来表示： 那么经过某个点(x0,y0)的所有直线都可以用这个式子来表示： $$r_\\theta=x_0\\cdot\\cos \\theta+y_0\\cdot\\sin \\theta$$ 也就是说每一个(r,θ)都表示一条经过(x0,y0)直线，那么同一条直线上的点必然会有同样的(r,θ)。如果将某个点所有的(r,θ)绘制成下面的曲线，那么同一条直线上的点的(r,θ)曲线会相交于一点： OpenCV中首先计算(r,θ) 累加数，累加数超过一定值后就认为在同一直线上。 霍夫直线变换OpenCV中用cv2.HoughLines()在二值图上实现霍夫变换，函数返回的是一组直线的(r,θ)数据： 1234567891011import cv2import numpy as np# 1.加载图片，转为二值图img = cv2.imread('shapes.jpg')drawing = np.zeros(img.shape[:], dtype=np.uint8)gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)edges = cv2.Canny(gray, 50, 150)# 2.霍夫直线变换lines = cv2.HoughLines(edges, 0.8, np.pi / 180, 90) 函数中： 参数1：要检测的二值图（一般是阈值分割或边缘检测后的图） 参数2：距离r的精度，值越大，考虑越多的线 参数3：角度θ的精度，值越小，考虑越多的线 参数4：累加数阈值，值越小，考虑越多的线 12345678910111213# 3.将检测的线画出来（注意是极坐标噢）for line in lines: rho, theta = line[0] a = np.cos(theta) b = np.sin(theta) x0 = a * rho y0 = b * rho x1 = int(x0 + 1000 * (-b)) y1 = int(y0 + 1000 * (a)) x2 = int(x0 - 1000 * (-b)) y2 = int(y0 - 1000 * (a)) cv2.line(drawing, (x1, y1), (x2, y2), (0, 0, 255)) 统计概率霍夫直线变换前面的方法又称为标准霍夫变换，它会计算图像中的每一个点，计算量比较大，另外它得到的是整一条线（r和θ），并不知道原图中直线的端点。所以提出了统计概率霍夫直线变换(Probabilistic Hough Transform)，是一种改进的霍夫变换： 1234drawing = np.zeros(img.shape[:], dtype=np.uint8)# 3.统计概率霍夫线变换lines = cv2.HoughLinesP(edges, 0.8, np.pi / 180, 90, minLineLength=50, maxLineGap=10) 前面几个参数跟之前的一样，有两个可选参数： minLineLength：最短长度阈值，比这个长度短的线会被排除 maxLineGap：同一直线两点之间的最大距离 1234# 3.将检测的线画出来for line in lines: x1, y1, x2, y2 = line[0] cv2.line(drawing, (x1, y1), (x2, y2), (0, 255, 0), 1, lineType=cv2.LINE_AA) cv2.LINE_AA在之前绘图功能中讲解过，表示抗锯齿线型。 霍夫圆变换霍夫圆变换跟直线变换类似，只不过线是用(r,θ)表示，圆是用(x_center,y_center,r)来表示，从二维变成了三维，数据量变大了很多；所以一般使用霍夫梯度法减少计算量，对该算法感兴趣的同学可参考：Circle Hough Transform 1234drawing = np.zeros(img.shape[:], dtype=np.uint8)# 2.霍夫圆变换circles = cv2.HoughCircles(edges, cv2.HOUGH_GRADIENT, 1, 20, param2=30)circles = np.int0(np.around(circles)) 其中， 参数2：变换方法，一般使用霍夫梯度法，详情：HoughModes 参数3 dp=1：表示霍夫梯度法中累加器图像的分辨率与原图一致 参数4：两个不同圆圆心的最短距离 参数5：param2跟霍夫直线变换中的累加数阈值一样 1234# 将检测的圆画出来for i in circles[0, :]: cv2.circle(drawing, (i[0], i[1]), i[2], (0, 255, 0), 2) # 画出外圆 cv2.circle(drawing, (i[0], i[1]), 2, (0, 0, 255), 3) # 画出圆心 小结 霍夫变换用来提取图像中的直线和圆等几何形状。 霍夫直线变换：cv2.HoughLines()（整条直线）, cv2.HoughLinesP()。 霍夫圆变换：cv2.HoughCircles()。 引用 本节源码 Hough Line Transform Hough Circle Transform Hough transform 经典霍夫变换（Hough Transform）","categories":[{"name":"机器视觉","slug":"机器视觉","permalink":"http://www.codec.wang/categories/%E6%9C%BA%E5%99%A8%E8%A7%86%E8%A7%89/"}],"tags":[{"name":"OpenCV","slug":"OpenCV","permalink":"http://www.codec.wang/tags/OpenCV/"},{"name":"Python","slug":"Python","permalink":"http://www.codec.wang/tags/Python/"},{"name":"图像处理","slug":"图像处理","permalink":"http://www.codec.wang/tags/%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86/"},{"name":"霍夫变换","slug":"霍夫变换","permalink":"http://www.codec.wang/tags/%E9%9C%8D%E5%A4%AB%E5%8F%98%E6%8D%A2/"}]},{"title":"Python+OpenCV教程16：模板匹配","slug":"Python-OpenCV教程16：模板匹配","date":"2017-12-27T08:45:31.000Z","updated":"2018-11-27T11:47:00.550Z","comments":true,"path":"opencv-python-template-matching/","link":"","permalink":"http://www.codec.wang/opencv-python-template-matching/","excerpt":"学习使用模板匹配在图像中寻找物体。","text":"学习使用模板匹配在图像中寻找物体。图片等可到源码处下载。 目标 使用模板匹配在图像中寻找物体 OpenCV函数：cv2.matchTemplate(), cv2.minMaxLoc() 教程模板匹配模板匹配就是用来在大图中找小图，也就是说在一副图像中寻找另外一张模板图像的位置： 用cv2.matchTemplate()实现模板匹配。首先我们来读入图片和模板： 1234567import cv2import numpy as npfrom matplotlib import pyplot as pltimg = cv2.imread('lena.jpg', 0)template = cv2.imread('face.jpg', 0)h, w = template.shape[:2] # rows-&gt;h, cols-&gt;w 匹配函数返回的是一副灰度图，最白的地方表示最大的匹配。使用cv2.minMaxLoc()函数可以得到最大匹配值的坐标，以这个点为左上角角点，模板的宽和高画矩形就是匹配的位置了： 1234567# 相关系数匹配方法：cv2.TM_CCOEFFres = cv2.matchTemplate(img, template, cv2.TM_CCOEFF)min_val, max_val, min_loc, max_loc = cv2.minMaxLoc(res)left_top = max_loc # 左上角right_bottom = (left_top[0] + w, left_top[1] + h) # 右下角cv2.rectangle(img, left_top, right_bottom, 255, 2) # 画出矩形位置 原理 这部分可看可不看，不太理解也没关系，还记得前面的方法吗？不懂得就划掉(✿◕‿◕✿) 模板匹配的原理其实很简单，就是不断地在原图中移动模板图像去比较，有6种不同的比较方法，详情可参考：TemplateMatchModes 平方差匹配CV_TM_SQDIFF：用两者的平方差来匹配，最好的匹配值为0 归一化平方差匹配CV_TM_SQDIFF_NORMED 相关匹配CV_TM_CCORR：用两者的乘积匹配，数值越大表明匹配程度越好 归一化相关匹配CV_TM_CCORR_NORMED 相关系数匹配CV_TM_CCOEFF：用两者的相关系数匹配，1表示完美的匹配，-1表示最差的匹配 归一化相关系数匹配CV_TM_CCOEFF_NORMED 归一化的意思就是将值统一到0~1，这些方法的对比代码可到源码处查看。模板匹配也是应用卷积来实现的：假设原图大小为W×H，模板图大小为w×h，那么生成图大小是(W-w+1)×(H-h+1)，生成图中的每个像素值表示原图与模板的匹配程度。 匹配多个物体前面我们是找最大匹配的点，所以只能匹配一次。我们可以设定一个匹配阈值来匹配多次： 123456789101112131415# 1.读入原图和模板img_rgb = cv2.imread('mario.jpg')img_gray = cv2.cvtColor(img_rgb, cv2.COLOR_BGR2GRAY)template = cv2.imread('mario_coin.jpg', 0)h, w = template.shape[:2]# 2.标准相关模板匹配res = cv2.matchTemplate(img_gray, template, cv2.TM_CCOEFF_NORMED)threshold = 0.8 # 3.这边是Python/Numpy的知识，后面解释loc = np.where(res &gt;= threshold) # 匹配程度大于%80的坐标y,xfor pt in zip(*loc[::-1]): # *号表示可选参数 right_bottom = (pt[0] + w, pt[1] + h) cv2.rectangle(img_rgb, pt, right_bottom, (0, 0, 255), 2) 第3步有几个Python/Numpy的重要知识，来大致看下： np.where()在这里返回res中值大于0.8的所有坐标，如： 123x = np.arange(9.).reshape(3, 3)print(np.where(x &gt; 5))# 结果(先y坐标，再x坐标)：(array([2, 2, 2]), array([0, 1, 2])) zip()函数，功能强大到难以解释，举个简单例子就知道了： 123x = [1, 2, 3]y = [4, 5, 6]print(list(zip(x, y))) # [(1, 4), (2, 5), (3, 6)] 这样大家就能理解前面代码的用法了吧：因为loc是先y坐标再x坐标，所以用loc[::-1]翻转一下，然后再用zip函数拼接在一起。 练习 之前我们有学过形状匹配，不论形状旋转/缩放都可以匹配到。思考一下，图片旋转或缩放的话模板匹配还有作用吗？ 小结 模板匹配用来在大图中找小图。 cv2.matchTemplate()用来进行模板匹配。 引用 本节源码 Template Matching 模板匹配 TemplateMatchModes","categories":[{"name":"机器视觉","slug":"机器视觉","permalink":"http://www.codec.wang/categories/%E6%9C%BA%E5%99%A8%E8%A7%86%E8%A7%89/"}],"tags":[{"name":"OpenCV","slug":"OpenCV","permalink":"http://www.codec.wang/tags/OpenCV/"},{"name":"Python","slug":"Python","permalink":"http://www.codec.wang/tags/Python/"},{"name":"图像处理","slug":"图像处理","permalink":"http://www.codec.wang/tags/%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86/"},{"name":"模板匹配","slug":"模板匹配","permalink":"http://www.codec.wang/tags/%E6%A8%A1%E6%9D%BF%E5%8C%B9%E9%85%8D/"}]},{"title":"Python+OpenCV教程15：直方图","slug":"Python-OpenCV教程15：直方图","date":"2017-12-23T09:48:30.000Z","updated":"2018-11-27T11:30:07.007Z","comments":true,"path":"opencv-python-histograms/","link":"","permalink":"http://www.codec.wang/opencv-python-histograms/","excerpt":"学习计算并绘制直方图，直方图均衡化等。","text":"学习计算并绘制直方图，直方图均衡化等。图片等可到源码处下载。 目标 计算并绘制直方图 （自适应）直方图均衡化 OpenCV函数：cv2.calcHist(), cv2.equalizeHist() 教程啥叫直方图直方图简单来说就是图像中每个像素值的个数统计，比如说一副灰度图中像素值为0的有多少个，1的有多少个……直方图是一种分析图片的手段： 在计算直方图之前，有几个术语先来了解一下： dims：要计算的通道数，对于灰度图dims=1，普通彩色图dims=3 range：要计算的像素值范围，一般为[0,256) bins：子区段数目，如果我们统计0255每个像素值，bins=256；如果划分区间，比如015, 1631…240255这样16个区间，bins=16 计算直方图OpenCV和Numpy中都提供了计算直方图的函数，我们对比下它们的性能。 OpenCV中直方图计算使用cv2.calcHist(images, channels, mask, histSize, ranges)计算，其中： 参数1：要计算的原图，以方括号的传入，如：[img] 参数2：类似前面提到的dims，灰度图写[0]就行，彩色图B/G/R分别传入[0]/[1]/[2] 参数3：要计算的区域，计算整幅图的话，写None 参数4：前面提到的bins 参数5：前面提到的range 123456import cv2import numpy as npimport matplotlib.pyplot as pltimg = cv2.imread('hist.jpg', 0)hist = cv2.calcHist([img], [0], None, [256], [0, 256]) # 性能：0.025288 s Numpy中直方图计算也可用Numpy的函数计算，其中ravel()函数将二维矩阵展平变成一维数组，之前有提到过： 1hist, bins = np.histogram(img.ravel(), 256, [0, 256]) # 性能：0.020628 s 经验之谈：Numpy中还有一种更高效的方式：（还记得怎么评估性能吗：番外篇：代码性能优化） 1hist = np.bincount(img.ravel(), minlength=256) # 性能：0.003163 s 计算出直方图之后，怎么把它画出来呢？ 绘制直方图其实Matplotlib自带了一个计算并绘制直方图的功能，不需要用到上面的函数： 12plt.hist(img.ravel(), 256, [0, 256])plt.show() 当然，也可以用前面计算出来的结果绘制： 12plt.plot(hist)plt.show() 从直方图上可以看到图片的大部分区域集中在150偏白的附近，这其实并不是很好的效果，下面我们来看看如何改善它。 使用OpenCV的画线功能也可以画直方图，不过太麻烦了，有兴趣的可以看下官方示例：hist.py。 直方图均衡化一副效果好的图像通常在直方图上的分布比较均匀，直方图均衡化就是用来改善图像的全局亮度和对比度。其实从观感上就可以发现，前面那幅图对比度不高，偏灰白。对均衡化算法感兴趣的同学可参考：维基百科：直方图均衡化 1equ = cv2.equalizeHist(img) OpenCV中用cv2.equalizeHist()实现均衡化。我们把两张图片并排显示，对比一下： 12cv2.imshow('equalization', np.hstack((img, equ))) # 并排显示cv2.waitKey(0) 可以看到均衡化后图片的亮度和对比度效果明显好于原图。 自适应均衡化不难看出来，直方图均衡化是应用于整幅图片的，会有什么问题呢？看下图： 很明显，因为全局调整亮度和对比度的原因，脸部太亮，大部分细节都丢失了。 自适应均衡化就是用来解决这一问题的：它在每一个小区域内（默认8×8）进行直方图均衡化。当然，如果有噪点的话，噪点会被放大，需要对小区域内的对比度进行了限制，所以这个算法全称叫：对比度受限的自适应直方图均衡化CLAHE(Contrast Limited Adaptive Histogram Equalization)。 123# 自适应均衡化，参数可选clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))cl1 = clahe.apply(img) 练习 cv2.calcHist()函数中的参数3是指要计算的区域(mask：目标区域白色，其余黑色)，编写一个只计算图片左上角200×200区域直方图的程序。 小结 直方图是一种分析图像的手段。 cv2.calcHist()和numpy.bincount()均可用来计算直方图，使用Matplotlib绘制直方图。 均衡化用来使图像的直方图分布更加均匀，提升亮度和对比度。 引用 本节源码 Histograms - 1 : Find, Plot, Analyze !!! Histograms - 2: Histogram Equalization 维基百科：直方图均衡化 维基百科：自适应直方图均衡化 Cambridge in Color website","categories":[{"name":"机器视觉","slug":"机器视觉","permalink":"http://www.codec.wang/categories/%E6%9C%BA%E5%99%A8%E8%A7%86%E8%A7%89/"}],"tags":[{"name":"OpenCV","slug":"OpenCV","permalink":"http://www.codec.wang/tags/OpenCV/"},{"name":"Python","slug":"Python","permalink":"http://www.codec.wang/tags/Python/"},{"name":"图像处理","slug":"图像处理","permalink":"http://www.codec.wang/tags/%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86/"},{"name":"直方图","slug":"直方图","permalink":"http://www.codec.wang/tags/%E7%9B%B4%E6%96%B9%E5%9B%BE/"}]},{"title":"Python+OpenCV教程14：轮廓特征","slug":"Python-OpenCV教程14：轮廓特征","date":"2017-12-20T10:46:19.000Z","updated":"2019-05-11T12:17:02.881Z","comments":true,"path":"opencv-python-contour-features/","link":"","permalink":"http://www.codec.wang/opencv-python-contour-features/","excerpt":"学习计算轮廓特征，如面积、周长、最小外接矩形等。","text":"学习计算轮廓特征，如面积、周长、最小外接矩形等。图片等可到源码处下载。 目标 计算物体的周长、面积、质心、最小外接矩形等 OpenCV函数：cv2.contourArea(), cv2.arcLength(), cv2.approxPolyDP() 等 教程在计算轮廓特征之前，我们先用上一节的代码把轮廓找到： 123456789import cv2import numpy as npimg = cv2.imread('handwriting.jpg', 0)_, thresh = cv2.threshold(img, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)image, contours, hierarchy = cv2.findContours(thresh, 3, 2)# 以数字3的轮廓为例cnt = contours[0] 为了便于绘制，我们创建出两幅彩色图，并把轮廓画在第一幅图上： 123img_color1 = cv2.cvtColor(image, cv2.COLOR_GRAY2BGR)img_color2 = np.copy(img_color1)cv2.drawContours(img_color1, [cnt], 0, (0, 0, 255), 2) 轮廓面积1area = cv2.contourArea(cnt) # 4386.5 注意轮廓特征计算的结果并不等同于像素点的个数，而是根据几何方法算出来的，所以有小数。 如果统计二值图中像素点个数，应尽量避免循环，可以使用cv2.countNonZero()，更加高效。 轮廓周长1perimeter = cv2.arcLength(cnt, True) # 585.7 参数2表示轮廓是否封闭，显然我们的轮廓是封闭的，所以是True。 图像矩矩可以理解为图像的各类几何特征，详情请参考：[Image Moments] 1M = cv2.moments(cnt) M中包含了很多轮廓的特征信息，比如M[‘m00’]表示轮廓面积，与前面cv2.contourArea()计算结果是一样的。质心也可以用它来算： 1cx, cy = M['m10'] / M['m00'], M['m01'] / M['m00'] # (205, 281) 外接矩形形状的外接矩形有两种，如下图，绿色的叫外接矩形，表示不考虑旋转并且能包含整个轮廓的矩形。蓝色的叫最小外接矩，考虑了旋转： 12x, y, w, h = cv2.boundingRect(cnt) # 外接矩形cv2.rectangle(img_color1, (x, y), (x + w, y + h), (0, 255, 0), 2) 123rect = cv2.minAreaRect(cnt) # 最小外接矩形box = np.int0(cv2.boxPoints(rect)) # 矩形的四个角点取整cv2.drawContours(img_color1, [box], 0, (255, 0, 0), 2) 其中np.int0(x)是把x取整的操作，比如377.93就会变成377，也可以用x.astype(np.int)。 最小外接圆外接圆跟外接矩形一样，找到一个能包围物体的最小圆： 123(x, y), radius = cv2.minEnclosingCircle(cnt)(x, y, radius) = np.int0((x, y, radius)) # 圆心和半径取整cv2.circle(img_color2, (x, y), radius, (0, 0, 255), 2) 拟合椭圆我们可以用得到的轮廓拟合出一个椭圆： 12ellipse = cv2.fitEllipse(cnt)cv2.ellipse(img_color2, ellipse, (255, 255, 0), 2) 形状匹配cv2.matchShapes()可以检测两个形状之间的相似度，返回值越小，越相似。先读入下面这张图片： 1234img = cv2.imread('shapes.jpg', 0)_, thresh = cv2.threshold(img, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)image, contours, hierarchy = cv2.findContours(thresh, 3, 2)img_color = cv2.cvtColor(thresh, cv2.COLOR_GRAY2BGR) # 用于绘制的彩色图 图中有3条轮廓，我们用A/B/C表示： 1234cnt_a, cnt_b, cnt_c = contours[0], contours[1], contours[2]print(cv2.matchShapes(cnt_b, cnt_b, 1, 0.0)) # 0.0print(cv2.matchShapes(cnt_b, cnt_c, 1, 0.0)) # 2.17e-05print(cv2.matchShapes(cnt_b, cnt_a, 1, 0.0)) # 0.418 可以看到BC相似程度比AB高很多，并且图形的旋转或缩放并没有影响。其中，参数3是匹配方法，详情可参考：ShapeMatchModes，参数4是OpenCV的预留参数，暂时没有实现，可以不用理会。 形状匹配是通过图像的Hu矩来实现的(cv2.HuMoments())，大家如果感兴趣，可以参考：Hu-Moments 练习 前面我们是对图片中的数字3进行轮廓特征计算的，大家换成数字1看看。 （选做）用形状匹配比较两个字母或数字（这相当于很简单的一个OCR噢）。 小结常用的轮廓特征： cv2.contourArea()算面积，cv2.arcLength()算周长，cv2.boundingRect()算外接矩。 cv2.minAreaRect()算最小外接矩，cv2.minEnclosingCircle()算最小外接圆。 cv2.matchShapes()进行形状匹配。 接口文档 cv2.contourArea() cv2.arcLength() cv2.moments() cv2.boundingRect() cv2.minAreaRect() cv2.minEnclosingCircle() cv2.fitEllipse() cv2.matchShapes() cv2.ShapeMatchModes 引用 本节源码 Contour Features Contours : More Functions","categories":[{"name":"机器视觉","slug":"机器视觉","permalink":"http://www.codec.wang/categories/%E6%9C%BA%E5%99%A8%E8%A7%86%E8%A7%89/"}],"tags":[{"name":"OpenCV","slug":"OpenCV","permalink":"http://www.codec.wang/tags/OpenCV/"},{"name":"Python","slug":"Python","permalink":"http://www.codec.wang/tags/Python/"},{"name":"图像处理","slug":"图像处理","permalink":"http://www.codec.wang/tags/%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86/"},{"name":"轮廓","slug":"轮廓","permalink":"http://www.codec.wang/tags/%E8%BD%AE%E5%BB%93/"}]},{"title":"Python+OpenCV教程番外篇11：凸包及更多轮廓特征","slug":"Python-OpenCV教程番外篇11：凸包及更多轮廓特征","date":"2017-12-20T05:41:11.000Z","updated":"2018-11-27T11:20:50.247Z","comments":true,"path":"opencv-python-extra-convex-hull/","link":"","permalink":"http://www.codec.wang/opencv-python-extra-convex-hull/","excerpt":"计算凸包及更多轮廓特征。","text":"计算凸包及更多轮廓特征。图片等可到源码处下载。 多边形逼近前面我们学习过最小外接矩和最小外接圆，那么可以用一个最小的多边形包围物体吗？当然可以： 123456789101112131415import cv2import numpy as np# 1.先找到轮廓img = cv2.imread('unregular.jpg', 0)_, thresh = cv2.threshold(img, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)image, contours, hierarchy = cv2.findContours(thresh, 3, 2)cnt = contours[0]# 2.进行多边形逼近，得到多边形的角点approx = cv2.approxPolyDP(cnt, 3, True)# 3.画出多边形image = cv2.cvtColor(image, cv2.COLOR_GRAY2BGR)cv2.polylines(image, [approx], True, (0, 255, 0), 2) 其中cv2.approxPolyDP()的参数2(epsilon)是一个距离值，表示多边形的轮廓接近实际轮廓的程度，值越小，越精确；参数3表示是否闭合。 凸包凸包跟多边形逼近很像，只不过它是物体最外层的”凸”多边形：集合A内连接任意两个点的直线都在A的内部，则称集合A是凸形的。如下图，红色的部分为手掌的凸包，双箭头部分表示凸缺陷(Convexity Defects)，凸缺陷常用来进行手势识别等： 123456789101112# 1.先找到轮廓img = cv2.imread('convex.jpg', 0)_, thresh = cv2.threshold(img, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)image, contours, hierarchy = cv2.findContours(thresh, 3, 2)cnt = contours[0]# 2.寻找凸包，得到凸包的角点hull = cv2.convexHull(cnt)# 3.绘制凸包image = cv2.cvtColor(image, cv2.COLOR_GRAY2BGR)cv2.polylines(image, [hull], True, (0, 255, 0), 2) 其中函数cv2.convexHull()有个可选参数returnPoints，默认是True，代表返回角点的x/y坐标；如果为False的话，表示返回轮廓中是凸包角点的索引，比如说： 1234print(hull[0]) # [[362 184]]（坐标）hull2 = cv2.convexHull(cnt, returnPoints=False)print(hull2[0]) # [510]（cnt中的索引）print(cnt[510]) # [[362 184]] 当使用cv2.convexityDefects()计算凸包缺陷时，returnPoints需为False，详情可参考：Convexity Defects 另外可以用下面的语句来判断轮廓是否是凸形的： 1print(cv2.isContourConvex(hull)) # True 点到轮廓距离cv2.pointPolygonTest()函数计算点到轮廓的最短距离（也就是垂线），又称多边形测试： 1dist = cv2.pointPolygonTest(cnt, (100, 100), True) # -3.53 其中参数3为True时表示计算距离值：点在轮廓外面值为负，点在轮廓上值为0，点在轮廓里面值为正；参数3为False时，只返回-1/0/1表示点相对轮廓的位置，不计算距离。 更多轮廓特征，如当量直径、平均强度等，我目前也没用到过，以后用到再写吧，感兴趣的可以参看：Contour Properties、Contours Hierarchy 引用 本节源码 Convexity Defects Contour Properties Contours Hierarchy","categories":[{"name":"机器视觉","slug":"机器视觉","permalink":"http://www.codec.wang/categories/%E6%9C%BA%E5%99%A8%E8%A7%86%E8%A7%89/"}],"tags":[{"name":"OpenCV","slug":"OpenCV","permalink":"http://www.codec.wang/tags/OpenCV/"},{"name":"Python","slug":"Python","permalink":"http://www.codec.wang/tags/Python/"},{"name":"图像处理","slug":"图像处理","permalink":"http://www.codec.wang/tags/%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86/"},{"name":"凸包","slug":"凸包","permalink":"http://www.codec.wang/tags/%E5%87%B8%E5%8C%85/"}]},{"title":"Python+OpenCV教程番外篇10：轮廓层级","slug":"Python-OpenCV教程番外篇10：轮廓层级","date":"2017-12-20T04:41:11.000Z","updated":"2018-11-27T10:56:12.299Z","comments":true,"path":"opencv-python-extra-contours-hierarchy/","link":"","permalink":"http://www.codec.wang/opencv-python-extra-contours-hierarchy/","excerpt":"了解轮廓间的层级关系。","text":"了解轮廓间的层级关系。图片等可到源码处下载。 前面我们使用cv2.findContours()寻找轮廓时，参数3表示轮廓的寻找方式(RetrievalModes)，当时我们传入的是cv2.RETR_TREE，它表示什么意思呢？另外，函数返回值hierarchy有什么用途呢？下面我们就来研究下这两个问题。 理解轮廓层级很多情况下，图像中的形状之间是有关联的，比如说下图： 图中总共有8条轮廓，2和2a分别表示外层和里层的轮廓，3和3a也是一样。从图中看得出来： 轮廓0/1/2是最外层的轮廓，我们可以说它们处于同一轮廓等级：0级 轮廓2a是轮廓2的子轮廓，反过来说2是2a的父轮廓，轮廓2a算一个等级：1级 同样3是2a的子轮廓，轮廓3处于一个等级：2级 类似的，3a是3的子轮廓，等等………… 这里面OpenCV关注的就是两个概念：同一轮廓等级和轮廓间的子属关系。 OpenCV中轮廓等级的表示如果我们打印出cv2.findContours()函数的返回值hierarchy，会发现它是一个包含4个值的数组：[Next, Previous, First Child, Parent] Next：与当前轮廓处于同一层级的下一条轮廓 举例来说，前面图中跟0处于同一层级的下一条轮廓是1，所以Next=1；同理，对轮廓1来说，Next=2；那么对于轮廓2呢？没有与它同一层级的下一条轮廓了，此时Next=-1。 Previous：与当前轮廓处于同一层级的上一条轮廓 跟前面一样，对于轮廓1来说，Previous=0；对于轮廓2，Previous=1；对于轮廓1，没有上一条轮廓了，所以Previous=-1。 First Child：当前轮廓的第一条子轮廓 比如对于轮廓2，第一条子轮廓就是轮廓2a，所以First Child=2a；对轮廓3a，First Child=4。 Parent：当前轮廓的父轮廓 比如2a的父轮廓是2，Parent=2；轮廓2没有父轮廓，所以Parent=-1。 下面我们通过代码验证一下： 12345678910111213import cv2# 1.读入图片img = cv2.imread('hierarchy.jpg')img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)_, thresh = cv2.threshold(img_gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)# 2.寻找轮廓image, contours, hierarchy = cv2.findContours(thresh, cv2.RETR_TREE, 2)# 3.绘制轮廓print(len(contours),hierarchy) # 8条cv2.drawContours(img, contours, -1, (0, 0, 255), 2) 经验之谈：OpenCV中找到的轮廓序号跟前面讲的不同噢，如下图： 现在既然我们了解了层级的概念，那么类似cv2.RETR_TREE的轮廓寻找方式又是啥意思呢？ 轮廓寻找方式OpenCV中有四种轮廓寻找方式RetrievalModes，下面分别来看下： 1. RETR_LIST这是最简单的一种寻找方式，它不建立轮廓间的子属关系，也就是所有轮廓都属于同一层级。这样，hierarchy中的后两个值[First Child, Parent]都为-1。比如同样的图，我们使用cv2.RETR_LIST来寻找轮廓： 1234567891011_, _, hierarchy = cv2.findContours(thresh, cv2.RETR_LIST, 2)print(hierarchy)# 结果如下[[[ 1 -1 -1 -1] [ 2 0 -1 -1] [ 3 1 -1 -1] [ 4 2 -1 -1] [ 5 3 -1 -1] [ 6 4 -1 -1] [ 7 5 -1 -1] [-1 6 -1 -1]]] 因为没有从属关系，所以轮廓0的下一条是1，1的下一条是2…… 经验之谈：如果你不需要轮廓层级信息的话，cv2.RETR_LIST更推荐使用，因为性能更好。 2. RETR_TREEcv2.RETR_TREE就是之前我们一直在使用的方式，它会完整建立轮廓的层级从属关系，前面已经详细说明过了。 3. RETR_EXTERNAL这种方式只寻找最高层级的轮廓，也就是它只会找到前面我们所说的3条0级轮廓： 1234567_, contours, hierarchy = cv2.findContours(thresh, cv2.RETR_EXTERNAL, 2)print(len(contours), hierarchy, sep='\\n')# 结果如下3[[[ 1 -1 -1 -1] [ 2 0 -1 -1] [-1 1 -1 -1]]] 4. RETR_CCOMP相比之下cv2.RETR_CCOMP比较难理解，但其实也很简单：它把所有的轮廓只分为2个层级，不是外层的就是里层的。结合代码和图片，我们来理解下： 1234567891011_, contours, hierarchy = cv2.findContours(thresh, cv2.RETR_CCOMP, 2)print(hierarchy)# 结果如下[[[ 1 -1 -1 -1] [ 2 0 -1 -1] [ 4 1 3 -1] [-1 -1 -1 2] [ 6 2 5 -1] [-1 -1 -1 4] [ 7 4 -1 -1] [-1 6 -1 -1]]] 注意：使用这个参数找到的轮廓序号与之前不同。 图中括号里面1代表外层轮廓，2代表里层轮廓。比如说对于轮廓2，Next就是4，Previous是1，它有里层的轮廓3，所以First Child=3，但因为只有两个层级，它本身就是外层轮廓，所以Parent=-1。大家可以针对其他的轮廓自己验证一下。 练习 如下图，找到3个圆环的内环，然后填充成(180,215,215)这种颜色： 引用 本节源码 Contours Hierarchy","categories":[{"name":"机器视觉","slug":"机器视觉","permalink":"http://www.codec.wang/categories/%E6%9C%BA%E5%99%A8%E8%A7%86%E8%A7%89/"}],"tags":[{"name":"OpenCV","slug":"OpenCV","permalink":"http://www.codec.wang/tags/OpenCV/"},{"name":"Python","slug":"Python","permalink":"http://www.codec.wang/tags/Python/"},{"name":"图像处理","slug":"图像处理","permalink":"http://www.codec.wang/tags/%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86/"},{"name":"轮廓层级","slug":"轮廓层级","permalink":"http://www.codec.wang/tags/%E8%BD%AE%E5%BB%93%E5%B1%82%E7%BA%A7/"}]},{"title":"Python+OpenCV教程13：轮廓","slug":"Python-OpenCV教程13：轮廓","date":"2017-12-20T01:44:23.000Z","updated":"2019-05-11T12:01:02.076Z","comments":true,"path":"opencv-python-contours/","link":"","permalink":"http://www.codec.wang/opencv-python-contours/","excerpt":"学习如何寻找并绘制轮廓。","text":"学习如何寻找并绘制轮廓。图片等可到源码处下载。 目标 了解轮廓概念 寻找并绘制轮廓 OpenCV函数：cv2.findContours(), cv2.drawContours() 教程啥叫轮廓轮廓是一系列相连的点组成的曲线，代表了物体的基本外形。 谈起轮廓不免想到边缘，它们确实很像。简单的说，轮廓是连续的，边缘并不全都连续（下图）。其实边缘主要是作为图像的特征使用，比如可以用边缘特征可以区分脸和手，而轮廓主要用来分析物体的形态，比如物体的周长和面积等，可以说边缘包括轮廓。 寻找轮廓的操作一般用于二值化图，所以通常会使用阈值分割或Canny边缘检测先得到二值图。 经验之谈：寻找轮廓是针对白色物体的，一定要保证物体是白色，而背景是黑色，不然很多人在寻找轮廓时会找到图片最外面的一个框。 寻找轮廓使用cv2.findContours()寻找轮廓： 12345678910import cv2img = cv2.imread('handwriting.jpg')img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)ret, thresh = cv2.threshold(img_gray, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)# 寻找二值化图中的轮廓image, contours, hierarchy = cv2.findContours( thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)print(len(contours)) # 结果应该为2 参数2：轮廓的查找方式，一般使用cv2.RETR_TREE，表示提取所有的轮廓并建立轮廓间的层级。更多请参考：RetrievalModes 参数3：轮廓的近似方法。比如对于一条直线，我们可以存储该直线的所有像素点，也可以只存储起点和终点。使用cv2.CHAIN_APPROX_SIMPLE就表示用尽可能少的像素点表示轮廓。更多请参考：ContourApproximationModes 简便起见，这两个参数也可以直接用真值3和2表示。 函数有3个返回值，image还是原来的二值化图片，hierarchy是轮廓间的层级关系（番外篇：轮廓层级），这两个暂时不用理会。我们主要看contours，它就是找到的轮廓了，以数组形式存储，记录了每条轮廓的所有像素点的坐标(x,y)。 绘制轮廓轮廓找出来后，为了方便观看，可以像前面图中那样用红色画出来：cv2.drawContours() 1cv2.drawContours(img, contours, -1, (0, 0, 255), 2) 其中参数2就是得到的contours，参数3表示要绘制哪一条轮廓，-1表示绘制所有轮廓，参数4是颜色（B/G/R通道，所以(0,0,255)表示红色），参数5是线宽，之前在绘制图形中介绍过。 经验之谈：很多人画图时明明用了彩色，但没有效果，请检查你是在哪个图上画，画在灰度图和二值图上显然是没有彩色的(⊙o⊙)。 一般情况下，我们会首先获得要操作的轮廓，再进行轮廓绘制及分析： 12cnt = contours[1]cv2.drawContours(img, [cnt], 0, (0, 0, 255), 2) 小结 轮廓特征非常有用，使用cv2.findContours()寻找轮廓，cv2.drawContours()绘制轮廓。 接口文档 cv2.findContours() cv2.RetrievalModes cv2.ContourApproximationModes cv2.drawContours() 引用 本节源码 Contours : Getting Started","categories":[{"name":"机器视觉","slug":"机器视觉","permalink":"http://www.codec.wang/categories/%E6%9C%BA%E5%99%A8%E8%A7%86%E8%A7%89/"}],"tags":[{"name":"OpenCV","slug":"OpenCV","permalink":"http://www.codec.wang/tags/OpenCV/"},{"name":"Python","slug":"Python","permalink":"http://www.codec.wang/tags/Python/"},{"name":"图像处理","slug":"图像处理","permalink":"http://www.codec.wang/tags/%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86/"},{"name":"轮廓","slug":"轮廓","permalink":"http://www.codec.wang/tags/%E8%BD%AE%E5%BB%93/"}]},{"title":"Python+OpenCV教程12：腐蚀与膨胀","slug":"Python-OpenCV教程12：腐蚀与膨胀","date":"2017-12-19T12:52:23.000Z","updated":"2019-05-11T11:57:48.488Z","comments":true,"path":"opencv-python-erode-and-dilate/","link":"","permalink":"http://www.codec.wang/opencv-python-erode-and-dilate/","excerpt":"学习常用形态学操作：腐蚀膨胀，开运算和闭运算。","text":"学习常用形态学操作：腐蚀膨胀，开运算和闭运算。图片等可到源码处下载。 目标 了解形态学操作的概念 学习膨胀、腐蚀、开运算和闭运算等形态学操作 OpenCV函数：cv2.erode(), cv2.dilate(), cv2.morphologyEx() 教程啥叫形态学操作形态学操作其实就是改变物体的形状，比如腐蚀就是”变瘦”，膨胀就是”变胖”，看下图就明白了： 经验之谈：形态学操作一般作用于二值化图，来连接相邻的元素或分离成独立的元素。腐蚀和膨胀是针对图片中的白色部分！ 腐蚀腐蚀的效果是把图片”变瘦”，其原理是在原图的小区域内取局部最小值。因为是二值化图，只有0和255，所以小区域内有一个是0该像素点就为0： 这样原图中边缘地方就会变成0，达到了瘦身目的（小胖福利(●ˇ∀ˇ●)） OpenCV中用cv2.erode()函数进行腐蚀，只需要指定核的大小就行： 123456import cv2import numpy as npimg = cv2.imread('j.bmp', 0)kernel = np.ones((5, 5), np.uint8)erosion = cv2.erode(img, kernel) # 腐蚀 这个核也叫结构元素，因为形态学操作其实也是应用卷积来实现的。结构元素可以是矩形/椭圆/十字形，可以用cv2.getStructuringElement()来生成不同形状的结构元素，比如： 123kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (5, 5)) # 矩形结构kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 5)) # 椭圆结构kernel = cv2.getStructuringElement(cv2.MORPH_CROSS, (5, 5)) # 十字形结构 膨胀膨胀与腐蚀相反，取的是局部最大值，效果是把图片”变胖”： 1dilation = cv2.dilate(img, kernel) # 膨胀 开/闭运算先腐蚀后膨胀叫开运算（因为先腐蚀会分开物体，这样容易记住），其作用是：分离物体，消除小区域。这类形态学操作用cv2.morphologyEx()函数实现： 1234kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (5, 5)) # 定义结构元素img = cv2.imread('j_noise_out.bmp', 0)opening = cv2.morphologyEx(img, cv2.MORPH_OPEN, kernel) # 开运算 闭运算则相反：先膨胀后腐蚀（先膨胀会使白色的部分扩张，以至于消除/“闭合”物体里面的小黑洞，所以叫闭运算） 12img = cv2.imread('j_noise_in.bmp', 0)closing = cv2.morphologyEx(img, cv2.MORPH_CLOSE, kernel) # 闭运算 经验之谈：很多人对开闭运算的作用不是很清楚（好吧，其实是比较容易混◑﹏◐），但看上图↑，不用怕：如果我们的目标物体外面有很多无关的小区域，就用开运算去除掉；如果物体内部有很多小黑洞，就用闭运算填充掉。 接下来的3种形态学操作并不常用，大家有兴趣可以看看（因为较短，没有做成番外篇）： 其他形态学操作 形态学梯度：膨胀图减去腐蚀图，dilation - erosion，这样会得到物体的轮廓： 12img = cv2.imread('school.bmp', 0)gradient = cv2.morphologyEx(img, cv2.MORPH_GRADIENT, kernel) 顶帽：原图减去开运算后的图：src - opening 1tophat = cv2.morphologyEx(img, cv2.MORPH_TOPHAT, kernel) 黑帽：闭运算后的图减去原图：closing - src 1blackhat = cv2.morphologyEx(img, cv2.MORPH_BLACKHAT, kernel) 小结 形态学操作就是改变物体的形状，如腐蚀使物体”变瘦”，膨胀使物体”变胖”。 先腐蚀后膨胀会分离物体，所以叫开运算，常用来去除小区域物体。 先膨胀后腐蚀会消除物体内的小洞，所以叫闭运算。开/闭理解了之后很容易记忆噢(⊙o⊙)。 接口文档 cv2.erode() cv2.getStructuringElement() cv2.dilate() cv2.MorphShapes cv2.morphologyEx() cv2.MorphTypes 引用 本节源码 Morphological Operations Computer Vision: Algorithms and Applications","categories":[{"name":"机器视觉","slug":"机器视觉","permalink":"http://www.codec.wang/categories/%E6%9C%BA%E5%99%A8%E8%A7%86%E8%A7%89/"}],"tags":[{"name":"OpenCV","slug":"OpenCV","permalink":"http://www.codec.wang/tags/OpenCV/"},{"name":"Python","slug":"Python","permalink":"http://www.codec.wang/tags/Python/"},{"name":"图像处理","slug":"图像处理","permalink":"http://www.codec.wang/tags/%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86/"},{"name":"腐蚀","slug":"腐蚀","permalink":"http://www.codec.wang/tags/%E8%85%90%E8%9A%80/"},{"name":"膨胀","slug":"膨胀","permalink":"http://www.codec.wang/tags/%E8%86%A8%E8%83%80/"},{"name":"形态学","slug":"形态学","permalink":"http://www.codec.wang/tags/%E5%BD%A2%E6%80%81%E5%AD%A6/"}]},{"title":"Python+OpenCV教程11：边缘检测","slug":"Python-OpenCV教程11：边缘检测","date":"2017-12-18T09:11:48.000Z","updated":"2019-05-11T11:52:20.398Z","comments":true,"path":"opencv-python-edge-detection/","link":"","permalink":"http://www.codec.wang/opencv-python-edge-detection/","excerpt":"学习使用Canny获取图像的边缘。","text":"学习使用Canny获取图像的边缘。图片等可到源码处下载。 Canny J . A Computational Approach To Edge Detection[J]. IEEE Transactions on Pattern Analysis and Machine Intelligence, 1986, PAMI-8(6):679-698. 目标 Canny边缘检测的简单概念 OpenCV函数：cv2.Canny() 教程Canny边缘检测方法常被誉为边缘检测的最优方法，废话不多说，先看个例子： 12345678import cv2import numpy as npimg = cv2.imread('handwriting.jpg', 0)edges = cv2.Canny(img, 30, 70) # canny边缘检测cv2.imshow('canny', np.hstack((img, edges)))cv2.waitKey(0) cv2.Canny()进行边缘检测，参数2、3表示最低、高阈值，下面来解释下具体原理。 经验之谈：之前我们用低通滤波的方式模糊了图片，那反过来，想得到物体的边缘，就需要用到高通滤波。推荐先阅读：番外篇：图像梯度。 Canny边缘检测Canny边缘提取的具体步骤如下： 1，使用5×5高斯滤波消除噪声： 边缘检测本身属于锐化操作，对噪点比较敏感，所以需要进行平滑处理。高斯滤波的具体内容参考前一篇：平滑图像$$K=\\frac{1}{256}\\left[ \\begin{matrix} 1 &amp; 4 &amp; 6 &amp; 4 &amp; 1 \\newline 4 &amp; 16 &amp; 24 &amp; 16 &amp; 4 \\newline 6 &amp; 24 &amp; 36 &amp; 24 &amp; 6 \\newline 4 &amp; 16 &amp; 24 &amp; 16 &amp; 4 \\newline 1 &amp; 4 &amp; 6 &amp; 4 &amp; 1 \\end{matrix} \\right]$$2，计算图像梯度的方向： 首先使用Sobel算子计算两个方向上的梯度$ G_x $和$ G_y $，然后算出梯度的方向：$$\\theta=\\arctan(\\frac{G_y}{G_x})$$保留这四个方向的梯度：0°/45°/90°/135°，有什么用呢？我们接着看。 3，取局部极大值： 梯度其实已经表示了轮廓，但为了进一步筛选，可以在上面的四个角度方向上再取局部极大值： 比如，A点在45°方向上大于B/C点，那就保留它，把B/C设置为0。 4，滞后阈值： 经过前面三步，就只剩下0和可能的边缘梯度值了，为了最终确定下来，需要设定高低阈值： 像素点的值大于最高阈值，那肯定是边缘（上图A） 同理像素值小于最低阈值，那肯定不是边缘 像素值介于两者之间，如果与高于最高阈值的点连接，也算边缘，所以上图中C算，B不算 Canny推荐的高低阈值比在2:1到3:1之间。 先阈值分割后检测其实很多情况下，阈值分割后再检测边缘，效果会更好： 12345_, thresh = cv2.threshold(img, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)edges = cv2.Canny(thresh, 30, 70)cv2.imshow('canny', np.hstack((img, thresh, edges)))cv2.waitKey(0) 代码中我用了番外篇：Otsu阈值法中的自动阈值分割，如果你不太了解，大可以使用传统的方法，不过如果是下面这种图片，推荐用Otsu阈值法。另外Python中某个值不用的话，就写个下划线’_’。 练习 （选做）如果你不太理解高低阈值的效果，创建两个滑动条来调节它们的值看看： 小结 Canny是用的最多的边缘检测算法，用cv2.Canny()实现。 接口文档 cv2.Canny() 引用 本节源码 Canny Edge Detection Canny 边缘检测 Canny J . A Computational Approach To Edge Detection[J]. IEEE Transactions on Pattern Analysis and Machine Intelligence, 1986, PAMI-8(6):679-698.","categories":[{"name":"机器视觉","slug":"机器视觉","permalink":"http://www.codec.wang/categories/%E6%9C%BA%E5%99%A8%E8%A7%86%E8%A7%89/"}],"tags":[{"name":"OpenCV","slug":"OpenCV","permalink":"http://www.codec.wang/tags/OpenCV/"},{"name":"Python","slug":"Python","permalink":"http://www.codec.wang/tags/Python/"},{"name":"图像处理","slug":"图像处理","permalink":"http://www.codec.wang/tags/%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86/"},{"name":"边缘","slug":"边缘","permalink":"http://www.codec.wang/tags/%E8%BE%B9%E7%BC%98/"},{"name":"Canny","slug":"Canny","permalink":"http://www.codec.wang/tags/Canny/"}]},{"title":"Python+OpenCV教程番外篇9：图像梯度","slug":"Python-OpenCV教程番外篇9：图像梯度","date":"2017-12-18T02:51:43.000Z","updated":"2018-11-26T14:09:07.566Z","comments":true,"path":"opencv-python-extra-image-gradients/","link":"","permalink":"http://www.codec.wang/opencv-python-extra-image-gradients/","excerpt":"了解图像梯度和边缘检测的相关概念。","text":"了解图像梯度和边缘检测的相关概念。图片等可到源码处下载。 还记得前面平滑图像中提到的滤波与模糊的区别吗？我们说低通滤波器是模糊，高通滤波器是锐化，这节我们就来看看高通滤波器。 图像梯度如果你还记得高数中用一阶导数来求极值的话，就很容易理解了：把图片想象成连续函数，因为边缘部分的像素值是与旁边像素明显有区别的，所以对图片局部求极值，就可以得到整幅图片的边缘信息了。不过图片是二维的离散函数，导数就变成了差分，这个差分就称为图像的梯度。 当然，大部分人应该是早忘记高数了(￣▽￣)”，所以看不懂的话，就把上面的解释划掉，我们重新从卷积的角度来看看。 垂直边缘提取滤波是应用卷积来实现的，卷积的关键就是卷积核，我们来考察下面这个卷积核： $$k1 = \\left[ \\begin{matrix} -1 &amp; 0 &amp; 1 \\newline -2 &amp; 0 &amp; 2 \\newline -1 &amp; 0 &amp; 1 \\end{matrix} \\right]$$ 这个核是用来提取图片中的垂直边缘的，怎么做到的呢？看下图： 当前列左右两侧的元素进行差分，由于边缘的值明显小于（或大于）周边像素，所以边缘的差分结果会明显不同，这样就提取出了垂直边缘。同理，把上面那个矩阵转置一下，就是提取水平边缘。这种差分操作就称为图像的梯度计算： $$k2 = \\left[ \\begin{matrix} -1 &amp; -2 &amp; -1 \\newline 0 &amp; 0 &amp; 0 \\newline 1 &amp; 2 &amp; 1 \\end{matrix} \\right]$$ 还记得滤波函数cv2.filter2D()吗？（番外篇：卷积基础）我们来手动实现上面的功能： 123456789101112img = cv2.imread('sudoku.jpg', 0)# 自己进行垂直边缘提取kernel = np.array([[-1, 0, 1], [-2, 0, 2], [-1, 0, 1]], dtype=np.float32)dst_v = cv2.filter2D(img, -1, kernel)# 自己进行水平边缘提取dst_h = cv2.filter2D(img, -1, kernel.T)# 横向并排对比显示cv2.imshow('edge', np.hstack((img, dst_v, dst_h)))cv2.waitKey(0) Sobel算子上面的这种差分方法就叫Sobel算子，它先在垂直方向计算梯度$ G_x=k_1×src $，再在水平方向计算梯度$ G_y=k_2×src $，最后求出总梯度：\\(G=\\sqrt{Gx^2+Gy^2}\\) 我们可以把前面的代码用Sobel算子更简单地实现： 12sobelx = cv2.Sobel(img, -1, 1, 0, ksize=3) # 只计算x方向sobely = cv2.Sobel(img, -1, 0, 1, ksize=3) # 只计算y方向 经验之谈：很多人疑问，Sobel算子的卷积核这几个值是怎么来的呢？事实上，并没有规定，你可以用你自己的。 比如，最初只利用领域间的原始差值来检测边缘的Prewitt算子： $$K = \\left[ \\begin{matrix} -1 &amp; 0 &amp; 1 \\newline -1 &amp; 0 &amp; 1 \\newline -1 &amp; 0 &amp; 1 \\end{matrix} \\right]$$ 还有比Sobel更好用的Scharr算子，大家可以了解下： $$K = \\left[ \\begin{matrix} -3 &amp; 0 &amp; 3 \\newline -10 &amp; 0 &amp; 10 \\newline -3 &amp; 0 &amp; 3 \\end{matrix} \\right]$$ 这些算法都是一阶边缘检测的代表，网上也有算子之间的对比资料，有兴趣的可参考引用。 Laplacian算子高数中用一阶导数求极值，在这些极值的地方，二阶导数为0，所以也可以通过求二阶导计算梯度：$ dst=\\frac{\\partial^2 f}{\\partial x^2}+\\frac{\\partial^2 f}{\\partial y^2} $ 一维的一阶和二阶差分公式分别为：$$\\frac{\\partial f}{\\partial x}=f(x+1)-f(x)$$ $$\\frac{\\partial^2 f}{\\partial x^2}=f(x+1)+f(x-1)-2f(x)$$ 提取前面的系数，那么一维的Laplacian滤波核是：$$K=\\left[ \\begin{matrix} 1 &amp; -2 &amp; 1 \\end{matrix} \\right]$$而对于二维函数f(x,y)，两个方向的二阶差分分别是： $$\\frac{\\partial^2 f}{\\partial x^2}=f(x+1,y)+f(x-1,y)-2f(x,y)$$ $$\\frac{\\partial^2 f}{\\partial y^2}=f(x,y+1)+f(x,y-1)-2f(x,y)$$ 合在一起就是： $$\\triangledown^2 f(x,y)=f(x+1,y)+f(x-1,y)+f(x,y+1)+f(x,y-1)-4f(x,y)$$ 同样提取前面的系数，那么二维的Laplacian滤波核就是： $$K = \\left[ \\begin{matrix} 0 &amp; 1 &amp; 0 \\newline 1 &amp; -4 &amp; 1 \\newline 0 &amp; 1 &amp; 0 \\end{matrix} \\right]$$ 这就是Laplacian算子的图像卷积模板，有些资料中在此基础上考虑斜对角情况，将卷积核拓展为： $$K = \\left[ \\begin{matrix} 1 &amp; 1 &amp; 1 \\newline 1 &amp; -8 &amp; 1 \\newline 1 &amp; 1 &amp; 1 \\end{matrix} \\right]$$ OpenCV中直接使用cv2.Laplacian()函数： 1laplacian = cv2.Laplacian(img, -1) # 使用Laplacian算子 Laplacian算子是二阶边缘检测的典型代表，一/二阶边缘检测各有优缺点，大家可自行了解。 练习 （选做）同志们有空补补高数姿势（知识）呗！(✿◕‿◕✿) 引用 本节源码 Image Gradients Sobel导数 维基百科：边缘检测 数字图像 - 边缘检测原理 - Sobel, Laplace, Canny算子","categories":[{"name":"机器视觉","slug":"机器视觉","permalink":"http://www.codec.wang/categories/%E6%9C%BA%E5%99%A8%E8%A7%86%E8%A7%89/"}],"tags":[{"name":"OpenCV","slug":"OpenCV","permalink":"http://www.codec.wang/tags/OpenCV/"},{"name":"Python","slug":"Python","permalink":"http://www.codec.wang/tags/Python/"},{"name":"图像处理","slug":"图像处理","permalink":"http://www.codec.wang/tags/%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86/"},{"name":"梯度","slug":"梯度","permalink":"http://www.codec.wang/tags/%E6%A2%AF%E5%BA%A6/"},{"name":"Sobel","slug":"Sobel","permalink":"http://www.codec.wang/tags/Sobel/"}]},{"title":"Python+OpenCV教程10：平滑图像","slug":"Python-OpenCV教程10：平滑图像","date":"2017-12-15T01:44:24.000Z","updated":"2019-05-11T11:51:01.293Z","comments":true,"path":"opencv-python-smoothing-images/","link":"","permalink":"http://www.codec.wang/opencv-python-smoothing-images/","excerpt":"学习模糊/平滑图像，消除噪点。","text":"学习模糊/平滑图像，消除噪点。图片等可到源码处下载。 目标 模糊/平滑图片来消除图片噪声 OpenCV函数：cv2.blur(), cv2.GaussianBlur(), cv2.medianBlur(), cv2.bilateralFilter() 教程滤波与模糊 推荐大家先阅读：番外篇：卷积基础(图片边框)，有助于理解卷积和滤波的概念。 关于滤波和模糊，很多人分不清，我来给大家理理（虽说如此，我后面也会混着用,,ԾㅂԾ,,）： 它们都属于卷积，不同滤波方法之间只是卷积核不同（对线性滤波而言） 低通滤波器是模糊，高通滤波器是锐化 低通滤波器就是允许低频信号通过，在图像中边缘和噪点都相当于高频部分，所以低通滤波器用于去除噪点、平滑和模糊图像。高通滤波器则反之，用来增强图像边缘，进行锐化处理。 常见噪声有椒盐噪声和高斯噪声，椒盐噪声可以理解为斑点，随机出现在图像中的黑点或白点；高斯噪声可以理解为拍摄图片时由于光照等原因造成的噪声。 均值滤波均值滤波是一种最简单的滤波处理，它取的是卷积核区域内元素的均值，用cv2.blur()实现，如3×3的卷积核： $$ kernel = \\frac{1}{9}\\left[ \\begin{matrix} 1 &amp; 1 &amp; 1 \\newline 1 &amp; 1 &amp; 1 \\newline 1 &amp; 1 &amp; 1 \\end{matrix} \\right]$$ 12img = cv2.imread('lena.jpg')blur = cv2.blur(img, (3, 3)) # 均值模糊 所有的滤波函数都有一个可选参数borderType，这个参数就是番外篇：卷积基础(图片边框)中所说的边框填充方式。 方框滤波方框滤波跟均值滤波很像，如3×3的滤波核如下： $$k = a\\left[ \\begin{matrix} 1 &amp; 1 &amp; 1 \\newline 1 &amp; 1 &amp; 1 \\newline 1 &amp; 1 &amp; 1 \\end{matrix} \\right]$$ 用cv2.boxFilter()函数实现，当可选参数normalize为True的时候，方框滤波就是均值滤波，上式中的a就等于1/9；normalize为False的时候，a=1，相当于求区域内的像素和。 12# 前面的均值滤波也可以用方框滤波实现：normalize=Trueblur = cv2.boxFilter(img, -1, (3, 3), normalize=True) 高斯滤波前面两种滤波方式，卷积核内的每个值都一样，也就是说图像区域中每个像素的权重也就一样。高斯滤波的卷积核权重并不相同：中间像素点权重最高，越远离中心的像素权重越小，来，数学时间( ╯□╰ )，还记得标准正态分布的曲线吗？ 显然这种处理元素间权值的方式更加合理一些。图像是2维的，所以我们需要使用2维的高斯函数，比如OpenCV中默认的3×3的高斯卷积核（具体原理和卷积核生成方式请参考文末的番外小篇）： $$k = \\left[ \\begin{matrix} 0.0625 &amp; 0.125 &amp; 0.0625 \\newline 0.125 &amp; 0.25 &amp; 0.125 \\newline 0.0625 &amp; 0.125 &amp; 0.0625 \\end{matrix} \\right]$$OpenCV中对应函数为cv2.GaussianBlur(src,ksize,sigmaX)： 1234img = cv2.imread('gaussian_noise.bmp')# 均值滤波vs高斯滤波blur = cv2.blur(img, (5, 5)) # 均值滤波gaussian = cv2.GaussianBlur(img, (5, 5), 1) # 高斯滤波 参数3 σx值越大，模糊效果越明显。高斯滤波相比均值滤波效率要慢，但可以有效消除高斯噪声，能保留更多的图像细节，所以经常被称为最有用的滤波器。均值滤波与高斯滤波的对比结果如下（均值滤波丢失的细节更多）： 中值滤波中值又叫中位数，是所有数排序后取中间的值。中值滤波就是用区域内的中值来代替本像素值，所以那种孤立的斑点，如0或255很容易消除掉，适用于去除椒盐噪声和斑点噪声。中值是一种非线性操作，效率相比前面几种线性滤波要慢。 比如下面这张斑点噪声图，用中值滤波显然更好： 1234img = cv2.imread('salt_noise.bmp', 0)# 均值滤波vs中值滤波blur = cv2.blur(img, (5, 5)) # 均值滤波median = cv2.medianBlur(img, 5) # 中值滤波 双边滤波模糊操作基本都会损失掉图像细节信息，尤其前面介绍的线性滤波器，图像的边缘信息很难保留下来。然而，边缘（edge）信息是图像中很重要的一个特征，所以这才有了双边滤波。用cv2.bilateralFilter()函数实现： 1234img = cv2.imread('lena.jpg')# 双边滤波vs高斯滤波gau = cv2.GaussianBlur(img, (5, 5), 0) # 高斯滤波blur = cv2.bilateralFilter(img, 9, 75, 75) # 双边滤波 可以看到，双边滤波明显保留了更多边缘信息。 番外小篇：高斯滤波卷积核要解释高斯滤波卷积核是如何生成的，需要先复习下概率论的知识（What？？又是数学( ╯□╰ )） 一维的高斯函数/正态分布$ X\\sim N(\\mu, \\sigma^2) $：$$G(x)=\\frac{1}{\\sqrt{2\\pi}\\sigma}exp(-\\frac{(x-\\mu)^2}{2\\sigma^2})$$当$ \\mu=0, \\sigma^2=1 $时，称为标准正态分布$ X\\sim N(0, 1) $：$$G(x)=\\frac{1}{\\sqrt{2\\pi}}exp(-\\frac{x^2}{2})$$二维X/Y相互独立的高斯函数：$$G(x,y)=\\frac{1}{2\\pi\\sigma_x\\sigma_y}exp(-\\frac{(x-\\mu_x)^2+(y-\\mu_y)^2}{2\\sigma_x\\sigma_y})=G(x)G(y)$$ 由上可知，二维高斯函数具有可分离性，所以OpenCV分两步计算二维高斯卷积，先水平再垂直，每个方向上都是一维的卷积。OpenCV中这个一维卷积的计算公式类似于上面的一维高斯函数：$$G(i)=\\alpha *exp(-\\frac{(i-\\frac{ksize-1}{2})^2}{2\\sigma^2})$$其中i=0…ksize-1，α是一个常数，也称为缩放因子，它使得\\(\\sum{G(i)}=1\\) 比如我们可以用cv2.getGaussianKernel(ksize,sigma)来生成一维卷积核： sigma&lt;=0时，sigma=0.3*((ksize-1)*0.5 - 1) + 0.8 sigma&gt;0时，sigma=sigma 12print(cv2.getGaussianKernel(3, 0))# 结果：[[0.25][0.5][0.25]] 生成之后，先进行三次的水平卷积：$$I×\\left[ \\begin{matrix} 0.25 &amp; 0.5 &amp; 0.25 \\newline 0.25 &amp; 0.5 &amp; 0.25 \\newline 0.25 &amp; 0.5 &amp; 0.25 \\end{matrix} \\right]$$然后再进行垂直的三次卷积：$$I×\\left[ \\begin{matrix} 0.25 &amp; 0.5 &amp; 0.25 \\newline 0.25 &amp; 0.5 &amp; 0.25 \\newline 0.25 &amp; 0.5 &amp; 0.25 \\end{matrix} \\right]×\\left[ \\begin{matrix} 0.25 &amp; 0.25 &amp; 0.25 \\newline 0.5 &amp; 0.5 &amp; 0.5 \\newline 0.25 &amp; 0.25 &amp; 0.25 \\end{matrix} \\right] =I×\\left[ \\begin{matrix} 0.0625 &amp; 0.125 &amp; 0.0625 \\newline 0.125 &amp; 0.25 &amp; 0.125 \\newline 0.0625 &amp; 0.125 &amp; 0.0625 \\end{matrix} \\right]$$这就是OpenCV中高斯卷积核的生成方式。其实，OpenCV源码中对小于7×7的核是直接计算好放在数组里面的，这样计算速度会快一点，感兴趣的可以看下源码：getGaussianKernel() 上面矩阵也可以写成：$$\\frac{1}{16}\\left[ \\begin{matrix} 1&amp; 2 &amp; 1 \\newline 2 &amp; 4 &amp; 2 \\newline 1 &amp; 2 &amp; 1 \\end{matrix} \\right]$$ 小结 在不知道用什么滤波器好的时候，优先高斯滤波cv2.GaussianBlur()，然后均值滤波cv2.blur()。 斑点和椒盐噪声优先使用中值滤波cv2.medianBlur()。 要去除噪点的同时尽可能保留更多的边缘信息，使用双边滤波cv2.bilateralFilter()。 线性滤波方式：均值滤波、方框滤波、高斯滤波（速度相对快）。 非线性滤波方式：中值滤波、双边滤波（速度相对慢）。 接口文档 cv2.blur() cv2.boxFilter() cv2.GaussianBlur() cv2.getGaussianKernel() cv2.medianBlur() cv2.bilateralFilter() 引用 本节源码 Smoothing Images 图像平滑处理","categories":[{"name":"机器视觉","slug":"机器视觉","permalink":"http://www.codec.wang/categories/%E6%9C%BA%E5%99%A8%E8%A7%86%E8%A7%89/"}],"tags":[{"name":"OpenCV","slug":"OpenCV","permalink":"http://www.codec.wang/tags/OpenCV/"},{"name":"Python","slug":"Python","permalink":"http://www.codec.wang/tags/Python/"},{"name":"图像处理","slug":"图像处理","permalink":"http://www.codec.wang/tags/%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86/"},{"name":"模糊","slug":"模糊","permalink":"http://www.codec.wang/tags/%E6%A8%A1%E7%B3%8A/"}]},{"title":"Python+OpenCV教程番外篇8：卷积基础(图片边框)","slug":"Python-OpenCV教程番外篇8：卷积基础-图片边框","date":"2017-12-14T08:27:45.000Z","updated":"2018-11-27T10:23:13.263Z","comments":true,"path":"opencv-python-extra-padding-and-convolution/","link":"","permalink":"http://www.codec.wang/opencv-python-extra-padding-and-convolution/","excerpt":"了解卷积/滤波的基础知识，给图片添加边框。","text":"了解卷积/滤波的基础知识，给图片添加边框。如果你已了解相关理论，请直接跳到添加边框部分。 卷积的概念其实很好理解，下面我就给大家做个最简单的解释，绝对轻松加愉快的辣o(￣▽￣)o 卷积什么是二维卷积呢？看下面一张图就一目了然： 卷积就是循环对图像跟一个核逐个元素相乘再求和得到另外一副图像的操作，比如结果图中第一个元素5是怎么算的呢？原图中3×3的区域与3×3的核逐个元素相乘再相加：$$5=1\\times1+2\\times0+1\\times0+0\\times0+1\\times0+1\\times0+3\\times0+0\\times0+2\\times2$$算完之后，整个框再往右移一步继续计算，横向计算完后，再往下移一步继续计算……网上有一副很经典的动态图，方便我们理解卷积： padding不难发现，前面我们用3×3的核对一副6×6的图像进行卷积，得到的是4×4的图，图片缩小了！那怎么办呢？我们可以把原图扩充一圈，再卷积，这个操作叫填充padding。 事实上，原图为n×n，卷积核为f×f，最终结果图大小为(n-f+1) × (n-f+1)。 那么扩展的这一层应该填充什么值呢？OpenCV中有好几种填充方式，都使用cv2.copyMakeBorder()函数实现，一起来看看。 添加边框cv2.copyMakeBorder()用来给图片添加边框，它有下面几个参数： src：要处理的原图 top, bottom, left, right：上下左右要扩展的像素数 borderType：边框类型，这个就是需要关注的填充方式，详情请参考：BorderTypes 其中默认方式和固定值方式最常用，我们详细说明一下： 固定值填充顾名思义，cv2.BORDER_CONSTANT这种方式就是边框都填充成一个固定的值，比如下面的程序都填充0： 123456img = cv2.imread('6_by_6.bmp', 0)print(img)# 固定值边框，统一都填充0也称为zero paddingcons = cv2.copyMakeBorder(img, 1, 1, 1, 1, cv2.BORDER_CONSTANT, value=0)print(cons) 默认边框类型默认边框cv2.BORDER_DEFAULT其实是取镜像对称的像素填充，比较拗口，一步步解释： 12default = cv2.copyMakeBorder(img, 1, 1, 1, 1, cv2.BORDER_DEFAULT)print(default) 首先进行上下填充，填充成与原图像边界对称的值，如下图： 同理再进行左右两边的填充，最后把四个顶点补充上就好了： 经验之谈：一般情况下默认方式更加合理，因为边界的像素值更加接近。具体应视场合而定。 OpenCV进行卷积OpenCV中用cv2.filter2D()实现卷积操作，比如我们的核是下面这样（3×3区域像素的和除以10）： $$M = \\frac{1}{10}\\left[ \\begin{matrix} 1 &amp; 1 &amp; 1 \\newline 1 &amp; 1 &amp; 1 \\newline 1 &amp; 1 &amp; 1 \\end{matrix} \\right] \\tag{3}$$ 12345img = cv2.imread('lena.jpg')# 定义卷积核kernel = np.ones((3, 3), np.float32) / 10# 卷积操作，-1表示通道数与原图相同dst = cv2.filter2D(img, -1, kernel) 可以看到这个核对图像进行了模糊处理，这是卷积的众多功能之一。当然卷积还有很多知识没有学到，后面我们再继续深入。 练习 尝试给”lena.jpg”添加几种不同的边框类型，对比下效果。 引用 本节源码 Basic Operations on Images 图像卷积与滤波的一些知识点","categories":[{"name":"机器视觉","slug":"机器视觉","permalink":"http://www.codec.wang/categories/%E6%9C%BA%E5%99%A8%E8%A7%86%E8%A7%89/"}],"tags":[{"name":"OpenCV","slug":"OpenCV","permalink":"http://www.codec.wang/tags/OpenCV/"},{"name":"Python","slug":"Python","permalink":"http://www.codec.wang/tags/Python/"},{"name":"图像处理","slug":"图像处理","permalink":"http://www.codec.wang/tags/%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86/"},{"name":"卷积","slug":"卷积","permalink":"http://www.codec.wang/tags/%E5%8D%B7%E7%A7%AF/"}]},{"title":"Python+OpenCV教程9：图像混合","slug":"Python-OpenCV教程9：图像混合","date":"2017-12-10T06:13:10.000Z","updated":"2019-05-08T03:39:10.332Z","comments":true,"path":"opencv-python-image-blending/","link":"","permalink":"http://www.codec.wang/opencv-python-image-blending/","excerpt":"学习图片间的数学运算，图像混合。","text":"学习图片间的数学运算，图像混合。图片等可到源码处下载。 目标 图片间的数学运算，如相加、按位运算等 OpenCV函数：cv2.add(), cv2.addWeighted(), cv2.bitwise_and() 教程 首先恭喜你已经完成了入门篇的学习噢，接下来我们学习一些OpenCV的基础内容，加油(ง •_•)ง 图片相加要叠加两张图片，可以用cv2.add()函数，相加两幅图片的形状（高度/宽度/通道数）必须相同。numpy中可以直接用res = img + img1相加，但这两者的结果并不相同： 1234x = np.uint8([250])y = np.uint8([10])print(cv2.add(x, y)) # 250+10 = 260 =&gt; 255print(x + y) # 250+10 = 260 % 256 = 4 如果是二值化图片（只有0和255两种值），两者结果是一样的（用numpy的方式更简便一些）。 图像混合图像混合cv2.addWeighted()也是一种图片相加的操作，只不过两幅图片的权重不一样，γ相当于一个修正值： $$dst = \\alpha\\times img1+\\beta\\times img2 + \\gamma$$ 123img1 = cv2.imread('lena_small.jpg')img2 = cv2.imread('opencv-logo-white.png')res = cv2.addWeighted(img1, 0.6, img2, 0.4, 0) 经验之谈：α和β都等于1时，就相当于图片相加。 按位操作按位操作包括按位与/或/非/异或操作，有什么用途呢？比如说我们要实现下图的效果： 如果将两幅图片直接相加会改变图片的颜色，如果用图像混合，则会改变图片的透明度，所以我们需要用按位操作。首先来了解一下掩膜（mask）的概念：掩膜是用一副二值化图片对另外一幅图片进行局部的遮挡，看下图就一目了然了： 所以我们的思路就是把原图中要放logo的区域抠出来，再把logo放进去就行了： 12345678910111213141516img1 = cv2.imread('lena.jpg')img2 = cv2.imread('opencv-logo-white.png')# 把logo放在左上角，所以我们只关心这一块区域rows, cols = img2.shape[:2]roi = img1[:rows, :cols]# 创建掩膜img2gray = cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY)ret, mask = cv2.threshold(img2gray, 10, 255, cv2.THRESH_BINARY)mask_inv = cv2.bitwise_not(mask)# 保留除logo外的背景img1_bg = cv2.bitwise_and(roi, roi, mask=mask_inv)dst = cv2.add(img1_bg, img2) # 进行融合img1[:rows, :cols] = dst # 融合后放在原图上 经验之谈：掩膜的概念在图像混合/叠加的场景下使用较多，可以多多练习噢！ 小结 cv2.add()用来叠加两幅图片，cv2.addWeighted()也是叠加两幅图片，但两幅图片的权重不一样。 cv2.bitwise_and(), cv2.bitwise_not(), cv2.bitwise_or(), cv2.bitwise_xor()分别执行按位与/或/非/异或运算。掩膜就是用来对图片进行全局或局部的遮挡。 接口文档 cv2.add() cv2.addWeighted() cv2.bitwise_and() cv2.bitwise_not() 引用 本节源码 掩膜 Arithmetic Operations on Images","categories":[{"name":"机器视觉","slug":"机器视觉","permalink":"http://www.codec.wang/categories/%E6%9C%BA%E5%99%A8%E8%A7%86%E8%A7%89/"}],"tags":[{"name":"OpenCV","slug":"OpenCV","permalink":"http://www.codec.wang/tags/OpenCV/"},{"name":"Python","slug":"Python","permalink":"http://www.codec.wang/tags/Python/"},{"name":"图像处理","slug":"图像处理","permalink":"http://www.codec.wang/tags/%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86/"},{"name":"图像混合","slug":"图像混合","permalink":"http://www.codec.wang/tags/%E5%9B%BE%E5%83%8F%E6%B7%B7%E5%90%88/"}]},{"title":"Python+OpenCV教程番外篇7：亮度与对比度","slug":"Python-OpenCV教程番外篇7：亮度与对比度","date":"2017-12-10T06:05:10.000Z","updated":"2018-11-26T07:48:31.783Z","comments":true,"path":"opencv-python-extra-contrast-brightness/","link":"","permalink":"http://www.codec.wang/opencv-python-extra-contrast-brightness/","excerpt":"学习如何调整图片的亮度和对比度。","text":"学习如何调整图片的亮度和对比度。图片等可到源码处下载。 亮度与对比度亮度调整是将图像像素的强度整体变大/变小，对比度调整指的是图像暗处的像素强度变低，亮出的变高，从而拓宽某个区域内的显示精度。 OpenCV中亮度和对比度应用这个公式来计算：$ g(x)=\\alpha f(x)+\\beta $，其中：α(&gt;0)、β常称为增益与偏置值，分别控制图片的对比度和亮度。 经验之谈：此处对α/β控制对比度和亮度有争议，具体请参考：OpenCV关于对比度和亮度的误解。 12345678910import cv2import numpy as npimg = cv2.imread('lena.jpg')# 此处需注意，请参考后面的解释res = np.uint8(np.clip((1.5 * img + 10), 0, 255))tmp = np.hstack((img, res)) # 两张图片横向合并（便于对比显示）cv2.imshow('image', tmp)cv2.waitKey(0) 还记得图像混合那一节中numpy对数据溢出的取模处理吗？250+10 = 260 =&gt; 260%256=4，它并不适用于我们的图像处理，所以用np.clip()函数将数据限定：a&lt;0 =&gt; a=0, a&gt;255 =&gt; a=255。 练习 创建两个滑动条分别调整对比度和亮度（对比度范围：00.3，亮度：0100）。提示：因为滑动条没有小数，所以可以设置为0~300，然后乘以0.01。 亮度/对比度用C++实现也很有趣，推荐阅读：OpenCV改变图像亮度和对比度以及优化。 引用 本节源码 numpy.clip() OpenCV关于对比度和亮度的误解 OpenCV改变图像亮度和对比度以及优化 Mat::convertTo","categories":[{"name":"机器视觉","slug":"机器视觉","permalink":"http://www.codec.wang/categories/%E6%9C%BA%E5%99%A8%E8%A7%86%E8%A7%89/"}],"tags":[{"name":"OpenCV","slug":"OpenCV","permalink":"http://www.codec.wang/tags/OpenCV/"},{"name":"Python","slug":"Python","permalink":"http://www.codec.wang/tags/Python/"},{"name":"图像处理","slug":"图像处理","permalink":"http://www.codec.wang/tags/%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86/"},{"name":"亮度","slug":"亮度","permalink":"http://www.codec.wang/tags/%E4%BA%AE%E5%BA%A6/"},{"name":"对比度","slug":"对比度","permalink":"http://www.codec.wang/tags/%E5%AF%B9%E6%AF%94%E5%BA%A6/"}]},{"title":"Python+OpenCV教程拓展挑战：PyQt编写GUI界面","slug":"Python-OpenCV教程挑战任务2：PyQt编写GUI界面","date":"2017-12-09T09:30:34.000Z","updated":"2018-12-02T13:37:44.709Z","comments":true,"path":"opencv-python-using-pyqt5-create-gui/","link":"","permalink":"http://www.codec.wang/opencv-python-using-pyqt5-create-gui/","excerpt":"拓展挑战：编写GUI图像处理应用程序。","text":"拓展挑战：编写GUI图像处理应用程序。 挑战内容前面我们学习的OpenCV内容都是运行在命令行中的，没有界面，所以本次的拓展挑战内容便是： 了解Python编写GUI界面的方法，使用PyQt5编写如下的图像处理应用程序，实现打开摄像头、捕获图片、读取本地图片、灰度化和Otsu自动阈值分割的功能。 挑战题不会做也木有关系，但请务必在自行尝试后，再看下面的解答噢，不然…我也没办法(￣▽￣)” 挑战解答简介 目前我们学的内容都是跑在命令行中的，并没有界面，那么”脚本语言”Python如何搭建GUI界面呢？ 其实Python支持多种图形界面库，如Tk(Tkinter)、wxPython、PyQt等，虽然Python自带Tkinter，无需额外安装包，但我更推荐使用PyQt，一是因为它完全基于Qt，跨平台，功能强大，有助于了解Qt的语法，二是Qt提供了Designer设计工具，界面设计上可以拖控件搞定，非常方便，大大节省时间。 最新版本：PyQt 5.x 官网（可能需要翻墙）：https://www.riverbankcomputing.com/software/pyqt/ 大家感兴趣的话，除去官网，下面是一些可参考的资源： Python Wiki: PyQt PyQt/Tutorials PyQt5 tutorial：英文原版 PyQt4 tutorial：中文版、英文原版 Qt5 Documentation 中文参考书：PyQt5快速开发与实战 基于Qt的Python IDE Eric 安装1pip install pyqt5 下载速度慢的话，可以到PyPI上下载离线版安装。另外我推荐使用Qt Designer来设计界面，如果你装的是Anaconda的话，就已经自带了designer.exe，例如我的是在：D:\\ProgramData\\Anaconda3\\Library\\bin\\，如果是普通的Python环境，则需要自行安装： 1pip install pyqt5-tools 安装完成后，designer.exe应该在Python安装目录下：xxx\\Lib\\site-packages\\pyqt5_tools\\。 可以使用下面的代码生成一个简单的界面： 1234567891011import sysfrom PyQt5.QtWidgets import QApplication, QWidgetif __name__ == '__main__': app = QApplication(sys.argv) window = QWidget() window.setWindowTitle('Hello World!') window.show() sys.exit(app.exec_()) 界面设计根据我们的挑战内容，解决思路是使用Qt Designer来设计界面，使用Python完成代码逻辑。打开designer.exe，会弹出创建新窗体的窗口，我们直接点击“create”： 界面的左侧是Qt的常用控件”Widget Box”，右侧有一个控件属性窗口”Property Editor”，其余暂时用不到。本例中我们只用到了”Push Button”控件和”Label”控件：最上面的三个Label控件用于显示图片，可以在属性窗口调整它的大小，我们统一调整到150×150： 另外，控件上显示的文字”text”属性和控件的名字”objectName”属性需要修改，便于显示和代码调用。可以按照下面我推荐的命名： 控件 显示内容text 控件名objectName PushButton 打开摄像头 btnOpenCamera PushButton 捕获图片 btnCapture PushButton 打开图片 btnReadImage PushButton 灰度化 btnGray PushButton 阈值分割(Otsu) btnThreshold Label 摄像头 labelCamera Label 捕获图 labelCapture Label 结果图 labelResult 这样大致界面就出来了，很简单： 按钮事件如果你之前有过一些GUI开发经验，比如MFC，WinForm等，就知道GUI是通过事件驱动的，什么意思呢？比如前面我们已经设计好了界面，接下来就需要实现”打开摄像头”到”阈值分割”这5个按钮的功能，也就是给每个按钮指定一个”函数”，逻辑代码写在这个函数里面。这种函数就称为事件，Qt中称为槽连接。 点击Designer工具栏的”Edit Signals/Slots”按钮，进入槽函数编辑界面，点击旁边的”Edit Widgets”可以恢复正常视图： 然后点击按钮并拖动，当产生类似于电路中的接地符号时释放鼠标，参看下面动图： 在弹出的配置窗口中，可以看到左侧是按钮的常用事件，我们选择点击事件”clicked()”，然后添加一个名为”btnOpenCamera_Clicked()”的槽函数： 重复上面的步骤，给五个按钮添加五个槽函数，最终结果如下： 到此，我们就完成了界面设计的所有工作，按下Ctrl+S保存当前窗口为.ui文件。.ui文件其实是按照XML格式标记的内容，可以用文本编辑器将.ui文件打开看看。 ui文件转py代码因为我们是用Designer工具设计出的界面，并不是用Python代码敲出来的，所以要想真正运行，需要使用pyuic5将ui文件转成py文件。pyuic5.exe默认在%\\Scripts\\下，比如我的是在：D:\\ProgramData\\Anaconda3\\Scripts\\。 打开cmd命令行，切换到ui文件的保存目录。Windows下有个小技巧，可以在目录的地址栏输入cmd，一步切换到当前目录： 然后执行这条指令： 1pyuic5 -o mainForm.py using_pyqt_create_ui.ui 如果出现pyuic5不是内部命令的错误，说明pyuic5的路径没有在环境变量里，添加下就好了。执行正常的话，就会生成mainForm.py文件，里面应该包含一个名为”Ui_MainWindow”的类。 编写逻辑代码 经验之谈：mainForm.py文件是根据ui文件生成的，也就是说重新生成会覆盖掉。所以为了使界面与逻辑分离，我们需要新建一个逻辑文件。 在同一工作目录下新建一个”mainEntry.py”的文件，存放逻辑代码。代码中的每部分我都写得比较独立，没有封装成函数，便于理解。代码看上去很长，但很简单，可以每个模块单独看，有几个需要注意的地方我做了注释： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126import sysimport cv2from PyQt5 import QtCore, QtGui, QtWidgetsfrom PyQt5.QtCore import *from PyQt5.QtGui import *from PyQt5.QtWidgets import QFileDialog, QMainWindowfrom mainForm import Ui_MainWindowclass PyQtMainEntry(QMainWindow, Ui_MainWindow): def __init__(self): super().__init__() self.setupUi(self) self.camera = cv2.VideoCapture(0) self.is_camera_opened = False # 摄像头有没有打开标记 # 定时器：30ms捕获一帧 self._timer = QtCore.QTimer(self) self._timer.timeout.connect(self._queryFrame) self._timer.setInterval(30) def btnOpenCamera_Clicked(self): ''' 打开和关闭摄像头 ''' self.is_camera_opened = ~self.is_camera_opened if self.is_camera_opened: self.btnOpenCamera.setText(\"关闭摄像头\") self._timer.start() else: self.btnOpenCamera.setText(\"打开摄像头\") self._timer.stop() def btnCapture_Clicked(self): ''' 捕获图片 ''' # 摄像头未打开，不执行任何操作 if not self.is_camera_opened: return self.captured = self.frame # 后面这几行代码几乎都一样，可以尝试封装成一个函数 rows, cols, channels = self.captured.shape bytesPerLine = channels * cols # Qt显示图片时，需要先转换成QImgage类型 QImg = QImage(self.captured.data, cols, rows, bytesPerLine, QImage.Format_RGB888) self.labelCapture.setPixmap(QPixmap.fromImage(QImg).scaled( self.labelCapture.size(), Qt.KeepAspectRatio, Qt.SmoothTransformation)) def btnReadImage_Clicked(self): ''' 从本地读取图片 ''' # 打开文件选取对话框 filename, _ = QFileDialog.getOpenFileName(self, '打开图片') if filename: self.captured = cv2.imread(str(filename)) # OpenCV图像以BGR通道存储，显示时需要从BGR转到RGB self.captured = cv2.cvtColor(self.captured, cv2.COLOR_BGR2RGB) rows, cols, channels = self.captured.shape bytesPerLine = channels * cols QImg = QImage(self.captured.data, cols, rows, bytesPerLine, QImage.Format_RGB888) self.labelCapture.setPixmap(QPixmap.fromImage(QImg).scaled( self.labelCapture.size(), Qt.KeepAspectRatio, Qt.SmoothTransformation)) def btnGray_Clicked(self): ''' 灰度化 ''' # 如果没有捕获图片，则不执行操作 if not hasattr(self, \"captured\"): return self.cpatured = cv2.cvtColor(self.captured, cv2.COLOR_RGB2GRAY) rows, columns = self.cpatured.shape bytesPerLine = columns # 灰度图是单通道，所以需要用Format_Indexed8 QImg = QImage(self.cpatured.data, columns, rows, bytesPerLine, QImage.Format_Indexed8) self.labelResult.setPixmap(QPixmap.fromImage(QImg).scaled( self.labelResult.size(), Qt.KeepAspectRatio, Qt.SmoothTransformation)) def btnThreshold_Clicked(self): ''' Otsu自动阈值分割 ''' if not hasattr(self, \"captured\"): return _, self.cpatured = cv2.threshold( self.cpatured, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU) rows, columns = self.cpatured.shape bytesPerLine = columns # 阈值分割图也是单通道，也需要用Format_Indexed8 QImg = QImage(self.cpatured.data, columns, rows, bytesPerLine, QImage.Format_Indexed8) self.labelResult.setPixmap(QPixmap.fromImage(QImg).scaled( self.labelResult.size(), Qt.KeepAspectRatio, Qt.SmoothTransformation)) @QtCore.pyqtSlot() def _queryFrame(self): ''' 循环捕获图片 ''' ret, self.frame = self.camera.read() img_rows, img_cols, channels = self.frame.shape bytesPerLine = channels * img_cols cv2.cvtColor(self.frame, cv2.COLOR_BGR2RGB, self.frame) QImg = QImage(self.frame.data, img_cols, img_rows, bytesPerLine, QImage.Format_RGB888) self.labelCamera.setPixmap(QPixmap.fromImage(QImg).scaled( self.labelCamera.size(), Qt.KeepAspectRatio, Qt.SmoothTransformation))if __name__ == \"__main__\": app = QtWidgets.QApplication(sys.argv) window = PyQtMainEntry() window.show() sys.exit(app.exec_()) 本文只是抛砖引玉，介绍了PyQt5的简单使用，想要深入学习，可以参考本文开头的参考资料噢(●ˇ∀ˇ●) 引用 本节源码","categories":[{"name":"机器视觉","slug":"机器视觉","permalink":"http://www.codec.wang/categories/%E6%9C%BA%E5%99%A8%E8%A7%86%E8%A7%89/"}],"tags":[{"name":"OpenCV","slug":"OpenCV","permalink":"http://www.codec.wang/tags/OpenCV/"},{"name":"Python","slug":"Python","permalink":"http://www.codec.wang/tags/Python/"},{"name":"图像处理","slug":"图像处理","permalink":"http://www.codec.wang/tags/%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86/"},{"name":"PyQt","slug":"PyQt","permalink":"http://www.codec.wang/tags/PyQt/"}]},{"title":"Python+OpenCV教程挑战任务：画动态时钟","slug":"Python-OpenCV教程挑战任务1：画动态时钟","date":"2017-12-09T09:29:34.000Z","updated":"2018-12-02T13:11:45.117Z","comments":true,"path":"opencv-python-clock-drawing/","link":"","permalink":"http://www.codec.wang/opencv-python-clock-drawing/","excerpt":"挑战任务：使用OpenCV绘制一个随系统时间动态变化的时钟。","text":"挑战任务：使用OpenCV绘制一个随系统时间动态变化的时钟。 挑战内容 完成如下图所展示的动态时钟，时钟需随系统时间变化，中间显示当前日期。 其实本次任务涉及的OpenCV知识并不多，但有助于提升大家的编程实践能力。 挑战题不会做也木有关系，但请务必在自行尝试后，再看下面的解答噢，不然…我也没办法(￣▽￣)” 挑战解答方案本次挑战任务旨在提升大家的动手实践能力，解决实际问题，所以我们得先有个解题思路和方案。观察下常见的时钟表盘： 整个表盘其实只有3根表针在动，所以可以先画出静态表盘，然后获取系统当前时间，根据时间实时动态绘制3根表针就解决了。 绘制表盘表盘上只有60条分/秒刻线和12条小时刻线，当然还有表盘的外部轮廓圆，也就是重点在如何画72根线。先把简单的圆画出来： 123456789101112131415import cv2import mathimport datetimeimport numpy as npmargin = 5 # 上下左右边距radius = 220 # 圆的半径center = (center_x, center_y) = (225, 225) # 圆心# 1. 新建一个画板并填充成白色img = np.zeros((450, 450, 3), np.uint8)img[:] = (255, 255, 255)# 2. 画出圆盘cv2.circle(img, center, radius, (0, 0, 0), thickness=5) 前面我们使用OpenCV画直线的时候，需知道直线的起点和终点坐标，那么画72根线就变成了获取72组坐标。 在平面坐标系下，已知半径和角度的话，A点的坐标可以表示为：$$\\begin{matrix} x=r\\times \\cos\\alpha \\newline y=r\\times \\sin\\alpha\\end{matrix}$$ 先只考虑将坐标系原点移动到左上角，角度依然是平面坐标系中的逆时针计算，那么新坐标是： $$\\begin{matrix} x=r+r\\times \\cos\\alpha \\newline y=r+r\\times \\sin\\alpha\\end{matrix}$$ 对于60条分/秒刻线，刻线间的夹角是360°/60=6°，对于小时刻线，角度是360°/12=30°，这样就得到了72组起点坐标，那怎么得到终点坐标呢？其实同样的原理，用一个同心的小圆来计算得到B点： 通过A/B两点就可以画出直线： 123456789101112131415161718192021222324pt1 = []# 3. 画出60条秒和分钟的刻线for i in range(60): # 最外部圆，计算A点 x1 = center_x+(radius-margin)*math.cos(i*6*np.pi/180.0) y1 = center_y+(radius-margin)*math.sin(i*6*np.pi/180.0) pt1.append((int(x1), int(y1))) # 同心小圆，计算B点 x2 = center_x+(radius-15)*math.cos(i*6*np.pi/180.0) y2 = center_y+(radius-15)*math.sin(i*6*np.pi/180.0) cv2.line(img, pt1[i], (int(x2), int(y2)), (0, 0, 0), thickness=2)# 4. 画出12条小时的刻线for i in range(12): # 12条小时刻线应该更长一点 x = center_x+(radius-25)*math.cos(i*30*np.pi/180.0) y = center_y+(radius-25)*math.sin(i*30*np.pi/180.0) # 这里用到了前面的pt1 cv2.line(img, pt1[i*5], (int(x), int(y)), (0, 0, 0), thickness=5)# 到这里基本的表盘图就已经画出来了 角度换算接下来算是一个小难点，首先时钟的起始坐标在正常二维坐标系的90°方向，其次时钟跟图像一样，都是顺时针计算角度的，所以三者需要统一下： 因为角度是完全对称的，顺逆时针没有影响，所以平面坐标系完全不用理会，放在这里只是便于大家理解。对于时钟坐标和图像坐标，时钟0的0°对应图像的270°，时钟15的90°对应图像的360°，时钟30的180°对应图像的450°（360°+90°）… 所以两者之间的关系便是： 12计算角度 &#x3D; 时钟角度+270°计算角度 &#x3D; 计算角度 if 计算角度&lt;&#x3D;360° else 计算角度-360° 同步时间Python中如何获取当前时间和添加日期文字都比较简单，看代码就行，我就不解释了。代码中角度计算我换了一种方式，其实是一样的，看你能不能看懂(●ˇ∀ˇ●)： 1234567891011121314151617181920212223242526272829303132333435while(1): # 不断拷贝表盘图，才能更新绘制，不然会重叠在一起 temp = np.copy(img) # 5. 获取系统时间，画出动态的时-分-秒三条刻线 now_time = datetime.datetime.now() hour, minute, second = now_time.hour, now_time.minute, now_time.second # 画秒刻线 # OpenCV中的角度是顺时针计算的，所以需要转换下 sec_angle = second*6+270 if second &lt;= 15 else (second-15)*6 sec_x = center_x+(radius-margin)*math.cos(sec_angle*np.pi/180.0) sec_y = center_y+(radius-margin)*math.sin(sec_angle*np.pi/180.0) cv2.line(temp, center, (int(sec_x), int(sec_y)), (203, 222, 166), 2) # 画分刻线 min_angle = minute*6+270 if minute &lt;= 15 else (minute-15)*6 min_x = center_x+(radius-35)*math.cos(min_angle*np.pi/180.0) min_y = center_y+(radius-35)*math.sin(min_angle*np.pi/180.0) cv2.line(temp, center, (int(min_x), int(min_y)), (186, 199, 137), 8) # 画时刻线 hour_angle = hour*30+270 if hour &lt;= 3 else (hour-3)*30 hour_x = center_x+(radius-65)*math.cos(hour_angle*np.pi/180.0) hour_y = center_y+(radius-65)*math.sin(hour_angle*np.pi/180.0) cv2.line(temp, center, (int(hour_x), int(hour_y)), (169, 198, 26), 15) # 6. 添加当前日期文字 font = cv2.FONT_HERSHEY_SIMPLEX time_str = now_time.strftime(\"%d/%m/%Y\") cv2.putText(img, time_str, (135, 275), font, 1, (0, 0, 0), 2) cv2.imshow('clocking', temp) if cv2.waitKey(1) == 27: # 按下ESC键退出 break 本此挑战旨在锻炼一步步解决实际问题的思路（虽然有点数学知识(￣▽￣)”），大家再接再厉噢！ 引用 本节源码","categories":[{"name":"机器视觉","slug":"机器视觉","permalink":"http://www.codec.wang/categories/%E6%9C%BA%E5%99%A8%E8%A7%86%E8%A7%89/"}],"tags":[{"name":"OpenCV","slug":"OpenCV","permalink":"http://www.codec.wang/tags/OpenCV/"},{"name":"Python","slug":"Python","permalink":"http://www.codec.wang/tags/Python/"},{"name":"图像处理","slug":"图像处理","permalink":"http://www.codec.wang/tags/%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86/"},{"name":"PyQt","slug":"PyQt","permalink":"http://www.codec.wang/tags/PyQt/"}]},{"title":"Python+OpenCV教程番外篇6：鼠标绘图","slug":"Python-OpenCV教程番外篇6：鼠标绘图","date":"2017-12-09T09:28:34.000Z","updated":"2018-11-26T06:57:25.327Z","comments":true,"path":"opencv-python-extra-drawing-with-mouse/","link":"","permalink":"http://www.codec.wang/opencv-python-extra-drawing-with-mouse/","excerpt":"学习如何用鼠标实时绘图。","text":"学习如何用鼠标实时绘图。图片等可到源码处下载。 目标 捕获鼠标事件 OpenCV函数：cv2.setMouseCallback() 教程知道鼠标在哪儿OpenCV中，我们需要创建一个鼠标的回调函数来获取鼠标当前的位置、当前的事件如左键按下/左键释放或是右键单击等等，然后执行相应的功能。 使用cv2.setMouseCallback()来创建鼠标的回调函数，比如我们在左键单击的时候，打印出当前鼠标的位置： 12345678910111213141516171819import cv2import numpy as np# 鼠标的回调函数def mouse_event(event, x, y, flags, param): # 通过event判断具体是什么事件，这里是左键按下 if event == cv2.EVENT_LBUTTONDOWN: print((x, y))img = np.zeros((512, 512, 3), np.uint8)cv2.namedWindow('image')# 定义鼠标的回调函数cv2.setMouseCallback('image', mouse_event)while(True): cv2.imshow('image', img) # 按下ESC键退出 if cv2.waitKey(20) == 27: break 上面的代码先定义鼠标的回调函数mouse_event()，然后在回调函数中判断是否是左键单击事件 EVENT_LBUTTONDOWN，是的话就打印出坐标。需要注意的是，回调函数的参数格式是固定的，不要随意更改。 那除了左键单击之外，还有哪些事件呢？可以用下面的代码打印出来： 123# 获取所有的事件events = [i for i in dir(cv2) if 'EVENT' in i]print(events) 综合实例现在我们来实现一个综合的例子，这个实例会帮助你理解图像交互的一些思想： 在图像上用鼠标画图，可以画圆或矩形，按m键在两种模式下切换。左键按下时开始画图，移动到哪儿画到哪儿，左键释放时结束画图。听上去很复杂，是吗？一步步来看： 用鼠标画图：需要定义鼠标的回调函数mouse_event 画圆或矩形：需要定义一个画图的模式mode 左键单击、移动、释放：需要捕获三个不同的事件 开始画图，结束画图：需要定义一个画图的标记位drawing 好，开始coding吧： 1234567891011121314151617181920212223242526272829303132333435363738394041import cv2import numpy as npdrawing = False # 是否开始画图mode = True # True：画矩形，False：画圆start = (-1, -1)def mouse_event(event, x, y, flags, param): global start, drawing, mode # 左键按下：开始画图 if event == cv2.EVENT_LBUTTONDOWN: drawing = True start = (x, y) # 鼠标移动，画图 elif event == cv2.EVENT_MOUSEMOVE: if drawing: if mode: cv2.rectangle(img, start, (x, y), (0, 255, 0), 1) else: cv2.circle(img, (x, y), 5, (0, 0, 255), -1) # 左键释放：结束画图 elif event == cv2.EVENT_LBUTTONUP: drawing = False if mode: cv2.rectangle(img, start, (x, y), (0, 255, 0), 1) else: cv2.circle(img, (x, y), 5, (0, 0, 255), -1)img = np.zeros((512, 512, 3), np.uint8)cv2.namedWindow('image')cv2.setMouseCallback('image', mouse_event)while(True): cv2.imshow('image', img) # 按下m切换模式 if cv2.waitKey(1) == ord('m'): mode = not mode elif cv2.waitKey(1) == 27: break 效果应该如下图所示： 小结 要用鼠标绘图，需要用cv2.setMouseCallback()定义回调函数，然后在回调函数中根据不同的event事件，执行不同的功能。 练习1.（选做）实现用鼠标画矩形，跟实例差不多，但只实时画一个，类似下面动图： 2.（选做）做一个在白色面板上绘图的简单程序，可用滑动条调整颜色和笔刷大小。 引用 本节源码 Mouse as a Paint-Brush","categories":[{"name":"机器视觉","slug":"机器视觉","permalink":"http://www.codec.wang/categories/%E6%9C%BA%E5%99%A8%E8%A7%86%E8%A7%89/"}],"tags":[{"name":"OpenCV","slug":"OpenCV","permalink":"http://www.codec.wang/tags/OpenCV/"},{"name":"Python","slug":"Python","permalink":"http://www.codec.wang/tags/Python/"},{"name":"图像处理","slug":"图像处理","permalink":"http://www.codec.wang/tags/%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86/"},{"name":"绘图","slug":"绘图","permalink":"http://www.codec.wang/tags/%E7%BB%98%E5%9B%BE/"}]},{"title":"Python+OpenCV教程8：绘图功能","slug":"Python-OpenCV教程8：绘图功能","date":"2017-12-09T03:29:48.000Z","updated":"2019-05-08T03:34:27.476Z","comments":true,"path":"opencv-python-drawing-function/","link":"","permalink":"http://www.codec.wang/opencv-python-drawing-function/","excerpt":"学习画线、圆和矩形等多种几何形状，给图片添加文字。","text":"学习画线、圆和矩形等多种几何形状，给图片添加文字。图片等可到源码处下载。 目标 绘制各种几何形状、添加文字 OpenCV函数：cv2.line(), cv2.circle(), cv2.rectangle(), cv2.ellipse(), cv2.putText() 教程参数说明绘制形状的函数有一些共同的参数，提前在此说明一下： img：要绘制形状的图片 color：绘制的颜色 彩色图就传入BGR的一组值，如蓝色就是(255,0,0) 灰度图，传入一个灰度值就行 thickness：线宽，默认为1；对于矩形/圆之类的封闭形状而言，传入-1表示填充形状 需要导入的模块和显示图片的通用代码： 123456import cv2import numpy as npimport matplotlib.pyplot as pltcv2.imshow('img', img)cv2.waitKey(0) 上图就是本教程绘制的最终效果，下面一步步来看： 画线画直线只需指定起点和终点的坐标就行： 1234# 创建一副黑色的图片img = np.zeros((512, 512, 3), np.uint8)# 画一条线宽为5的蓝色直线，参数2：起点，参数3：终点cv2.line(img, (0, 0), (512, 512), (255, 0, 0), 5) 经验之谈：所有绘图函数均会直接影响原图片，这点要注意。 画矩形画矩形需要知道左上角和右下角的坐标： 12# 画一个绿色边框的矩形，参数2：左上角坐标，参数3：右下角坐标cv2.rectangle(img, (384, 0), (510, 128), (0, 255, 0), 3) 画圆画圆需要指定圆心和半径，注意下面的例子中线宽=-1代表填充： 12# 画一个填充红色的圆，参数2：圆心坐标，参数3：半径cv2.circle(img, (447, 63), 63, (0, 0, 255), -1) 画椭圆画椭圆需要的参数比较多，请对照后面的代码理解这几个参数： 参数2：椭圆中心(x,y) 参数3：x/y轴的长度 参数4：angle—椭圆的旋转角度 参数5：startAngle—椭圆的起始角度 参数6：endAngle—椭圆的结束角度 经验之谈：OpenCV中原点在左上角，所以这里的角度是以顺时针方向计算的。 12# 在图中心画一个填充的半圆cv2.ellipse(img, (256, 256), (100, 50), 0, 0, 180, (255, 0, 0), -1) 画多边形画多边形需要指定一系列多边形的顶点坐标，相当于从第一个点到第二个点画直线，再从第二个点到第三个点画直线…. OpenCV中需要先将多边形的顶点坐标需要变成顶点数×1×2维的矩阵，再来绘制： 12345# 定义四个顶点坐标pts = np.array([[10, 5], [50, 10], [70, 20], [20, 30]], np.int32)# 顶点个数：4，矩阵变成4*1*2维pts = pts.reshape((-1, 1, 2))cv2.polylines(img, [pts], True, (0, 255, 255)) cv2.polylines()的参数3如果是False的话，多边形就不闭合。 经验之谈：如果需要绘制多条直线，使用cv2.polylines()要比cv2.line()高效很多，例如： 12345# 使用cv2.polylines()画多条直线line1 = np.array([[100, 20], [300, 20]], np.int32).reshape((-1, 1, 2))line2 = np.array([[100, 60], [300, 60]], np.int32).reshape((-1, 1, 2))line3 = np.array([[100, 100], [300, 100]], np.int32).reshape((-1, 1, 2))cv2.polylines(img, [line1, line2, line3], True, (0, 255, 255)) 添加文字使用cv2.putText()添加文字，它的参数也比较多，同样请对照后面的代码理解这几个参数： 参数2：要添加的文本 参数3：文字的起始坐标（左下角为起点） 参数4：字体 参数5：文字大小（缩放比例） 1234# 添加文字font = cv2.FONT_HERSHEY_SIMPLEXcv2.putText(img, 'ex2tron', (10, 500), font, 4, (255, 255, 255), 2, lineType=cv2.LINE_AA) 字体可参考：HersheyFonts。另外，这里有个线型lineType参数，LINE_AA表示抗锯齿线型，具体可见LineTypes 小结 cv2.line()画直线，cv2.circle()画圆，cv2.rectangle()画矩形，cv2.ellipse()画椭圆，cv2.polylines()画多边形，cv2.putText()添加文字。 画多条直线时，cv2.polylines()要比cv2.line()高效很多。 练习 你能用已学的绘图功能画出OpenCV的logo吗？(提示：椭圆和圆) 接口文档 cv2.line() cv2.circle() cv2.rectangle() cv2.ellipse() cv2.putText() cv2.polylines() 引用 本节源码 LineTypes Drawing Functions in OpenCV","categories":[{"name":"机器视觉","slug":"机器视觉","permalink":"http://www.codec.wang/categories/%E6%9C%BA%E5%99%A8%E8%A7%86%E8%A7%89/"}],"tags":[{"name":"OpenCV","slug":"OpenCV","permalink":"http://www.codec.wang/tags/OpenCV/"},{"name":"Python","slug":"Python","permalink":"http://www.codec.wang/tags/Python/"},{"name":"图像处理","slug":"图像处理","permalink":"http://www.codec.wang/tags/%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86/"},{"name":"绘图","slug":"绘图","permalink":"http://www.codec.wang/tags/%E7%BB%98%E5%9B%BE/"}]},{"title":"Python-OpenCV教程番外篇5：仿射变换与透视变换","slug":"Python-OpenCV教程番外篇5：仿射变换与透视变换","date":"2017-12-08T07:36:53.000Z","updated":"2018-11-26T12:06:04.508Z","comments":true,"path":"opencv-python-extra-warpaffine-warpperspective/","link":"","permalink":"http://www.codec.wang/opencv-python-extra-warpaffine-warpperspective/","excerpt":"常见的2D图像变换从原理上讲主要包括基于2×3矩阵的仿射变换和基于3×3矩阵透视变换。","text":"常见的2D图像变换从原理上讲主要包括基于2×3矩阵的仿射变换和基于3×3矩阵透视变换。 仿射变换基本的图像变换就是二维坐标的变换：从一种二维坐标(x,y)到另一种二维坐标(u,v)的线性变换： $$\\begin{matrix} u=a_1x+b_1y+c_1 \\newline v=a_2x+b_2y+c_2 \\end{matrix}$$如果写成矩阵的形式，就是：$$\\left[ \\begin{matrix} u \\newline v \\end{matrix} \\right] = \\left[ \\begin{matrix} a_1 &amp; b_1 \\newline a_2 &amp; b_2 \\end{matrix} \\right] \\left[ \\begin{matrix} x \\newline y \\end{matrix} \\right]+\\left[ \\begin{matrix} c_1 \\newline c_2 \\end{matrix} \\right]$$作如下定义：$$R=\\left[ \\begin{matrix} a_1 &amp; b_1 \\newline a_2 &amp; b_2 \\end{matrix} \\right], t=\\left[ \\begin{matrix} c_1 \\newline c_2 \\end{matrix} \\right],T=\\left[ \\begin{matrix} R &amp; t \\end{matrix} \\right]$$矩阵T(2×3)就称为仿射变换的变换矩阵，R为线性变换矩阵，t为平移矩阵，简单来说，仿射变换就是线性变换+平移。变换后直线依然是直线，平行线依然是平行线，直线间的相对位置关系不变，因此非共线的三个对应点便可确定唯一的一个仿射变换，线性变换4个自由度+平移2个自由度→仿射变换自由度为6。 来看下OpenCV中如何实现仿射变换： 12345678910111213141516171819import cv2import numpy as npimport matplotlib.pyplot as pltimg = cv2.imread('drawing.jpg')rows, cols = img.shape[:2]# 变换前的三个点pts1 = np.float32([[50, 65], [150, 65], [210, 210]])# 变换后的三个点pts2 = np.float32([[50, 100], [150, 65], [100, 250]])# 生成变换矩阵M = cv2.getAffineTransform(pts1, pts2)dst = cv2.warpAffine(img, M, (cols, rows))plt.subplot(121), plt.imshow(img), plt.title('input')plt.subplot(122), plt.imshow(dst), plt.title('output')plt.show() 三个点我已经在图中标记了出来。用cv2.getAffineTransform()生成变换矩阵，接下来再用cv2.warpAffine()实现变换。 思考：三个点我标记的是红色，为什么Matplotlib显示出来是下面这种颜色？（练习） 其实平移、旋转、缩放和翻转等变换就是对应了不同的仿射变换矩阵，下面分别来看下。 平移 平移就是x和y方向上的直接移动，可以上下/左右移动，自由度为2，变换矩阵可以表示为：$$\\left[ \\begin{matrix} u \\newline v \\end{matrix} \\right] = \\left[ \\begin{matrix} 1 &amp; 0 \\newline 0 &amp; 1 \\end{matrix} \\right] \\left[ \\begin{matrix} x \\newline y \\end{matrix} \\right]+\\left[ \\begin{matrix} t_x \\newline t_y \\end{matrix} \\right]$$ 旋转 旋转是坐标轴方向饶原点旋转一定的角度θ，自由度为1，不包含平移，如顺时针旋转可以表示为：$$\\left[ \\begin{matrix} u \\newline v \\end{matrix} \\right] = \\left[ \\begin{matrix} \\cos \\theta &amp; -\\sin \\theta \\newline \\sin \\theta &amp; \\cos \\theta \\end{matrix} \\right] \\left[ \\begin{matrix} x \\newline y \\end{matrix} \\right]+\\left[ \\begin{matrix} 0 \\newline 0 \\end{matrix} \\right]$$ 思考：如果不是绕原点，而是可变点，自由度是多少呢？（请看下文刚体变换） 翻转翻转是x或y某个方向或全部方向上取反，自由度为2，比如这里以垂直翻转为例：$$\\left[ \\begin{matrix} u \\newline v \\end{matrix} \\right] = \\left[ \\begin{matrix} 1 &amp; 0 \\newline 0 &amp; -1 \\end{matrix} \\right] \\left[ \\begin{matrix} x \\newline y \\end{matrix} \\right]+\\left[ \\begin{matrix} 0 \\newline 0 \\end{matrix} \\right]$$ 刚体变换旋转+平移也称刚体变换（Rigid Transform），就是说如果图像变换前后两点间的距离仍然保持不变，那么这种变化就称为刚体变换。刚体变换包括了平移、旋转和翻转，自由度为3。变换矩阵可以表示为： $$\\left[ \\begin{matrix} u \\newline v \\end{matrix} \\right] = \\left[ \\begin{matrix} \\cos \\theta &amp; -\\sin \\theta \\newline \\sin \\theta &amp; \\cos \\theta \\end{matrix} \\right] \\left[ \\begin{matrix} x \\newline y \\end{matrix} \\right]+\\left[ \\begin{matrix} t_x \\newline t_y \\end{matrix} \\right]$$ 由于只是旋转和平移，刚体变换保持了直线间的长度不变，所以也称欧式变换（变化前后保持欧氏距离）。 缩放 缩放是x和y方向的尺度（倍数）变换，在有些资料上非等比例的缩放也称为拉伸/挤压，等比例缩放自由度为1，非等比例缩放自由度为2，矩阵可以表示为：$$\\left[ \\begin{matrix} u \\newline v \\end{matrix} \\right] = \\left[ \\begin{matrix} s_x &amp; 0 \\newline 0 &amp; s_y \\end{matrix} \\right] \\left[ \\begin{matrix} x \\newline y \\end{matrix} \\right]+\\left[ \\begin{matrix} 0 \\newline 0 \\end{matrix} \\right]$$ 相似变换相似变换又称缩放旋转，相似变换包含了旋转、等比例缩放和平移等变换，自由度为4。在OpenCV中，旋转就是用相似变换实现的： 若缩放比例为scale，旋转角度为θ，旋转中心是$ (center_x,center_y) $，则仿射变换可以表示为： $$\\left[ \\begin{matrix} u \\newline v \\end{matrix} \\right] = \\left[ \\begin{matrix} \\alpha &amp; \\beta \\newline -\\beta &amp; \\alpha \\end{matrix} \\right] \\left[ \\begin{matrix} x \\newline y \\end{matrix} \\right]+\\left[ \\begin{matrix} (1-\\alpha)center_x-\\beta center_y \\newline \\beta center_x+(1-\\alpha)center_y \\end{matrix} \\right]$$其中，$$\\alpha=scale \\cdot \\cos \\theta,\\beta=scale \\cdot \\sin \\theta$$ 相似变换相比刚体变换加了缩放，所以并不会保持欧氏距离不变，但直线间的夹角依然不变。 经验之谈：OpenCV中默认按照逆时针旋转噢~ 总结一下（原图[#计算机视觉：算法与应用p39]）： 变换 矩阵 自由度 保持性质 平移 [I, t]（2×3） 2 方向/长度/夹角/平行性/直线性 刚体 [R, t]（2×3） 3 长度/夹角/平行性/直线性 相似 [sR, t]（2×3） 4 夹角/平行性/直线性 仿射 [T]（2×3） 6 平行性/直线性 透视 [T]（3×3） 8 直线性 透视变换前面仿射变换后依然是平行四边形，并不能做到任意的变换。 透视变换（Perspective Transformation）是将二维的图片投影到一个三维视平面上，然后再转换到二维坐标下，所以也称为投影映射（Projective Mapping）。简单来说就是二维→三维→二维的一个过程。$$\\begin{matrix} X=a_1 x + b_1 y + c_1 \\newline Y=a_2 x + b_2 y + c_2 \\newline Z=a_3 x + b_3 y + c_3 \\end{matrix}$$这次我写成齐次矩阵的形式：$$\\left[ \\begin{matrix} X \\newline Y \\newline Z \\end{matrix} \\right] = \\left[ \\begin{matrix} a_1 &amp; b_1 &amp; c_1 \\newline a_2 &amp; b_2 &amp; c_2 \\newline a_3 &amp; b_3 &amp; c_3 \\end{matrix} \\right] \\left[ \\begin{matrix} x \\newline y \\newline 1 \\end{matrix} \\right]$$其中，$ \\left[ \\begin{matrix} a_1 &amp; b_1 \\newline a_2 &amp; b_2 \\newline \\end{matrix} \\right] $表示线性变换，$ \\left[ \\begin{matrix} a_3 &amp; b_3 \\end{matrix} \\right] $产生透视变换，其余表示平移变换，因此仿射变换是透视变换的子集。接下来再通过除以Z轴转换成二维坐标：$$x^{’}=\\frac{X}{Z}=\\frac{a_1x+b_1y+c_1}{a_3x+b_3y+c_3 }$$ $$y^{’}=\\frac{Y}{Z}=\\frac{a_2x+b_2y+c_2}{a_3x+b_3y+c_3 }$$ 透视变换相比仿射变换更加灵活，变换后会产生一个新的四边形，但不一定是平行四边形，所以需要非共线的四个点才能唯一确定，原图中的直线变换后依然是直线。因为四边形包括了所有的平行四边形，所以透视变换包括了所有的仿射变换。 OpenCV中首先根据变换前后的四个点用cv2.getPerspectiveTransform()生成3×3的变换矩阵，然后再用cv2.warpPerspective()进行透视变换。实战演练一下： 123456789101112131415img = cv2.imread('card.jpg')# 原图中卡片的四个角点pts1 = np.float32([[148, 80], [437, 114], [94, 247], [423, 288]])# 变换后分别在左上、右上、左下、右下四个点pts2 = np.float32([[0, 0], [320, 0], [0, 178], [320, 178]])# 生成透视变换矩阵M = cv2.getPerspectiveTransform(pts1, pts2)# 进行透视变换，参数3是目标图像大小dst = cv2.warpPerspective(img, M, (320, 178))plt.subplot(121), plt.imshow(img[:, :, ::-1]), plt.title('input')plt.subplot(122), plt.imshow(dst[:, :, ::-1]), plt.title('output')plt.show() 代码中有个img[:, :, ::-1]还记得吗？忘记的话，请看练习。 当然，我们后面学习了特征提取之后，就可以自动识别角点了。透视变换是一项很酷的功能。比如我们经常会用手机去拍身份证和文件，无论你怎么拍，貌似都拍不正或者有边框。如果你使用过手机上面一些扫描类软件，比如”扫描全能王“，”Office Lens“，它们能很好地矫正图片，这些软件就是应用透视变换实现的。 练习 请复习：Matplotlib显示图像。 引用 本节源码 计算机视觉：算法与应用 维基百科：仿射变换 如何通俗地讲解「仿射变换」这个概念？","categories":[{"name":"机器视觉","slug":"机器视觉","permalink":"http://www.codec.wang/categories/%E6%9C%BA%E5%99%A8%E8%A7%86%E8%A7%89/"}],"tags":[{"name":"OpenCV","slug":"OpenCV","permalink":"http://www.codec.wang/tags/OpenCV/"},{"name":"Python","slug":"Python","permalink":"http://www.codec.wang/tags/Python/"},{"name":"图像处理","slug":"图像处理","permalink":"http://www.codec.wang/tags/%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86/"},{"name":"图像变换","slug":"图像变换","permalink":"http://www.codec.wang/tags/%E5%9B%BE%E5%83%8F%E5%8F%98%E6%8D%A2/"}]},{"title":"Python+OpenCV教程7：图像几何变换","slug":"Python-OpenCV教程7：图像几何变换","date":"2017-12-08T06:36:53.000Z","updated":"2019-05-08T03:19:07.243Z","comments":true,"path":"opencv-python-image-geometric-transformation/","link":"","permalink":"http://www.codec.wang/opencv-python-image-geometric-transformation/","excerpt":"学习如何旋转、平移、缩放和翻转图片。","text":"学习如何旋转、平移、缩放和翻转图片。图片等可到源码处下载。 目标 实现旋转、平移和缩放图片 OpenCV函数：cv2.resize(), cv2.flip(), cv2.warpAffine() 教程 图像的几何变换从原理上看主要包括两种：基于2×3矩阵的仿射变换（平移、缩放、旋转和翻转等）、基于3×3矩阵的透视变换，感兴趣的小伙伴可参考番外篇：仿射变换与透视变换。 缩放图片缩放就是调整图片的大小，使用cv2.resize()函数实现缩放。可以按照比例缩放，也可以按照指定的大小缩放： 1234567891011import cv2img = cv2.imread('drawing.jpg')# 按照指定的宽度、高度缩放图片res = cv2.resize(img, (132, 150))# 按照比例缩放，如x,y轴均放大一倍res2 = cv2.resize(img, None, fx=2, fy=2, interpolation=cv2.INTER_LINEAR)cv2.imshow('shrink', res), cv2.imshow('zoom', res2)cv2.waitKey(0) 我们也可以指定缩放方法interpolation，更专业点叫插值方法，默认是INTER_LINEAR，全部可以参考：InterpolationFlags 翻转图片镜像翻转图片，可以用cv2.flip()函数： 1dst = cv2.flip(img, 1) 其中，参数2 = 0：垂直翻转(沿x轴)，参数2 &gt; 0: 水平翻转(沿y轴)，参数2 &lt; 0: 水平垂直翻转。 平移图片要平移图片，我们需要定义下面这样一个矩阵，tx,ty是向x和y方向平移的距离： $$ M = \\left[ \\begin{matrix} 1 &amp; 0 &amp; t_x \\newline 0 &amp; 1 &amp; t_y \\end{matrix} \\right]$$ 平移是用仿射变换函数cv2.warpAffine()实现的： 12345678910111213# 平移图片import numpy as nprows, cols = img.shape[:2]# 定义平移矩阵，需要是numpy的float32类型# x轴平移100，y轴平移50M = np.float32([[1, 0, 100], [0, 1, 50]])# 用仿射变换实现平移dst = cv2.warpAffine(img, M, (cols, rows))cv2.imshow('shift', dst)cv2.waitKey(0) 旋转图片旋转同平移一样，也是用仿射变换实现的，因此也需要定义一个变换矩阵。OpenCV直接提供了 cv2.getRotationMatrix2D()函数来生成这个矩阵，该函数有三个参数： 参数1：图片的旋转中心 参数2：旋转角度(正：逆时针，负：顺时针) 参数3：缩放比例，0.5表示缩小一半 123456# 45°旋转图片并缩小一半M = cv2.getRotationMatrix2D((cols / 2, rows / 2), 45, 0.5)dst = cv2.warpAffine(img, M, (cols, rows))cv2.imshow('rotation', dst)cv2.waitKey(0) 小结 cv2.resize()缩放图片，可以按指定大小缩放，也可以按比例缩放。 cv2.flip()翻转图片，可以指定水平/垂直/水平垂直翻转三种方式。 平移/旋转是靠仿射变换cv2.warpAffine()实现的。 接口文档 cv2.resize() cv2.filp() cv2.warpAffine() cv2.getRotationMatrix2D() 引用 本节源码 Geometric Transformations of Images","categories":[{"name":"机器视觉","slug":"机器视觉","permalink":"http://www.codec.wang/categories/%E6%9C%BA%E5%99%A8%E8%A7%86%E8%A7%89/"}],"tags":[{"name":"OpenCV","slug":"OpenCV","permalink":"http://www.codec.wang/tags/OpenCV/"},{"name":"Python","slug":"Python","permalink":"http://www.codec.wang/tags/Python/"},{"name":"图像处理","slug":"图像处理","permalink":"http://www.codec.wang/tags/%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86/"},{"name":"几何变换","slug":"几何变换","permalink":"http://www.codec.wang/tags/%E5%87%A0%E4%BD%95%E5%8F%98%E6%8D%A2/"}]},{"title":"Python+OpenCV教程番外篇4：Otsu阈值法","slug":"Python-OpenCV教程番外篇4：Otsu阈值法","date":"2017-12-08T04:48:05.000Z","updated":"2019-05-11T11:47:00.408Z","comments":true,"path":"opencv-python-extra-otsu-thresholding/","link":"","permalink":"http://www.codec.wang/opencv-python-extra-otsu-thresholding/","excerpt":"大部分图像处理任务都需要先进行二值化操作，阈值的选取很关键，Otsu阈值法会自动计算阈值。","text":"大部分图像处理任务都需要先进行二值化操作，阈值的选取很关键，Otsu阈值法会自动计算阈值。 Otsu阈值法（日本人大津展之提出的，也可称大津算法）非常适用于双峰图片，啥意思呢？ Otsu N. A threshold selection method from gray-level histograms[J]. IEEE transactions on systems, man, and cybernetics, 1979, 9(1): 62-66. 什么是双峰图片？双峰图片就是指图片的灰度直方图上有两个峰值，直方图就是每个值（0~255）的像素点个数统计，后面会详细介绍。 Otsu算法假设这副图片由前景色和背景色组成，通过统计学方法（最大类间方差）选取一个阈值，将前景和背景尽可能分开，我们先来看下代码，然后详细说明下算法原理。 代码示例下面这段代码对比了使用固定阈值和Otsu阈值后的不同结果： 另外，对含噪点的图像，先进行滤波操作效果会更好。 1234567891011121314import cv2from matplotlib import pyplot as pltimg = cv2.imread('noisy.jpg', 0)# 固定阈值法ret1, th1 = cv2.threshold(img, 100, 255, cv2.THRESH_BINARY)# Otsu阈值法ret2, th2 = cv2.threshold(img, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)# 先进行高斯滤波，再使用Otsu阈值法blur = cv2.GaussianBlur(img, (5, 5), 0)ret3, th3 = cv2.threshold(blur, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU) 下面我们用Matplotlib把原图、直方图和阈值图都显示出来： 123456789101112131415161718192021222324images = [img, 0, th1, img, 0, th2, blur, 0, th3]titles = ['Original', 'Histogram', 'Global(v=100)', 'Original', 'Histogram', \"Otsu's\", 'Gaussian filtered Image', 'Histogram', \"Otsu's\"]for i in range(3): # 绘制原图 plt.subplot(3, 3, i * 3 + 1) plt.imshow(images[i * 3], 'gray') plt.title(titles[i * 3], fontsize=8) plt.xticks([]), plt.yticks([]) # 绘制直方图plt.hist，ravel函数将数组降成一维 plt.subplot(3, 3, i * 3 + 2) plt.hist(images[i * 3].ravel(), 256) plt.title(titles[i * 3 + 1], fontsize=8) plt.xticks([]), plt.yticks([]) # 绘制阈值图 plt.subplot(3, 3, i * 3 + 3) plt.imshow(images[i * 3 + 2], 'gray') plt.title(titles[i * 3 + 2], fontsize=8) plt.xticks([]), plt.yticks([])plt.show() 可以看到，Otsu阈值明显优于固定阈值，省去了不断尝试阈值判断效果好坏的过程。其中，绘制直方图时，使用了numpy中的ravel()函数，它会将原矩阵压缩成一维数组，便于画直方图。 Otsu算法详解Otsu阈值法将整幅图分为前景（目标）和背景，以下是一些符号规定： $ T $：分割阈值 $ N_0 $：前景像素点数 $ N_1 $：背景像素点数 $ \\omega_0 $：前景的像素点数占整幅图像的比例 $ \\omega_1 $：背景的像素点数占整幅图像的比例 $ \\mu_0 $：前景的平均像素值 $ \\mu_1 $：背景的平均像素值 $ \\mu $：整幅图的平均像素值 $ rows\\times cols $：图像的行数和列数 结合下图会更容易理解一些，有一副大小为4×4的图片，假设阈值T为1，那么： 其实很好理解，$ N_0+N_1 $就是总的像素点个数，也就是行数乘列数：$$N_0+N_1=rows\\times cols$$$ \\omega_0 $和$ \\omega_1 $是前/背景所占的比例，也就是：$$\\omega_0=\\frac{N_0}{rows\\times cols}$$$$\\omega_1=\\frac{N_1}{rows\\times cols}$$$$\\omega_0+\\omega_1=1 \\tag{1}$$整幅图的平均像素值就是：$$\\mu=\\omega_0\\times \\mu_0+\\omega_1\\times \\mu_1 \\tag{2}$$ 此时，我们定义一个前景$ \\mu_0 $与背景$ \\mu_1 $的方差$ g $： $$g=\\omega_0(\\mu_0-\\mu)^2+\\omega_1(\\mu_1-\\mu)^2 \\tag{3}$$ 将前述的1/2/3公式整合在一起，便是： $$g=\\omega_0\\omega_1(\\mu_0-\\mu_1)^2$$ $ g $就是前景与背景两类之间的方差，这个值越大，说明前景和背景的差别也就越大，效果越好。Otsu算法便是遍历阈值T，使得$ g $最大，所以又称为最大类间方差法。基本上双峰图片的阈值T在两峰之间的谷底。 接口文档 cv2.ThresholdTypes cv2.GaussianBlur() 引用 本节源码 numpy.ravel Otsu’s Method(wikipedia) Image Thresholding 一维OTSU法、最小交叉熵法、二维OTSU法及C++源码 Otsu N. A threshold selection method from gray-level histograms[J]. IEEE transactions on systems, man, and cybernetics, 1979, 9(1): 62-66.","categories":[{"name":"机器视觉","slug":"机器视觉","permalink":"http://www.codec.wang/categories/%E6%9C%BA%E5%99%A8%E8%A7%86%E8%A7%89/"}],"tags":[{"name":"OpenCV","slug":"OpenCV","permalink":"http://www.codec.wang/tags/OpenCV/"},{"name":"Python","slug":"Python","permalink":"http://www.codec.wang/tags/Python/"},{"name":"图像处理","slug":"图像处理","permalink":"http://www.codec.wang/tags/%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86/"},{"name":"阈值","slug":"阈值","permalink":"http://www.codec.wang/tags/%E9%98%88%E5%80%BC/"}]},{"title":"Python+OpenCV教程6：阈值分割","slug":"Python-OpenCV教程6：阈值分割","date":"2017-12-07T13:14:44.000Z","updated":"2019-05-11T11:45:00.768Z","comments":true,"path":"opencv-python-image-thresholding/","link":"","permalink":"http://www.codec.wang/opencv-python-image-thresholding/","excerpt":"学习使用不同的阈值方法”二值化”图像。","text":"学习使用不同的阈值方法”二值化”图像。图片等可到源码处下载。 目标 使用固定阈值、自适应阈值和Otsu阈值法”二值化”图像 OpenCV函数：cv2.threshold(), cv2.adaptiveThreshold() 教程固定阈值分割固定阈值分割很直接，一句话说就是像素点值大于阈值变成一类值，小于阈值变成另一类值。 123456789import cv2# 灰度图读入img = cv2.imread('gradient.jpg', 0)# 阈值分割ret, th = cv2.threshold(img, 127, 255, cv2.THRESH_BINARY)cv2.imshow('thresh', th)cv2.waitKey(0) cv2.threshold()用来实现阈值分割，ret是return value缩写，代表当前的阈值，暂时不用理会。函数有4个参数： 参数1：要处理的原图，一般是灰度图 参数2：设定的阈值 参数3：最大阈值，一般为255 参数4：阈值的方式，主要有5种，详情：ThresholdTypes 下面结合代码理解下这5种阈值方式： 1234567891011121314151617181920import matplotlib.pyplot as plt# 应用5种不同的阈值方法ret, th1 = cv2.threshold(img, 127, 255, cv2.THRESH_BINARY)ret, th2 = cv2.threshold(img, 127, 255, cv2.THRESH_BINARY_INV)ret, th3 = cv2.threshold(img, 127, 255, cv2.THRESH_TRUNC)ret, th4 = cv2.threshold(img, 127, 255, cv2.THRESH_TOZERO)ret, th5 = cv2.threshold(img, 127, 255, cv2.THRESH_TOZERO_INV)titles = ['Original', 'BINARY', 'BINARY_INV', 'TRUNC', 'TOZERO', 'TOZERO_INV']images = [img, th1, th2, th3, th4, th5]# 使用Matplotlib显示for i in range(6): plt.subplot(2, 3, i + 1) plt.imshow(images[i], 'gray') plt.title(titles[i], fontsize=8) plt.xticks([]), plt.yticks([]) # 隐藏坐标轴plt.show() 经验之谈：很多人误以为阈值分割就是二值化。从上图中可以发现，两者并不等同，阈值分割结果是两类值，而不是两个值，所以教程开头我把二值化加了引号。 自适应阈值看得出来固定阈值是在整幅图片上应用一个阈值进行分割，它并不适用于明暗分布不均的图片。 cv2.adaptiveThreshold()自适应阈值会每次取图片的一小部分计算阈值，这样图片不同区域的阈值就不尽相同。它有5个参数，其实很好理解，先看下效果： 12345678910111213141516171819# 自适应阈值对比固定阈值img = cv2.imread('sudoku.jpg', 0)# 固定阈值ret, th1 = cv2.threshold(img, 127, 255, cv2.THRESH_BINARY)# 自适应阈值th2 = cv2.adaptiveThreshold( img, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 11, 4)th3 = cv2.adaptiveThreshold( img, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 17, 6)titles = ['Original', 'Global(v = 127)', 'Adaptive Mean', 'Adaptive Gaussian']images = [img, th1, th2, th3]for i in range(4): plt.subplot(2, 2, i + 1), plt.imshow(images[i], 'gray') plt.title(titles[i], fontsize=8) plt.xticks([]), plt.yticks([])plt.show() 参数1：要处理的原图 参数2：最大阈值，一般为255 参数3：小区域阈值的计算方式 ADAPTIVE_THRESH_MEAN_C：小区域内取均值 ADAPTIVE_THRESH_GAUSSIAN_C：小区域内加权求和，权重是个高斯核 参数4：阈值方式（跟前面讲的那5种相同） 参数5：小区域的面积，如11就是11*11的小块 参数6：最终阈值等于小区域计算出的阈值再减去此值 如果你没看懂上面的参数也不要紧，暂时会用就行，当然我建议你调整下参数看看不同的结果。 Otsu阈值在前面固定阈值中，我们是随便选了一个阈值如127，那如何知道我们选的这个阈值效果好不好呢？答案是：不断尝试，所以这种方法在很多文献中都被称为经验阈值。Otsu阈值法就提供了一种自动高效的二值化方法，不过我们直方图还没学，这里暂时略过。 好吧，我知道我激起了你的兴趣，~ o(￣▽￣)o，有能力的童鞋可以看下练习题。 小结 cv2.threshold()用来进行固定阈值分割。固定阈值不适用于光线不均匀的图片，所以用 cv2.adaptiveThreshold()进行自适应阈值分割。 二值化跟阈值分割并不等同。针对不同的图片，可以采用不同的阈值方法。 练习 Otsu阈值是一种高效的二值化算法，请阅读番外篇：Otsu阈值法 接口文档 cv2.threshold() cv2.adaptiveThreshold() cv2.ThresholdTypes() 引用 本节源码 Image Thresholding","categories":[{"name":"机器视觉","slug":"机器视觉","permalink":"http://www.codec.wang/categories/%E6%9C%BA%E5%99%A8%E8%A7%86%E8%A7%89/"}],"tags":[{"name":"OpenCV","slug":"OpenCV","permalink":"http://www.codec.wang/tags/OpenCV/"},{"name":"Python","slug":"Python","permalink":"http://www.codec.wang/tags/Python/"},{"name":"图像处理","slug":"图像处理","permalink":"http://www.codec.wang/tags/%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86/"},{"name":"阈值","slug":"阈值","permalink":"http://www.codec.wang/tags/%E9%98%88%E5%80%BC/"}]},{"title":"Python+OpenCV教程5：颜色空间转换","slug":"Python-OpenCV教程5：颜色空间转换","date":"2017-12-07T07:21:19.000Z","updated":"2019-05-08T03:03:42.330Z","comments":true,"path":"opencv-python-changing-colorspaces/","link":"","permalink":"http://www.codec.wang/opencv-python-changing-colorspaces/","excerpt":"学习如何进行图片的颜色空间转换，视频中追踪特定颜色的物体。","text":"学习如何进行图片的颜色空间转换，视频中追踪特定颜色的物体。图片等可到源码处下载。 目标 颜色空间转换，如BGR↔Gray，BGR↔HSV等 追踪视频中特定颜色的物体 OpenCV函数：cv2.cvtColor(), cv2.inRange() 教程颜色空间转换123456789import cv2img = cv2.imread('lena.jpg')# 转换为灰度图img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)cv2.imshow('img', img)cv2.imshow('gray', img_gray)cv2.waitKey(0) cv2.cvtColor()用来进行颜色模型转换，参数1是要转换的图片，参数2是转换模式， COLOR_BGR2GRAY表示BGR→Gray，可用下面的代码显示所有的转换模式： 12flags = [i for i in dir(cv2) if i.startswith('COLOR_')]print(flags) 经验之谈：颜色转换其实是数学运算，如灰度化最常用的是：gray=R*0.299+G*0.587+B*0.114。 视频中特定颜色物体追踪HSV是一个常用于颜色识别的模型，相比BGR更易区分颜色，转换模式用COLOR_BGR2HSV表示。 经验之谈：OpenCV中色调H范围为[0,179]，饱和度S是[0,255]，明度V是[0,255]。虽然H的理论数值是0°~360°，但8位图像像素点的最大值是255，所以OpenCV中除以了2，某些软件可能使用不同的尺度表示，所以同其他软件混用时，记得归一化。 现在，我们实现一个使用HSV来只显示视频中蓝色物体的例子，步骤如下： 捕获视频中的一帧 从BGR转换到HSV 提取蓝色范围的物体 只显示蓝色物体 123456789101112131415161718192021222324252627import numpy as npcapture = cv2.VideoCapture(0)# 蓝色的范围，不同光照条件下不一样，可灵活调整lower_blue = np.array([100, 110, 110])upper_blue = np.array([130, 255, 255])while(True): # 1.捕获视频中的一帧 ret, frame = capture.read() # 2.从BGR转换到HSV hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV) # 3.inRange()：介于lower/upper之间的为白色，其余黑色 mask = cv2.inRange(hsv, lower_blue, upper_blue) # 4.只保留原图中的蓝色部分 res = cv2.bitwise_and(frame, frame, mask=mask) cv2.imshow('frame', frame) cv2.imshow('mask', mask) cv2.imshow('res', res) if cv2.waitKey(1) == ord('q'): break 其中，bitwise_and()函数暂时不用管，后面会讲到。那蓝色的HSV值的上下限lower和upper范围是怎么得到的呢？其实很简单，我们先把标准蓝色的BGR值用cvtColor()转换下： 123blue = np.uint8([[[255, 0, 0]]])hsv_blue = cv2.cvtColor(blue, cv2.COLOR_BGR2HSV)print(hsv_blue) # [[[120 255 255]]] 结果是[120, 255, 255]，所以，我们把蓝色的范围调整成了上面代码那样。 经验之谈：Lab颜色空间也经常用来做颜色识别，有兴趣的同学可以了解下。 小结 cv2.cvtColor()函数用来进行颜色空间转换，常用BGR↔Gray，BGR↔HSV。 HSV颜色模型常用于颜色识别。要想知道某种颜色在HSV下的值，可以将它的BGR值用cvtColor()转换得到。 练习 尝试在视频中同时提取红色、蓝色、绿色的物体。（效果如下） 接口文档 cv2.cvtColor() cv2.inRange() cv2.bitwise_and() 引用 本节源码 Changing Colorspaces","categories":[{"name":"机器视觉","slug":"机器视觉","permalink":"http://www.codec.wang/categories/%E6%9C%BA%E5%99%A8%E8%A7%86%E8%A7%89/"}],"tags":[{"name":"OpenCV","slug":"OpenCV","permalink":"http://www.codec.wang/tags/OpenCV/"},{"name":"Python","slug":"Python","permalink":"http://www.codec.wang/tags/Python/"},{"name":"图像处理","slug":"图像处理","permalink":"http://www.codec.wang/tags/%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86/"},{"name":"HSV","slug":"HSV","permalink":"http://www.codec.wang/tags/HSV/"}]},{"title":"Python+OpenCV教程4：图像基本操作","slug":"Python-OpenCV教程4：图像基本操作","date":"2017-12-07T04:13:15.000Z","updated":"2019-05-02T15:19:40.475Z","comments":true,"path":"opencv-python-basic-operations/","link":"","permalink":"http://www.codec.wang/opencv-python-basic-operations/","excerpt":"学习获取和修改像素点的值，ROI感兴趣区域，通道分离合并等基本操作。","text":"学习获取和修改像素点的值，ROI感兴趣区域，通道分离合并等基本操作。图片等可到源码处下载。 目标 访问和修改图片像素点的值 获取图片的宽、高、通道数等属性 了解感兴趣区域ROI 分离和合并图像通道 教程获取和修改像素点值我们先读入一张图片： 123import cv2img = cv2.imread('lena.jpg') 通过行列的坐标来获取某像素点的值，对于彩色图，结果是B,G,R三个值的列表，对于灰度图或单通道图，只有一个值： 123456px = img[100, 90]print(px) # [103 98 197]# 只获取蓝色blue通道的值px_blue = img[100, 90, 0]print(px_blue) # 103 还记得吗？行对应y，列对应x，所以其实是img[y, x]，需要注意噢(●ˇ∀ˇ●)。容易混淆的话，可以只记行和列，行在前，列在后。 修改像素的值也是同样的方式： 12img[100, 90] = [255, 255, 255]print(img[100, 90]) # [255 255 255] 经验之谈：还有一种性能更好的方式，获取：img.item(100,100,0)，修改：img.itemset((100,100,0),255)，但这种方式只能B,G,R逐一进行。 注意：这步操作只是内存中的img像素点值变了，因为没有保存，所以原图并没有更改。 图片属性img.shape获取图像的形状，图片是彩色的话，返回一个包含行数（高度）、列数（宽度）和通道数的元组，灰度图只返回行数和列数： 1234print(img.shape) # (263, 247, 3)# 形状中包括行数、列数和通道数height, width, channels = img.shape# img是灰度图的话：height, width = img.shape img.dtype获取图像数据类型： 1print(img.dtype) # uint8 经验之谈：多数错误是因为数据类型不对导致的，所以健壮的代码应该对这个属性加以判断。 img.size获取图像总像素数： 1print(img.size) # 263*247*3=194883 ROIROI：Region of Interest，感兴趣区域。什么意思呢？比如我们要检测眼睛，因为眼睛肯定在脸上，所以我们感兴趣的只有脸这部分，其他都不care，所以可以单独把脸截取出来，这样就可以大大节省计算量，提高运行速度。 截取ROI非常简单，指定图片的范围即可（后面我们学了特征后，就可以自动截取辣，(ง •_•)ง）： 1234# 截取脸部ROIface = img[100:200, 115:188]cv2.imshow('face', face)cv2.waitKey(0) 通道分割与合并彩色图的BGR三个通道是可以分开单独访问的，也可以将单独的三个通道合并成一副图像。分别使用cv2.split()和cv2.merge()： 12b, g, r = cv2.split(img)img = cv2.merge((b, g, r)) split()函数比较耗时，更高效的方式是用numpy中的索引，如提取B通道： 123b = img[:, :, 0]cv2.imshow('blue', b)cv2.waitKey(0) 小结 img[y,x]获取/设置像素点值，img.shape：图片的形状（行数、列数、通道数）,img.dtype：图像的数据类型。 img[y1:y2,x1:x2]进行ROI截取，cv2.split()/cv2.merge()通道分割/合并。更推荐的获取单通道方式：b = img[:, :, 0]。 练习 打开lena.jpg，将帽子部分（高：25120，宽：50220）的红色通道截取出来并显示。 接口文档 cv2.split() cv2.merge() 引用 本节源码 Basic Operations on Images","categories":[{"name":"机器视觉","slug":"机器视觉","permalink":"http://www.codec.wang/categories/%E6%9C%BA%E5%99%A8%E8%A7%86%E8%A7%89/"}],"tags":[{"name":"OpenCV","slug":"OpenCV","permalink":"http://www.codec.wang/tags/OpenCV/"},{"name":"Python","slug":"Python","permalink":"http://www.codec.wang/tags/Python/"},{"name":"图像处理","slug":"图像处理","permalink":"http://www.codec.wang/tags/%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86/"},{"name":"ROI","slug":"ROI","permalink":"http://www.codec.wang/tags/ROI/"}]},{"title":"Python+OpenCV教程番外篇3：滑动条","slug":"Python-OpenCV教程番外篇3：滑动条","date":"2017-12-06T14:23:11.000Z","updated":"2019-05-02T15:07:50.631Z","comments":true,"path":"opencv-python-extra-trackbar/","link":"","permalink":"http://www.codec.wang/opencv-python-extra-trackbar/","excerpt":"学习使用滑动条动态调整参数。","text":"学习使用滑动条动态调整参数。图片等可到源码处下载。 滑动条的使用首先我们需要创建一个滑动条，如cv2.createTrackbar(&#39;R&#39;,&#39;image&#39;,0,255,call_back)，其中 参数1：滑动条的名称 参数2：所在窗口的名称 参数3：当前的值 参数4：最大值 参数5：回调函数名称，回调函数默认有一个表示当前值的参数 创建好之后，可以在回调函数中获取滑动条的值，也可以用：cv2.getTrackbarPos()得到，其中，参数1是滑动条的名称，参数2是窗口的名称。 RGB调色板下面我们实现一个RGB的调色板，理解下滑动条的用法： 1234567891011121314151617181920212223242526import cv2import numpy as np# 回调函数，x表示滑块的位置，本例暂不使用def nothing(x): passimg = np.zeros((300, 512, 3), np.uint8)cv2.namedWindow('image')# 创建RGB三个滑动条cv2.createTrackbar('R', 'image', 0, 255, nothing)cv2.createTrackbar('G', 'image', 0, 255, nothing)cv2.createTrackbar('B', 'image', 0, 255, nothing)while(True): cv2.imshow('image', img) if cv2.waitKey(1) == 27: break # 获取滑块的值 r = cv2.getTrackbarPos('R', 'image') g = cv2.getTrackbarPos('G', 'image') b = cv2.getTrackbarPos('B', 'image') # 设定img的颜色 img[:] = [b, g, r] 小结 cv2.createTrackbar()用来创建滑动条，可以在回调函数中或使用cv2.getTrackbarPos()得到滑块的位置 接口文档 cv2.createTrackbar() cv2.getTrackbarPos() 引用 本节源码 Trackbar as the Color Palette","categories":[{"name":"机器视觉","slug":"机器视觉","permalink":"http://www.codec.wang/categories/%E6%9C%BA%E5%99%A8%E8%A7%86%E8%A7%89/"}],"tags":[{"name":"OpenCV","slug":"OpenCV","permalink":"http://www.codec.wang/tags/OpenCV/"},{"name":"Python","slug":"Python","permalink":"http://www.codec.wang/tags/Python/"},{"name":"图像处理","slug":"图像处理","permalink":"http://www.codec.wang/tags/%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86/"},{"name":"滑动条","slug":"滑动条","permalink":"http://www.codec.wang/tags/%E6%BB%91%E5%8A%A8%E6%9D%A1/"}]},{"title":"Python+OpenCV教程3：打开摄像头","slug":"Python-OpenCV教程3：打开摄像头","date":"2017-12-06T08:38:02.000Z","updated":"2019-05-02T15:09:34.866Z","comments":true,"path":"opencv-python-open-camera/","link":"","permalink":"http://www.codec.wang/opencv-python-open-camera/","excerpt":"学习打开摄像头捕获照片、播放本地视频、录制视频等。","text":"学习打开摄像头捕获照片、播放本地视频、录制视频等。图片/视频等可到源码处下载。 目标 打开摄像头并捕获照片 播放本地视频，录制视频 OpenCV函数：cv2.VideoCapture(), cv2.VideoWriter() 教程打开摄像头要使用摄像头，需要使用cv2.VideoCapture(0)创建VideoCapture对象，参数0指的是摄像头的编号，如果你电脑上有两个摄像头的话，访问第2个摄像头就可以传入1，依此类推。 1234567891011121314# 打开摄像头并灰度化显示import cv2capture = cv2.VideoCapture(0)while(True): # 获取一帧 ret, frame = capture.read() # 将这帧转换为灰度图 gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY) cv2.imshow('frame', gray) if cv2.waitKey(1) == ord('q'): break capture.read()函数返回的第1个参数ret(return value缩写)是一个布尔值，表示当前这一帧是否获取正确。cv2.cvtColor()用来转换颜色，这里将彩色图转成灰度图。 另外，通过cap.get(propId)可以获取摄像头的一些属性，比如捕获的分辨率，亮度和对比度等。propId是从0~18的数字，代表不同的属性，完整的属性列表可以参考：VideoCaptureProperties。也可以使用cap.set(propId,value)来修改属性值。比如说，我们在while之前添加下面的代码： 12345678# 获取捕获的分辨率# propId可以直接写数字，也可以用OpenCV的符号表示width, height = capture.get(3), capture.get(4)print(width, height)# 以原分辨率的一倍来捕获capture.set(cv2.CAP_PROP_FRAME_WIDTH, width * 2)capture.set(cv2.CAP_PROP_FRAME_HEIGHT, height * 2) 经验之谈：某些摄像头设定分辨率等参数时会无效，因为它有固定的分辨率大小支持，一般可在摄像头的资料页中找到。 播放本地视频跟打开摄像头一样，如果把摄像头的编号换成视频的路径就可以播放本地视频了。回想一下cv2.waitKey()，它的参数表示暂停时间，所以这个值越大，视频播放速度越慢，反之，播放速度越快，通常设置为25或30。 12345678910# 播放本地视频capture = cv2.VideoCapture('demo_video.mp4')while(capture.isOpened()): ret, frame = capture.read() gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY) cv2.imshow('frame', gray) if cv2.waitKey(30) == ord('q'): break 录制视频之前我们保存图片用的是cv2.imwrite()，要保存视频，我们需要创建一个VideoWriter的对象，需要给它传入四个参数： 输出的文件名，如’output.avi’ 编码方式FourCC码 帧率FPS 要保存的分辨率大小 FourCC是用来指定视频编码方式的四字节码，所有的编码可参考Video Codecs。如MJPG编码可以这样写： cv2.VideoWriter_fourcc(*&#39;MJPG&#39;)或cv2.VideoWriter_fourcc(&#39;M&#39;,&#39;J&#39;,&#39;P&#39;,&#39;G&#39;) 12345678910111213141516capture = cv2.VideoCapture(0)# 定义编码方式并创建VideoWriter对象fourcc = cv2.VideoWriter_fourcc(*'MJPG')outfile = cv2.VideoWriter('output.avi', fourcc, 25., (640, 480))while(capture.isOpened()): ret, frame = capture.read() if ret: outfile.write(frame) # 写入文件 cv2.imshow('frame', frame) if cv2.waitKey(1) == ord('q'): break else: break 小结 使用cv2.VideoCapture()创建视频对象，然后在循环中一帧帧显示图像。参数传入数字时，代表打开摄像头，传入本地视频路径时，表示播放本地视频。 cap.get(propId)获取视频属性，cap.set(propId,value)设置视频属性。 cv2.VideoWriter()创建视频写入对象，用来录制/保存视频。 练习 请先阅读番外篇：滑动条，然后实现一个可以拖动滑块播放视频的功能。（提示：需要用到 cv2.CAP_PROP_FRAME_COUNT和cv2.CAP_PROP_POS_FRAMES两个属性）。 接口文档 VideoCapture Object VideoWriter Object cv2.cvtColor() 引用 本节源码 Video Codecs by FOURCC Getting Started with Videos","categories":[{"name":"机器视觉","slug":"机器视觉","permalink":"http://www.codec.wang/categories/%E6%9C%BA%E5%99%A8%E8%A7%86%E8%A7%89/"}],"tags":[{"name":"OpenCV","slug":"OpenCV","permalink":"http://www.codec.wang/tags/OpenCV/"},{"name":"Python","slug":"Python","permalink":"http://www.codec.wang/tags/Python/"},{"name":"图像处理","slug":"图像处理","permalink":"http://www.codec.wang/tags/%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86/"}]},{"title":"Python+OpenCV教程番外篇2：无损保存和Matplotlib使用","slug":"Python-OpenCV教程番外篇2：无损保存和Matplotlib使用","date":"2017-12-06T07:55:15.000Z","updated":"2019-05-02T15:29:42.678Z","comments":true,"path":"opencv-python-extra-high-quality-save-and-using-matplotlib/","link":"","permalink":"http://www.codec.wang/opencv-python-extra-high-quality-save-and-using-matplotlib/","excerpt":"了解常用图片格式和OpenCV高质量保存图片的方式，学习如何使用Matplotlib显示OpenCV图像。","text":"了解常用图片格式和OpenCV高质量保存图片的方式，学习如何使用Matplotlib显示OpenCV图像。 无损保存事实上，我们日常看到的大部分图片都是压缩过的，那么都有哪些常见的图片格式呢？ 常用图片格式 bmp 全称：Bitmap 不压缩 jpg 全称：Joint Photographic Experts Group 有损压缩方式 png 全称：Portable Network Graphics 无损压缩方式 简单来说，同一个文件保存成不同的格式后，文件大小上bmp肯定是最大的，而png和jpg，不同的压缩比结果会有所不同。可以用画图工具新建一副100×100的图像，分别保存成这三种格式来验证： 高质量保存用cv2.imwrite()保存图片时，可以传入第三个参数（请参考接口文档），用于控制保存质量： cv2.IMWRITE_JPEG_QUALITY：jpg质量控制，取值0~100，值越大，质量越好，默认为95 cv2.IMWRITE_PNG_COMPRESSION：png质量控制，取值0~9，值越大，压缩比越高，默认为1 还有诸如CV_IMWRITE_WEBP_QUALITY的参量，不常用，请参考：ImwriteFlags。 举例来说，原图lena.jpg的分辨率是350×350，大小49.7KB。我们把它转成不同格式看下： 123456789101112131415161718import cv2new_img = cv2.imread('lena.jpg')# bmpcv2.imwrite('img_bmp.bmp',new_img) # 文件大小：359KB# jpg 默认95%质量cv2.imwrite('img_jpg95.jpg',new_img) # 文件大小：52.3KB# jpg 20%质量cv2.imwrite('img_jpg20.jpg',new_img,[int(cv2.IMWRITE_JPEG_QUALITY),20]) # 文件大小：8.01KB# jpg 100%质量cv2.imwrite('img_jpg100.jpg',new_img,[int(cv2.IMWRITE_JPEG_QUALITY),100]) # 文件大小：82.5KB# png 默认1压缩比cv2.imwrite('img_png1.png',new_img) # 文件大小：240KB# png 9压缩比cv2.imwrite('img_png9.png',new_img,[int(cv2.IMWRITE_PNG_COMPRESSION),9]) # 文件大小：207KB 可以看到： bmp文件是最大的，没有任何压缩（1个像素点1byte，3通道的彩色图总大小：350×350×3/1024 ≈ 359 KB） jpg/png本身就有压缩的，所以就算是100%的质量保存，体积也比bmp小很多 jpg的容量优势很明显，这也是它为什么如此流行的原因 思考：为什么原图49.7KB，保存成bmp或其他格式反而大了呢？ 这是个很有趣的问题，很多童鞋都问过我。这里需要明确的是保存新格式时，容量大小跟原图的容量没有直接关系，而是取决于原图的分辨率大小和原图本身的内容（压缩方式），所以lena.jpg保存成不压缩的bmp格式时，容量大小就是固定的350×350×3/1024 ≈ 359 KB；另外，容量变大不代表画质提升噢，不然就逆天了~ MatplotlibMatplotlib是Python的一个很常用的绘图库，有兴趣的可以去官网学习更多内容。 显示灰度图12345678import cv2import matplotlib.pyplot as pltimg = cv2.imread('lena.jpg', 0)# 灰度图显示，cmap(color map)设置为grayplt.imshow(img, cmap='gray')plt.show() 结果如下： 显示彩色图OpenCV中的图像是以BGR的通道顺序存储的，但Matplotlib是以RGB模式显示的，所以直接在Matplotlib中显示OpenCV图像会出现问题，因此需要转换一下: 1234567891011121314151617import cv2import matplotlib.pyplot as pltimg = cv2.imread('lena.jpg')img2 = img[:, :, ::-1]# 或使用# img2 = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)# 显示不正确的图plt.subplot(121),plt.imshow(img) # 显示正确的图plt.subplot(122)plt.xticks([]), plt.yticks([]) # 隐藏x和y轴plt.imshow(img2)plt.show() img[:,:,0]表示图片的蓝色通道，img[:,:,::-1]就表示BGR翻转，变成RGB，说明一下： 熟悉Python的童鞋应该知道，对一个字符串s翻转可以这样写：s[::-1]，’abc’变成’cba’，-1表示逆序。图片是二维的，所以完整地复制一副图像就是： 1img2 = img[:,:] # 写全就是：img2 = img[0:height,0:width] 而图片是有三个通道，相当于一个长度为3的字符串，所以通道翻转与图片复制组合起来便是img[:,:,::-1]。 结果如下： 加载和保存图片不使用OpenCV，Matplotlib也可以加载和保存图片： 12345678import matplotlib.image as pliimg = pli.imread('lena.jpg')plt.imshow(img)# 保存图片，需放在show()函数之前plt.savefig('lena2.jpg')plt.show() 接口文档 cv2.imwrite() ImwriteFlags 引用 本节源码 聊一聊几种常用web图片格式 Matplotlib官网","categories":[{"name":"机器视觉","slug":"机器视觉","permalink":"http://www.codec.wang/categories/%E6%9C%BA%E5%99%A8%E8%A7%86%E8%A7%89/"}],"tags":[{"name":"OpenCV","slug":"OpenCV","permalink":"http://www.codec.wang/tags/OpenCV/"},{"name":"Python","slug":"Python","permalink":"http://www.codec.wang/tags/Python/"},{"name":"图像处理","slug":"图像处理","permalink":"http://www.codec.wang/tags/%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86/"},{"name":"Matplotlib","slug":"Matplotlib","permalink":"http://www.codec.wang/tags/Matplotlib/"}]},{"title":"Python+OpenCV教程2：基本元素-图片","slug":"Python-OpenCV教程2：基本元素-图片","date":"2017-12-06T07:52:06.000Z","updated":"2019-05-02T15:14:14.117Z","comments":true,"path":"opencv-python-basic-element-image/","link":"","permalink":"http://www.codec.wang/opencv-python-basic-element-image/","excerpt":"学习如何加载图片，显示并保存图片。","text":"学习如何加载图片，显示并保存图片。图片等可到源码处下载。 目标 加载图片，显示图片，保存图片 OpenCV函数：cv2.imread(), cv2.imshow(), cv2.imwrite() 教程大部分人可能都知道电脑上的彩色图是以RGB(红-绿-蓝，Red-Green-Blue)颜色模式显示的，但OpenCV中彩色图是以B-G-R通道顺序存储的，灰度图只有一个通道。 图像坐标的起始点是在左上角，所以行对应的是y，列对应的是x： 加载图片使用cv2.imread()来读入一张图片： 1234import cv2# 加载灰度图img = cv2.imread('lena.jpg', 0) 参数1：图片的文件名 如果图片放在当前文件夹下，直接写文件名就行了，如’lena.jpg’ 否则需要给出绝对路径，如’D:\\OpenCVSamples\\lena.jpg’ 参数2：读入方式，省略即采用默认值 cv2.IMREAD_COLOR：彩色图，默认值(1) cv2.IMREAD_GRAYSCALE：灰度图(0) cv2.IMREAD_UNCHANGED：包含透明通道的彩色图(-1) 经验之谈：路径中不能有中文噢，并且没有加载成功的话是不会报错的，print(img)的结果为None，后面处理才会报错，算是个小坑。 显示图片使用cv2.imshow()显示图片，窗口会自适应图片的大小： 12cv2.imshow('lena', img)cv2.waitKey(0) 参数1是窗口的名字，参数2是要显示的图片。不同窗口之间用窗口名区分，所以窗口名相同就表示是同一个窗口，显示结果如下： cv2.waitKey()是让程序暂停的意思，参数是等待时间（毫秒ms）。时间一到，会继续执行接下来的程序，传入0的话表示一直等待。等待期间也可以获取用户的按键输入：k = cv2.waitKey(0)（练习1）。 我们也可以先用cv2.namedWindow()创建一个窗口，之后再显示图片： 1234# 先定义窗口，后显示图片cv2.namedWindow('lena2', cv2.WINDOW_NORMAL)cv2.imshow('lena2', img)cv2.waitKey(0) 参数1依旧是窗口的名字，参数2默认是cv2.WINDOW_AUTOSIZE，表示窗口大小自适应图片，也可以设置为cv2.WINDOW_NORMAL，表示窗口大小可调整。图片比较大的时候，可以考虑用后者。 保存图片使用cv2.imwrite()保存图片，参数1是包含后缀名的文件名： 1cv2.imwrite('lena_gray.jpg', img) Nice，是不是很简单呐，再接再厉噢(●’◡’●) 小结 cv2.imread()读入图片、cv2.imshow()显示图片、cv2.imwrite()保存图片。 练习 打开lena.jpg并显示，如果按下’s’，就保存图片为’lena_save.bmp’，否则就结束程序。 Matplotlib是Python中常用的一个绘图库，请学习番外篇：无损保存和Matplotlib使用。 接口文档 Mat Object cv2.imread() cv2.imshow() cv2.imwrite() cv.namedWindow() 引用 本节源码 Getting Started with Images","categories":[{"name":"机器视觉","slug":"机器视觉","permalink":"http://www.codec.wang/categories/%E6%9C%BA%E5%99%A8%E8%A7%86%E8%A7%89/"}],"tags":[{"name":"OpenCV","slug":"OpenCV","permalink":"http://www.codec.wang/tags/OpenCV/"},{"name":"Python","slug":"Python","permalink":"http://www.codec.wang/tags/Python/"},{"name":"图像处理","slug":"图像处理","permalink":"http://www.codec.wang/tags/%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86/"}]},{"title":"Python+OpenCV教程番外篇1：代码性能优化","slug":"Python-OpenCV教程番外篇1：代码性能优化","date":"2017-12-06T07:51:52.000Z","updated":"2019-05-11T11:42:29.351Z","comments":true,"path":"opencv-python-extra-code-optimization/","link":"","permalink":"http://www.codec.wang/opencv-python-extra-code-optimization/","excerpt":"学习如何评估和优化代码性能。（本节还没更新完…………）","text":"学习如何评估和优化代码性能。（本节还没更新完…………） 完成一项任务很重要，高效地完成更重要。图像处理是对矩阵的操作，数据量巨大。如果代码写的不好，性能差距将很大，所以这节我们来了解下如何评估和提升代码性能。 评估代码运行时间123456import cv2start = cv2.getTickCount()# 这里写测试代码...end = cv2.getTickCount()print((end - start) / cv2.getTickFrequency()) 这段代码就是用来测量程序运行时间的（单位：s），其中cv2.getTickCount()函数得到电脑启动以来的时钟周期数，cv2.getTickFrequency()返回你电脑的主频，前后相减再除以主频就是你代码的运行时间（这样解释并不完全准确，但能理解就行）。另外，也可以用Python中的time模块计时： 123456import timestart = time.clock()# 这里写测试代码...end = time.clock()print(end - start) 经验之谈：如果你使用的是IPython或Jupyter Notebook开发环境，性能分析将会非常方便，详情请参考：Timing and Profiling in IPython 优化原则 数据元素少时用Python语法，数据元素多时用Numpy： 1234567x = 10z = np.uint8([10])# 尝试比较下面三句话各自的运行时间y = x * x * x # (1.6410249677846285e-06)y = x**3 # (2.461537451676943e-06)y = z * z * z # 最慢 (3.1179474387907945e-05) 所以Numpy的运行速度并不一定比Python本身语法快，元素数量较少时，请用Python本身格式。 尽量避免使用循环，尤其嵌套循环，因为极其慢！！！ 优先使用OpenCV/Numpy中封装好的函数 尽量将数据向量化，变成Numpy的数据格式 尽量避免数组的复制操作 接口文档 cv2.getTickCount() cv2.getTickFrequency() 引用 本节源码 Python Optimization Techniques Timing and Profiling in IPython Advanced Numpy","categories":[{"name":"机器视觉","slug":"机器视觉","permalink":"http://www.codec.wang/categories/%E6%9C%BA%E5%99%A8%E8%A7%86%E8%A7%89/"}],"tags":[{"name":"OpenCV","slug":"OpenCV","permalink":"http://www.codec.wang/tags/OpenCV/"},{"name":"Python","slug":"Python","permalink":"http://www.codec.wang/tags/Python/"},{"name":"图像处理","slug":"图像处理","permalink":"http://www.codec.wang/tags/%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86/"}]},{"title":"Python+OpenCV教程1：简介与安装","slug":"Python-OpenCV教程1：简介与安装","date":"2017-12-06T07:50:59.000Z","updated":"2018-12-04T13:48:43.191Z","comments":true,"path":"opencv-python-introduction-and-installation/","link":"","permalink":"http://www.codec.wang/opencv-python-introduction-and-installation/","excerpt":"相信大部分人知道的OpenCV都是用C++来开发的，那为什么我推荐使用Python呢？","text":"相信大部分人知道的OpenCV都是用C++来开发的，那为什么我推荐使用Python呢？ 本教程翻译自OpenCV官方英文教程，我按照使用度和难易度翻译，重新编写了大量原创内容，将不常用和较难的部分写成番外篇，浅显易懂，很easy的辣。每节的源码、图片和练习题答案均可在引用处找到噢(⊙o⊙) Python照样快！众所周知，虽然Python语法简洁，编写高效，但相比C/C++运行慢很多。然而Python还有个重要的特性：它是一门胶水语言！Python可以很容易地扩展C/C++。OpenCV-Python就是用Python包装了C++的实现，背后实际就是C++的代码在跑，所以代码的运行速度跟原生C/C++速度一样快。 我举两个简单的例子就一目了然了：一个是读入图片，另一个是调整图片的对比度和亮度： 可以看到某些情况下Python的运行速度甚至好于C++，代码行数也直接少一半多！另外，图像是矩阵数据，OpenCV-Python原生支持Numpy，相当于Python中的Matlab，为矩阵运算、科学计算提供了极大的便利性。 人工智能浪潮近些年，人工智能相关技术的快速发展大家有目共睹，不必多说。在编程语言方面，更多人希望的是具备高效开发效率、跨平台、高度扩展性的语言，尤其是一些AI巨头优先推出支持Python语言的深度学习框架，如Facebook的PyTorch、Google的Tensorflow等，可以说Python是名副其实的“网红语言”了。 从TIOBE编程语言排行榜也可以看到，Python发展迅猛，已经逼近C++的份额。这个排行榜每月更新，我就不截图了，编写时TOP5：Java/C/C++/Python/C#。 人生苦短，我用Python 如果你搞科研用，果断放弃C++（Matlab？出门左拐） 如果你是快速原型开发，验证方案，果断放弃C++ 如果你懒的配置OpenCV环境，果断放弃C++ 如果你的程序是在支持Python的较高硬件环境下运行，果断放弃C++ 如果你担心Python写不了界面，那是你的问题o_o …. 除非你的程序是MFC或已经用C++编写其他模块或是嵌入式设备，那就用C++吧 “人生苦短，我用Python！！！” 安装 本教程编写时使用的软件版本是：OpenCV 3.x，Python 3.x。 要安装OpenCV，只需cmd下的一条指令： 1pip install opencv-python pip是Python的包管理器，如果你还没安装Python，强烈推荐安装Anaconda，它包含了大量的科学计算包，不用后期一个个安装。即使你已经装了Python也没有影响，Anaconda相当于虚拟环境，互不干扰。 安装步骤进入Anaconda官网，下载最新版本的安装文件，速度比较慢的话，可以去清华开源镜像站。 Windows版下载的是exe文件，双击可以直接安装，安装时记得勾选 Add Anaconda to my PATH environment variable，添加到环境变量中。 Linux版下载的是sh文件，下载完成后，终端切换到下载目录，执行bash Anaconda3-xx.sh，Linux版也会提示添加环境变量，记得输yes就行。 安装测试Python安装好之后，可以在cmd中输入python --version来查看Python的版本信息。对于OpenCV，打开Python的开发环境，输入import cv2，运行没有报错说明一切正常。要查看OpenCV的版本，可以： 1print(cv2.__version__) # '3.4.1' Python开发环境我用的是Visual Studio Code，也可以用PyCharm/Atom/Jupyter Notebook(Anaconda自带)，或者直接在命令行里敲，自己习惯就行。 常见问题 pip识别不了：环境变量中没有pip的目录，找到pip目录，添加到用户（或系统）变量的path中。 下载速度很慢：可到此处下载离线版。下载完成后，cmd切换到下载目录，输入 pip install 文件名安装。 学习软件为了便于学习OpenCV，我写了一个教学款软件LearnOpenCVEdu，目前只开发了一部分功能，有兴趣的童鞋可以支持一下噢😊 经验之谈：虽然从一开始我就推荐大家使用OpenCV-Python进行图像处理，但想要深入理解OpenCV，C++还是必须的，尤其是OpenCV源码！ 引用 本节源码 网络资料 OpenCV Docs官方文档 OpenCV 官方Github 官方英文教程：OpenCV-Python Tutorials LearnOpenCV、LearnOpenCV Github Numpy Quickstart Tutorial OpenCV 中文教程 书籍 Programming Computer Vision with Python、中文书 https://www.pyimagesearch.com/practical-python-opencv/ 名校视觉研究所/课程 卡内基梅隆大学 多伦多大学","categories":[{"name":"机器视觉","slug":"机器视觉","permalink":"http://www.codec.wang/categories/%E6%9C%BA%E5%99%A8%E8%A7%86%E8%A7%89/"}],"tags":[{"name":"OpenCV","slug":"OpenCV","permalink":"http://www.codec.wang/tags/OpenCV/"},{"name":"Python","slug":"Python","permalink":"http://www.codec.wang/tags/Python/"},{"name":"图像处理","slug":"图像处理","permalink":"http://www.codec.wang/tags/%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86/"}]},{"title":"Brand7 2.0更名\"品牌漆\"正式上架咯！","slug":"Brand7-2-0更名品牌漆正式上架咯！","date":"2017-11-26T11:04:32.000Z","updated":"2019-03-24T06:13:50.745Z","comments":true,"path":"brand7-2-release/","link":"","permalink":"http://www.codec.wang/brand7-2-release/","excerpt":"隔了一年更新，良心都有点痛了( ╯□╰ )","text":"隔了一年更新，良心都有点痛了( ╯□╰ ) 示威的人做的不对的话，引起示威的人呢？ ——《辩护人》 当初Brand7写完的时候，一直想写一个关于电影的APP，甚至做出了雏形：MovieBackdrops，可惜，时间不多，事情却很多。前段时间闭关，摸着自己的良心，终于把Brand7更新了一把，来看看更新内容吧： 品牌漆（Brand7）是一款Win10 UWP猜品牌的小游戏，里面涵盖了汽车、娱乐、时尚、生活、餐饮、科技、旅游七个类别的550个品牌。Ver2.0.1更新日志如下： 更名“品牌漆” 全新Logo 全新启动界面 新增50个品牌，现共550个品牌 全面中文版（英文被很多人吐槽看不懂( ╯□╰ )） 界面UI调整 可以在Win10应用商店中搜索“品牌漆”进行下载，或点击此处。 生命不息，折腾不止，Excelsior!","categories":[{"name":"Build篇","slug":"Build篇","permalink":"http://www.codec.wang/categories/Build%E7%AF%87/"}],"tags":[{"name":"Brand7","slug":"Brand7","permalink":"http://www.codec.wang/tags/Brand7/"},{"name":"品牌漆","slug":"品牌漆","permalink":"http://www.codec.wang/tags/%E5%93%81%E7%89%8C%E6%BC%86/"}]},{"title":"【视觉与图像】OpenCV篇：Python+OpenCV实用教程","slug":"Python-OpenCV教程（目录）","date":"2017-10-10T14:22:13.000Z","updated":"2019-12-26T10:13:46.533Z","comments":true,"path":"opencv-python/","link":"","permalink":"http://www.codec.wang/opencv-python/","excerpt":"目录","text":"目录 入门篇 简介与安装（了解安装OpenCV-Python） | 番外篇1：代码性能优化 基本元素-图片（图片载入/显示/保存） | 番外篇2：无损保存和Matplotlib使用 打开摄像头（打开摄像头捕获图片/播放保存视频） | 番外篇3：滑动条 图像基本操作（访问像素点/ROI/通道分离合并/图片属性） 颜色空间转换（颜色空间转换/追踪特定颜色物体） 阈值分割（阈值分割/二值化） | 番外篇4：Otsu阈值法 图像几何变换（旋转/平移/缩放/翻转） | 番外篇5：仿射变换与透视变换 绘图功能（画线/画圆/画矩形/添加文字） | 番外篇6：鼠标绘图 挑战任务：画动态时钟 | 拓展挑战：PyQt5编写GUI界面 基础篇 图像混合（算数运算/混合/按位运算） | 番外篇7：亮度与对比度 平滑图像（卷积/滤波/模糊/降噪） | 番外篇8：卷积基础(图片边框) 边缘检测（Canny/Sobel） | 番外篇9：图像梯度 腐蚀与膨胀（形态学操作/腐蚀/膨胀/开运算/闭运算） 轮廓 （寻找/绘制轮廓） | 番外篇10：轮廓层级 轮廓特征 （面积/周长/最小外接矩(圆)/形状匹配） | 番外篇11：凸包及更多轮廓特征 直方图（计算绘制直方图/均衡化） 模板匹配（大图中找小图） 霍夫变换（提取直线/圆） 挑战任务：车道检测","categories":[{"name":"机器视觉","slug":"机器视觉","permalink":"http://www.codec.wang/categories/%E6%9C%BA%E5%99%A8%E8%A7%86%E8%A7%89/"}],"tags":[{"name":"OpenCV","slug":"OpenCV","permalink":"http://www.codec.wang/tags/OpenCV/"},{"name":"Python","slug":"Python","permalink":"http://www.codec.wang/tags/Python/"},{"name":"图像处理","slug":"图像处理","permalink":"http://www.codec.wang/tags/%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86/"}]},{"title":"【利器】GitKraken：酷炫的Git GUI客户端","slug":"【利器】GitKraken：酷炫的Git GUI客户端","date":"2017-10-05T09:33:20.000Z","updated":"2019-03-24T06:13:50.744Z","comments":true,"path":"tools-gitkraken/","link":"","permalink":"http://www.codec.wang/tools-gitkraken/","excerpt":"不喜欢敲命令？那么这款酷炫的Git客户端让你逼格满满！","text":"不喜欢敲命令？那么这款酷炫的Git客户端让你逼格满满！ 真正的忘记是不需要努力的。——《大鱼海棠》 废话一段先：以前上班的时候，公司里版本管理系统用的是perforce，你应该、可能没听过( ╯□╰ )。总之，就是集中式版本管理系统，相比于git的分布式有很多缺陷，具体可以看“集中式vs分布式”。但作为一款商业软件，perforce提供的优秀客户端体验还是相当不错的。使用git后，一直都是敲命令的，一是因为习惯，毕竟码代码逼格高嘛，二是因为git的GUI客户端要不很丑，要不功能捉急，总之不想用。之后，体验了这个软件，又同类似的SourceTree对比了下，无奈，我，还是喜欢颜值高的~ o(￣▽￣)o另外，以前外教老师提问说《加勒比海盗2》中的那个怪物叫啥，阅片无数的我，那天竟然没回答上，装逼失败，所以对这只“挪威海怪kraken”影响特别深刻。好了，开始正题吧~ 官网/下载：GitKraken GitKraken对Windows/Linux/Mac三大主流平台都支持，其方便之处在于，它不需要安装配置，双击打开就可以了。打开之后，可以选择用Github账号登陆，需要Github授权： 打开/克隆/初始化GitKranken支持打开本地仓库，从指定的URL或Github、Gitlab、Bitbucket等上面直接克隆。前面我们已经用Github直接登陆了，所以，从Github克隆时，会直接列出你当前的所有仓库项目，非常方便。当然，也可以连接到Gitlab/Bitbucket平台： 初始化/新建项目也非常方便，在Init选项中，可以选择初始化一个本地仓库或类似Github之类的远程仓库。GitKraken初始化时还提供了.gitignore的文件的相关模板： 界面/功能打开一个仓库后，主界面如下图，酷炫简洁，顶部提供了常用的Git功能，就不细说了。我主要提及一下，如何进行版本差分： 在提交日志的主界面，如果要比较任意两个版本之间的差分，按住Ctrl键，选择要比较的版本，右边会自动列出两个版本之间所修改的文件，点击文件就可以看到diff了： 当然，最新版本（本文使用的是3.1版本）的GitKraken提供了Merge和Diff工具的自定义（File-Preferences-General中设置），比如说我最常用的Merge工具是WinMerge，就可以在这里配置。 抛砖引玉，大致介绍了一下，其实熟悉Git的话，这个工具使用起来还是蛮简单的~ o(￣▽￣)o 2019年3月19日更新：最近我一直用VSCode，集成的git功能再加上gitlens这款插件，体验也很棒。 生命不息，折腾不止，Excelsior!","categories":[{"name":"利器篇","slug":"利器篇","permalink":"http://www.codec.wang/categories/%E5%88%A9%E5%99%A8%E7%AF%87/"}],"tags":[{"name":"Git","slug":"Git","permalink":"http://www.codec.wang/tags/Git/"},{"name":"GitKraken","slug":"GitKraken","permalink":"http://www.codec.wang/tags/GitKraken/"}]},{"title":"【利器】七牛云：每月免费10G的图床","slug":"【利器】七牛云：每月免费10G的图床","date":"2017-09-18T11:55:38.000Z","updated":"2019-07-01T06:54:44.762Z","comments":true,"path":"tools-qiniuyun/","link":"","permalink":"http://www.codec.wang/tools-qiniuyun/","excerpt":"随着越来越多的人开始使用Markdown写自己的独立博客，一个好用稳定的图床是必不可少的了。","text":"随着越来越多的人开始使用Markdown写自己的独立博客，一个好用稳定的图床是必不可少的了。 对比在七牛云之前，我使用过国外的Cloud App和阿里云的OSS对象存储。 首先，国外的东西在国内稳定性和速度都是相对较差的，我试着在阿里云和Cloud App上上传同一张图片并生成外链，Cloud App要比阿里的加载速度延迟1-2s，阿里基本秒开。 阿里的OSS对象存储虽然很稳定，但是并不提供免费的空间。相对来说，七牛云提供的每月10G免费流量，对于博客来说，绰绰有余了。 另外，七牛云提供了诸多的图片处理接口，如水印、格式转换、缩放等，很实用，很强大。 使用注册并登陆七牛云，在七牛云的产品列表中，添加一个对象存储，如这里取名为picblog： 创建好之后，七牛云会自动生成一个测试域名： 这个域名就是你文件的前缀了。比如，我们点击”内容管理”，点击”上传文件”，选择一幅图片上传。上传完成后，复制该文件的外链地址： 这个地址就是你的外链地址辣，你可以在浏览器中直接访问，比如：mysql_demo 绑定域名添加二级域名七牛云默认的测试域名有时间限制，貌似一个月就过期不能用了。所以，你如果已经购买了域名的话，可以在这里绑定自己的二级域名，这样既好记又方便管理。 比如，这里我已经在万网上购买了ex2tron.xin的域名，这里我演示如何将七牛云的存储空间绑定pic.ex2tron.xin这个域名。 在七牛云的存储空间页面，点击”绑定域名”，只需要在加速域名处填写要绑定的域名，其他项保持默认即可： 1加速域名： pic.ex2tron.xin 创建后，系统会配置一段时间，等待处理完成，会显示一个诸如xxx.qiniudns.com的CNAME记录值，记下此值，后面要用到。 添加域名解析打开万网的域名控制台，添加一条CNAME的解析： 1234记录类型：CNAME主机记录：pic记录值：xxx.qiniudns.com# 其他选型保持默认 这样，你上传的图片外链就是：http://pic.ex2tron.xin/filename.png之类的了。 添加图片样式利用七牛云做图床的另外一个强大之处在于丰富的图片样式。点击”图片样式”-“新建图片样式”，七牛云提供了如下很多种场景： 比如，这里我们选择”指定宽高，强行缩放+打图片水印”，然后添加一个文字水印，可以调整文字的字体样式，位置等等： 调整好之后，为样式取个名称，如webpic，这样，只要在原来外链的后面添加-webpic就可以了： 1http:&#x2F;&#x2F;pic.ex2tron.xin&#x2F;filename.png-webpic 其中-这个连接符可以通过存储空间控制面板的”样式分隔符设置”中进行修改。 图床工具对于七牛云，每张图片都在网页端上传还是比较麻烦的，所以用一些图床客户端工具会更加快速。 这里推荐两款工具： MPic图床神器。打开软件后，设置好自己的AK和SK（可在七牛云的个人中心-密钥管理中看到）。MPic支持文件拖拽上传，点击复制就可以复制外链，非常方便： 生命不息，折腾不止，Excelsior!","categories":[{"name":"利器篇","slug":"利器篇","permalink":"http://www.codec.wang/categories/%E5%88%A9%E5%99%A8%E7%AF%87/"}],"tags":[{"name":"七牛","slug":"七牛","permalink":"http://www.codec.wang/tags/%E4%B8%83%E7%89%9B/"},{"name":"图床","slug":"图床","permalink":"http://www.codec.wang/tags/%E5%9B%BE%E5%BA%8A/"}]},{"title":"Hexo+Github Pages轻松搭博客(4)：自有服务器部署","slug":"Hexo-Github-Pages轻松搭博客-4-：自有服务器部署","date":"2017-09-13T14:11:12.000Z","updated":"2019-12-26T06:59:46.799Z","comments":true,"path":"hexo-blog-with-github-pages-4/","link":"","permalink":"http://www.codec.wang/hexo-blog-with-github-pages-4/","excerpt":"将博客放在Github上有很多优点，比如免费、易管理、免费xxx.github.io的域名等，但访问速度嘛，就很一般了。对于喜欢折腾的童鞋，如果有一台自己的服务器，也可以把博客部署在云上。","text":"将博客放在Github上有很多优点，比如免费、易管理、免费xxx.github.io的域名等，但访问速度嘛，就很一般了。对于喜欢折腾的童鞋，如果有一台自己的服务器，也可以把博客部署在云上。 之前我们购买了独立域名www.ex2tron.top，并将域名解析到了Github。现在我们要把博客放在云服务器上，并且将域名解析到这台服务器，好，开干！ 说明：以阿里云服务器为例，之前我已经使用apache部署了一个web应用，所以我后面会讲到apache如何配置多个域名。当然你也可以使用nginx，部署流程都类似。 服务器环境配置用ssh user@ip连接到服务器后，先更新下： 12sudo apt updatesudo apt upgrade 查看git有没有安装： 1git --version # 没安装的话：sudo apt install git 不建议使用root账号，所以这里添加一个名为git的新用户： 12adduser gitadduser git sudo # 添加到sudo中 切换到git用户，并新建用户目录： 123su git # 切换git用户cdmkdir .ssh &amp;&amp; cd .ssh 然后将本地PC上ssh的id_rsa.pub文件内容复制到该目录的authorized_keys文件中，可以直接使用vim编辑，也可以在本机PC上使用scp命令（新版Windows10都已经自带ssh和scp等工具，可参考：如何使用Windows 10的OpenSSH Client和Server）： 1scp .ssh/id_rsa.pub user@ip:/home/git/.ssh/authorized_keys 这个时候可以退出ssh连接，并使用git用户直接登录了： 1ssh git@ip Git远程仓库及同步 此处可参考我之前的Blog：搭建自己的Github/Git服务器 跟GitHub一样，我们需要建一个博客的远程仓库。在git用户的主目录下创建仓库目录： 1234mkdir /home/git/hexoblog.gitsudo chown -R git:git hexoblog.git # 不修改权限的话，无法推送cd /home/git/hexoblog.gitgit init --bare # 初始化仓库 接下来需要修改本地Hexo的配置文件_config.yml。首先将url改成你的服务器公网ip或域名： 1url: http:&#x2F;&#x2F;www.ex2tron.top&#x2F; 其次在deploy项这里，如果你将博客推送到多个平台的话，直接新增一条就行： 123deploy:- type: git repo: git@47.101.xxx.xxx:&#x2F;home&#x2F;git&#x2F;hexoblog.git 现在可以运行hexo g -d正常push了。 如果hexo d推送的时候出现如下错误： 12remote: fatal: Unable to create temporary file &#39;&#x2F;home&#x2F;git&#x2F;hexoblog.git&#x2F;.&#x2F;objects&#x2F;pack&#x2F;tmp_pack_XXXXXX&#39;: Permission deniedfatal: sha1 file &#39;&lt;stdout&gt;&#39; write error: Broken pipe 说明是git权限的原因，你有可能少执行了这句话噢：sudo chown -R git:git hexoblog.git apache2配置首先自然是安装apache2咯： 1sudo apt install apache2 在/var/www/下面创建网站的根目录： 1sudo mkdir /var/www/html/hexoblog 正常来说，这是我们第一次使用apache配置，后面会讲到我的情况。编辑apache2的配置文件： 1sudo vim /etc/apache2/sites-available/000-default.conf 找到DocumentRoot项，并做如下更改： 1DocumentRoot /var/www/html/hexoblog 最后重启apache生效： 1sudo service apache2 restart 前面提到过，我已经在apache2配置过一个web应用和域名了，这个时候可以在conf文件中新增一项配置： 1234567891011121314# 之前的：&lt;VirtualHost *:80&gt; ......&lt;&#x2F;VirtualHost&gt;# 新增的：&lt;VirtualHost *:80&gt; ServerName www.ex2tron.top ServerAlias www.ex2tron.top DocumentRoot &#x2F;var&#x2F;www&#x2F;html&#x2F;hexoblog&#x2F; &lt;Directory &quot;&#x2F;var&#x2F;www&#x2F;html&#x2F;hexoblog&#x2F;&quot;&gt; Order deny,allow Allow from all &lt;&#x2F;Directory&gt;&lt;&#x2F;VirtualHost&gt; 创建Git钩子现在远程仓库创建好了，但是需要将Hexo的静态HTML文件传送到/var/www/html/hexoblog下面才行。切换到远程仓库hexoblog.git目录下面： 1cd /home/git/hexoblog.git/hooks/ 创建并编辑一个新的钩子文件： 12sudo touch post-receivesudo vim post-receive 在其中加入两行： 12#!/bin/bashgit --work-tree=/var/www/html/hexoblog --git-dir=/home/git/hexoblog.git checkout -f 赋予可执行权限给文件： 1sudo chmod +x post-receive 最后一定要确保git用户有权限操作博客目录： 1sudo chown git:git -R /var/www/html 这样，每次hexo d的时候就会自动同步文件到/var/www/html/hexoblog/博客目录下。此时，访问www.ex2tron.top便可以浏览你的博客辣，当然别忘了将你的域名解析到服务器IP噢，awesome！ 引用 Hexo+Github Pages轻松搭博客(3)：绑定独立域名 apache解析多个域名 生命不息，折腾不止，Excelsior!","categories":[{"name":"Build篇","slug":"Build篇","permalink":"http://www.codec.wang/categories/Build%E7%AF%87/"}],"tags":[{"name":"Hexo","slug":"Hexo","permalink":"http://www.codec.wang/tags/Hexo/"},{"name":"Github","slug":"Github","permalink":"http://www.codec.wang/tags/Github/"},{"name":"阿里云","slug":"阿里云","permalink":"http://www.codec.wang/tags/%E9%98%BF%E9%87%8C%E4%BA%91/"}]},{"title":"Hexo+Github Pages轻松搭博客(3)：绑定独立域名","slug":"Hexo-Github-Pages轻松搭博客-3：绑定独立域名","date":"2017-09-13T13:25:24.000Z","updated":"2019-04-04T13:55:07.944Z","comments":true,"path":"hexo-blog-with-github-pages-3/","link":"","permalink":"http://www.codec.wang/hexo-blog-with-github-pages-3/","excerpt":"嫌username.github.io不够高大上？？那就来个高大上的独立域名吧。","text":"嫌username.github.io不够高大上？？那就来个高大上的独立域名吧。 购买域名域名可以去很多地方购买，非.com/.cn的域名也比较便宜，我这里以万网为例，打开万网主页： 查找你想购买的域名，比如我购买``ex2tron.top`这个域名。.top域名的价格还是很便宜的，划算： 购买需要登陆阿里云的账号。购买成功后，按照提示进行实名认证和拍照备案，认证过程需要几天。 域名解析域名认证完成后，登陆阿里云控制台，在左侧导航栏找到”域名与网站（万网）”——“云解析DNS”： 选择你的域名，点击”解析设置”，我们添加三条解析： 记录类型：CNAME，主机记录：www，路线：默认，记录值：username.github.io 记录类型：A，主机记录：@，路线：默认，记录值：192.30.252.153 记录类型：A，主机记录：@，路线：默认，记录值：192.30.252.154 （图上文字小的话，可以点击查看大图） 绑定域名设置完成后，在本地的hexo博客的source目录下，新建一个名为CNAME的文件（没有任何后缀），编辑文件内容为你的域名，如ex2tron.top。这里如果在域名上加www的话，访问时会跳转到www.ex2tron.top，为了简洁起见，我这里就不加了。 配置完成后，重新发布博客就可以用独立域名ex2tron.top来访问博客辣( •̀ ω •́ )✧： 12hexo cleanhexo g -d 引用 Hexo个人免费博客(五) 使用自己的域名 生命不息，折腾不止，Excelsior!","categories":[{"name":"Build篇","slug":"Build篇","permalink":"http://www.codec.wang/categories/Build%E7%AF%87/"}],"tags":[{"name":"Hexo","slug":"Hexo","permalink":"http://www.codec.wang/tags/Hexo/"},{"name":"Github","slug":"Github","permalink":"http://www.codec.wang/tags/Github/"}]},{"title":"Hexo+Github Pages轻松搭博客(2)：在Github上部署","slug":"Hexo-Github-Pages轻松搭博客-2：在Github上部署","date":"2017-09-13T12:15:47.000Z","updated":"2019-04-04T13:53:49.383Z","comments":true,"path":"hexo-blog-with-github-pages-2/","link":"","permalink":"http://www.codec.wang/hexo-blog-with-github-pages-2/","excerpt":"使用免费的Github Pages服务或者部署在自己服务器上，别人就可以访问你的博客啦！","text":"使用免费的Github Pages服务或者部署在自己服务器上，别人就可以访问你的博客啦！ 关联Github首先登陆Github，没有账号的话，先注册一个。新建一个名为username.github.io的仓库，username必须与你的账户名相同，比如我的就是ex2tron.github.io，这就是你博客的域名地址了（绑定独立域名之后再说）。新建时注意勾选”Initialize this repository with a README“，因为这个仓库必须不能为空。 如果你是git新用户的话，推荐看：廖雪峰的Git教程-远程仓库 接下来打开博客目录下的_config.yml配置文件，定位到最后的deploy选项，修改如下： 1234deploy: type: git repository: git@github.com:ex2tron/ex2tron.github.io.git branch: master 注意冒号后面有个空格，不然会出错滴~配置好之后，使用下面的命令就可以部署到Github上了： 123$ hexo clean$ hexo g$ hexo d 这样通过Github提供的域名地址（如我的：https://ex2tron.github.io）就可以访问你的博客了，简单快速高效！ 发布新博客博客搭建起来之后，就可以用Markdown写博客辣，使用下面的命令，创建新博客（如名为：我的第一篇博客）： 1$ hexo new '我的第一篇博客' 此命令会在博客目录\\source\\_posts\\下生成“我的第一篇博客.md”文件，这就是你的博客源文件啦，文件开头如下，记得冒号后面有空格噢，不然会出错： 12345---title: 我的第一篇博客date: 2017-09-13 20:15:47tags: #文章标签，格式：[1,2,3]--- 不熟悉Markdown语法的可以看：Markdown 语法说明。写完之后依然使用之前的三条命令发布： 123$ hexo clean$ hexo g$ hexo d 后面两条指令也可以简化为一条： 1$ hexo g -d 常出现的问题 在hexo d进行部署时，如果出现ERROR Deployer not found: git的问题，可以先用下面的命令修复： 1$ npm install hexo-deployer-git --save 如果你没配置过ssh导致部署失败（可以通过ssh -T username@example.com来测试ssh有无配置成功），可以参考这篇文章：针对github权限导致hexo部署失败的解决方案 生命不息，折腾不止，Excelsior!","categories":[{"name":"Build篇","slug":"Build篇","permalink":"http://www.codec.wang/categories/Build%E7%AF%87/"}],"tags":[{"name":"Hexo","slug":"Hexo","permalink":"http://www.codec.wang/tags/Hexo/"},{"name":"Github","slug":"Github","permalink":"http://www.codec.wang/tags/Github/"}]},{"title":"Hexo+Github Pages轻松搭博客(1)：安装Hexo","slug":"Hexo-Github-Pages轻松搭博客-1：安装Hexo","date":"2017-09-13T08:07:06.000Z","updated":"2019-04-04T13:19:26.500Z","comments":true,"path":"hexo-blog-with-github-pages-1/","link":"","permalink":"http://www.codec.wang/hexo-blog-with-github-pages-1/","excerpt":"想用Github Pages轻松搭建自己的博客，用Hexo，10分钟！","text":"想用Github Pages轻松搭建自己的博客，用Hexo，10分钟！ 废话区域：我在接触Hexo（可以读作Hack So）之前，绝对没少尝试建立一个完全自由、自己说了算的独立博客：WordPress定位重量级，功能强大，生成的是动态网站，依赖数据库……太繁琐了，放弃而Jekyll和Hexo都是静态建站工具，但Jekyll的依赖项也很多，也不简约，不想用最后才是名气相对不高的Hexo，相信我，熟练的情况下，10分钟就可以搭出来。 简介Hexo是一个免费的静态Blog生成工具。简单来说，就是把你写的Markdown博客文件生成静态网页，把这个网页放在Github或者你自己的服务器上就可以快速访问了。软件界，从来不缺自动化工具(ง •_•)ง 安装官网文档：Hexo Docs Hexo安装前，你的电脑上需要先有下面这两个东西： Node.js Git 如果已经安装了的话，命令行下一句话就好啦： 1$ npm install -g hexo-cli 初始化博客目录在你的本地新建一个存放博客的目录，比如”D:\\MyHexoBlog“，然后在这个目录右键，选择”Git Bash Here“，输入下面两条命令进行初始化： 12$ hexo init$ npm install 初始化完成之后，你的目录结构应该是这样的： 12345678.├── _config.yml├── package.json├── scaffolds├── source| ├── _drafts| └── _posts└── themes 如果没有出错的话，继续执行下面的指令启动服务： 12$ hexo g $ hexo s 启动之后，在浏览器中访问：http://localhost:4000/，是不是看到了漂亮的Hexo博客页面了。不过目前这个博客还是运行在你本机上的，下篇我们看一下怎么样让别人也能访问这个博客。 引用 Hexo Docs Hexo+Github搭建个人博客(一)——开始搭建 生命不息，折腾不止，Excelsior!","categories":[{"name":"Build篇","slug":"Build篇","permalink":"http://www.codec.wang/categories/Build%E7%AF%87/"}],"tags":[{"name":"Hexo","slug":"Hexo","permalink":"http://www.codec.wang/tags/Hexo/"},{"name":"Github","slug":"Github","permalink":"http://www.codec.wang/tags/Github/"}]},{"title":"【利器】用VS Code写Markdown","slug":"【利器】用VSCode写Markdown","date":"2017-09-11T07:11:22.000Z","updated":"2019-03-24T06:13:50.746Z","comments":true,"path":"tools-markdown-in-vscode/","link":"","permalink":"http://www.codec.wang/tools-markdown-in-vscode/","excerpt":"Markdown以其简洁、优雅整齐的风格，成为目前非常流行的博客文件格式。甚至有人说：每个人都应该用Markdown写博客","text":"Markdown以其简洁、优雅整齐的风格，成为目前非常流行的博客文件格式。甚至有人说：每个人都应该用Markdown写博客。关于Markdown相较富文本的优势，我就不细说了。 Markdown编辑器支持Markdown的工具有很多，大家可以参考网上，如这篇文章：码字必备：18 款优秀的 Markdown 写作工具 | 2015 年度盘点。就我自己目前在Windows上使用的而言有：简书、有道云笔记、Typora、VSCode 简书本身就是一个博客平台，有道云笔记是类似OneNote和印象笔迹的应用。如果你已经在使用这两个平台的话，就不用多说了。但如果只是想用一个单纯的Markdown编辑器的话，推荐极致简洁的Typora。虽说界面简洁，但功能强大，不仅内置了常见的一些Markdown样式，还支持PDF/HTML等多种格式导出，我常用的就是Typora： 你是一枚文青的话，千万不要错过这款编辑器。不过，对于程序猿来说，VSCode才显得更有味道。 用VSCode写MarkdownVSCode是目前很火的一款编辑器，就不过多介绍了。现在版本的VSCode默认已经支持Markdown预览，无需下载插件。用VSCode打开md文件或将当前文件更改为Markdown格式就可以开始书写了： VSCode支持两种预览方式： 按下Ctrl+K V，像上图一样左右同步实时预览 按下Ctrl+Shift+V，只预览最终渲染结果 如上图，编写和预览界面是实时同步的，不需要的话，可以按下Ctrl+,组合键，添加如下两条设置： 12\"markdown.preview.scrollEditorWithPreview\": false,\"markdown.preview.scrollPreviewWithEditorSelection\": false 另外，目前VSCode预览样式中，中文的显示很别扭。所以可以下载第三方的CSS样式，这里推荐Github风格的CSS 下载完成后，配置CSS文件的设置如下即可： 123\"markdown.styles\": [ \"file:///D:/markdown-github.css\"] 另外，VSCode中有很多Markdown相关的插件，如Markdown All in One和Markdown Theme Kit等，大家可以下载下来尝试一下哈！ 引用Markdown editing with Visual Studio Code 生命不息，折腾不止，Excelsior!","categories":[{"name":"利器篇","slug":"利器篇","permalink":"http://www.codec.wang/categories/%E5%88%A9%E5%99%A8%E7%AF%87/"}],"tags":[{"name":"Markdown","slug":"Markdown","permalink":"http://www.codec.wang/tags/Markdown/"},{"name":"VSCode","slug":"VSCode","permalink":"http://www.codec.wang/tags/VSCode/"}]},{"title":"【利器】MyCLI：自动补全和语法高亮的MySQL命令行工具","slug":"【利器】MyCLI：自动补全和语法高亮的MySQL命令行工具","date":"2017-09-11T06:32:14.000Z","updated":"2019-03-24T06:13:50.746Z","comments":true,"path":"tools-mycli/","link":"","permalink":"http://www.codec.wang/tools-mycli/","excerpt":"mycli是MySQL命令行工具，支持关键字语法高亮和自动补全，看上面的动图你就知道了。","text":"mycli是MySQL命令行工具，支持关键字语法高亮和自动补全，看上面的动图你就知道了。 mycli不仅能在命令行中提示MySQL的关键字，更牛掰的是数据库名、表名、字段名都可以提示，非常方便。如果你经常在命令行里码MySQL命令，相信这款工具一定会让你满意。 官网：MyCLI 安装其实mycli是一个Python的包，所以你已经安装了Python(pip)的话，用下面一条指令就好了： 1pip install mycli 如果出现问题，可以参考官网，有详细的说明。 使用安装好之后，在命令行下，将以往登陆MySQL用的mysql换成mycli，不用加-p选项就可以了： 好了，大家觉得好用的话，欢迎扩散噢！ 生命不息，折腾不止，Excelsior!","categories":[{"name":"利器篇","slug":"利器篇","permalink":"http://www.codec.wang/categories/%E5%88%A9%E5%99%A8%E7%AF%87/"}],"tags":[{"name":"MyCLI","slug":"MyCLI","permalink":"http://www.codec.wang/tags/MyCLI/"},{"name":"MySQL","slug":"MySQL","permalink":"http://www.codec.wang/tags/MySQL/"}]},{"title":"Qt+OpenCV环境搭建","slug":"Qt-OpenCV环境搭建","date":"2017-07-27T00:17:00.000Z","updated":"2019-03-24T06:13:50.746Z","comments":true,"path":"qt-opencv-installation-guide/","link":"","permalink":"http://www.codec.wang/qt-opencv-installation-guide/","excerpt":"Windows下的配置 念念不忘，必有回响。——《一代宗师》 我电脑上安装的Qt版本信息：Qt 5.8/Qt Creator 4.2.1/MinGW 5.3.0","text":"Windows下的配置 念念不忘，必有回响。——《一代宗师》 我电脑上安装的Qt版本信息：Qt 5.8/Qt Creator 4.2.1/MinGW 5.3.0 Qt官方下载 首先用CMake编译OpenCV3.2，参考：CMake编译OpenCV3.2（Qt平台）。针对Qt5.8+OpenCV3.2我已经编译好了，可以直接下载。 编译好之后，把下面三个文件夹提取出来放在一个新目录下，比如：D:\\QtOpenCV OpenCV安装目录下的build\\include文件夹 CMake生成后的lib文件夹 CMake生成后的bin文件夹 放好之后，将上图bin的路径（D:\\QtOpenCV\\bin）添加到系统环境变量，此时最好重启资源管理器或注销一下，以使得环境变量更改生效。 然后打开Qt的pro文件，在SOURCES前面添加如下的OpenCV的依赖项： 1234567891011# INCLUDEPATH 头文件路径INCLUDEPATH += D:\\QtOpenCV\\include\\opencv\\ D:\\QtOpenCV\\include\\opencv2\\ D:\\QtOpenCV\\include# LIBS 库文件，-L指定库路径 -llib指定程序用到的lib库# 使用下面方法包含所有库# LIBS += -L D:\\QtOpenCV\\lib\\libopencv_*.a# 或使用下面方法只包含要使用的库LIBS += -L D:\\QtOpenCV\\lib\\ -llibopencv_highgui320.dll.a\\ -llibopencv_imgproc320.dll.a 这样就配置完成啦，这里有一些OpenCV的示例代码，可以参考一下：C++ OpenCV示例 Ubuntu下的配置Ubuntu下如果不用CMake自行安装的话，就简单多了，在终端里面输入下面几条指令就搞定了： 12345# 安装Qt5sudo apt-get install cmake qt5-default qtcreator# 安装opencvsudo apt-get install libopencv-devsudo apt-get install libcv-dev 同样，在Qt的pro文件中添加OpenCV的依赖项就可以调用了： 12345678INCLUDEPATH += /usr/include\\ /usr/include/opencv\\ /usr/include/opencv2LIBS += -L/usr/lib\\ -llibopencv_highgui\\ -llibopencv_core\\ -llibopencv_imgproc\\ -llibopencv_calib3d 如果LIBS像上面这样加不进去的话，可以一个一个加，比如： 12LIBS += -L/usr/lib/libopencv_highgui.soLIBS += -L/usr/lib/libopencv_core.so 另外，不同版本和不同平台库的位置可能不同，比如树莓派下，库文件可能在： 1LIBS += -L/usr/lib/arm-linux-gnueabihf\\ 生命不息，折腾不止，Excelsior!","categories":[{"name":"Build篇","slug":"Build篇","permalink":"http://www.codec.wang/categories/Build%E7%AF%87/"}],"tags":[{"name":"CMake","slug":"CMake","permalink":"http://www.codec.wang/tags/CMake/"},{"name":"OpenCV","slug":"OpenCV","permalink":"http://www.codec.wang/tags/OpenCV/"},{"name":"Qt","slug":"Qt","permalink":"http://www.codec.wang/tags/Qt/"}]},{"title":"CMake编译OpenCV3.2（Qt平台）","slug":"CMake编译OpenCV3-2（Qt平台）","date":"2017-07-26T14:25:29.000Z","updated":"2019-03-27T12:11:40.238Z","comments":true,"path":"cmake-make-opencv/","link":"","permalink":"http://www.codec.wang/cmake-make-opencv/","excerpt":"最近，需要在Windows下搭建一个Qt和OpenCV的环境，可惜官方OpenCV3.2的build里面并不是针对Qt平台的。所以，需要用CMake编译OpenCV的源码。","text":"最近，需要在Windows下搭建一个Qt和OpenCV的环境，可惜官方OpenCV3.2的build里面并不是针对Qt平台的。所以，需要用CMake编译OpenCV的源码。 CMake V3.9.0 OpenCV V3.2.0 Qt V5.8.0 所有的大人都曾经是小孩，虽然只有少数的人记得。 All grown-ups were once children… but only few of them remember it.《小王子》 编译步骤安装完CMake后，打开cmake-gui，如下图所示： 选择OpenCV3.2源码所在位置，我的是在：D:\\ProgramFiles\\OpenCV3\\sources 选择编译生成的目录 最后点击”Configure”，如下图所示： 选择“MinGW Makefiles”并勾选“Specify native compilers”，点击“Next”： 这里分别选择Qt安装目录下gcc和g++的路径，点击“Finish”，等待配置完成。 配置完成后，勾选“WITH_OPENGL”和“WITH_QT”，点击“Generate”就可以了。如果发生错误： 将Qt的相关路径配置如下： 先点击“Configure”，再次点击“Generate”就可以生成了。然后在cmd下切换到生成的目录，我的是D:\\OpenCVBuild，执行命令：mingw32-make开始编译（25分钟左右）： 编译好之后，再执行mingw32-make install就完成了。 生命不息，折腾不止，Excelsior!","categories":[{"name":"Build篇","slug":"Build篇","permalink":"http://www.codec.wang/categories/Build%E7%AF%87/"}],"tags":[{"name":"CMake","slug":"CMake","permalink":"http://www.codec.wang/tags/CMake/"},{"name":"OpenCV","slug":"OpenCV","permalink":"http://www.codec.wang/tags/OpenCV/"},{"name":"Qt","slug":"Qt","permalink":"http://www.codec.wang/tags/Qt/"}]},{"title":"【云服务】搭建自己的Github/Git服务器","slug":"【云服务】搭建自己的Github-Git服务器","date":"2017-06-04T11:38:56.000Z","updated":"2019-03-25T02:20:42.719Z","comments":true,"path":"set-up-your-own-git-server/","link":"","permalink":"http://www.codec.wang/set-up-your-own-git-server/","excerpt":"Github是目前最流行的托管开源代码的远程仓库，但如果想要创建私有仓库，不公开代码的话，Github是收费的。","text":"Github是目前最流行的托管开源代码的远程仓库，但如果想要创建私有仓库，不公开代码的话，Github是收费的。但像我们这种穷苦的孩子，只能选择自己搭一个Git服务器咯。 2019-1-8更新：微软收购Github后，私有代码库从此免费！！喜大普奔啊！ 我们需要一台Linux电脑，可以当作局域网内的Github。当然如果你有阿里云之类的服务器的话就更好了，有网的地方就可以push/pull代码，我这里以自己的本地Ubuntu电脑为例： 安装Git1sudo apt-get install git 一句话，没啥好说的(+_+) 新建git用户并配置创建用于运行Git服务的用户git，新建账号时，会提示你输入该用户的密码，其他保持默认即可： 1sudo adduser git adduser指令会在/home目录下生成以git名命名的文件夹，代表git用户目录： 1ls /home 在git用户目录下新建.ssh文件夹和authorized_keys文件： 12mkdir /home/git/.sshtouch /home/git/.ssh/authorized_keys 熟悉ssh的同学应该知道authorized_keys文件用于收集所有需要登录到此Git服务器的客户端公钥，一行一个。如果你已经生成过ssh密钥的话，Windows系统会在C:\\Users\\用户名\\.ssh\\，Linux系统一般在/home/user/.ssh/下，没有生成的话，可以用下面的指令生成： 1ssh-keygen -t rsa 将id_rsa.pub中的内容拷贝到服务器的authorized_keys文件中： 1echo \"pub_key_content\" &gt;&gt; /home/git/.ssh/authorized_keys 新建仓库现在其实就跟Github一样的流程了，首先在建立一个新仓库，比如在/home/git/repos下： 123mkdir /home/git/reposcd /home/git/repos/sudo git init --bare sample.git 然后将sample.git仓库的用户和组都改成git： 1sudo chown -R git:git sample.git 这样就建好了远程仓库，接下来你可以将已有的本地仓库关联或者克隆到本地： 1git remote add origin git@server_ip:/home/git/repos/sample.git 1git clone git@server_ip:/home/git/repos/sample.git 还有点小问题~前面新建用户的步骤完成后，git用户是可以直接在终端登陆服务器的，因此需要禁止git用户登陆shell，编辑/etc/passwd文件，找到git的一行： 1git:x:1001:1001:,,,:/home/git:/bin/bash 将启动环境改为： 1git:x:1001:1001:,,,:/home/git:/usr/bin/git-shell git-shell是一个每次一登录就退出的程序，这样配置之后，git用户可以使用ssh管理仓库，但无法登陆shell。 引用 廖雪峰Git教程 生命不息，折腾不止，Excelsior!","categories":[{"name":"Build篇","slug":"Build篇","permalink":"http://www.codec.wang/categories/Build%E7%AF%87/"}],"tags":[{"name":"Build","slug":"Build","permalink":"http://www.codec.wang/tags/Build/"},{"name":"Github","slug":"Github","permalink":"http://www.codec.wang/tags/Github/"},{"name":"Git Sever","slug":"Git-Sever","permalink":"http://www.codec.wang/tags/Git-Sever/"}]}]}