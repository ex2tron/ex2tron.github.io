[{"title":"【片单】漫威宇宙电影合集","date":"2017-12-05T14:44:35.000Z","path":"2017/12/05/【片单】漫威宇宙电影合集/","text":"十年，17部电影，超过130亿美元的总票房，漫威宇宙电影合集下载！！！ Excelsior! ——斯坦·李 漫威电影宇宙MCU的成绩有目共睹，在十周年《复仇者联盟3》上映之前，来补一波漫威宇宙的电影吧（点击片名即可下载）！ MCU观影指南： 第一阶段： 2008《钢铁侠1》、 2008《无敌浩克》 2010《钢铁侠2》 2011《雷神1》 2011《美国队长1：复仇者先锋》 2012《复仇者联盟1》 第二阶段： 2013《钢铁侠3》 2013《雷神2：黑暗世界》 2014《美国队长2：冬日战士》 2014《银河护卫队1》 2015《复仇者联盟2：奥创纪元》 2015《蚁人》 第三阶段： 2016《美国队长3：内战》 2016《奇异博士》 2017《银河护卫队2》 2017《蜘蛛侠：英雄归来》 2017《雷神3：诸神黄昏》(上映中) 2018《复仇者联盟3：无限战争》(即将上映) 无限战争！！！","tags":[{"name":"Lens","slug":"Lens","permalink":"https://ex2tron.github.io/tags/Lens/"},{"name":"片单","slug":"片单","permalink":"https://ex2tron.github.io/tags/片单/"},{"name":"漫威","slug":"漫威","permalink":"https://ex2tron.github.io/tags/漫威/"},{"name":"Marvel","slug":"Marvel","permalink":"https://ex2tron.github.io/tags/Marvel/"},{"name":"复仇者联盟","slug":"复仇者联盟","permalink":"https://ex2tron.github.io/tags/复仇者联盟/"}]},{"title":"Brand7 2.0更名\"品牌漆\"正式上架咯！","date":"2017-11-26T11:04:32.000Z","path":"2017/11/26/Brand7-2-0更名品牌漆正式上架咯！/","text":"隔了一年更新，良心都有点痛了( ╯□╰ ) 示威的人做的不对的话，引起示威的人呢？ ——《辩护人》 当初Brand7写完的时候，一直想写一个关于电影的APP，甚至做出了雏形：MovieBackdrops，可惜，时间不多，事情却很多。前段时间闭关，摸着自己的良心，终于把Brand7更新了一把，来看看更新内容吧： 品牌漆（Brand7）是一款Win10 UWP猜品牌的小游戏，里面涵盖了汽车、娱乐、时尚、生活、餐饮、科技、旅游七个类别的550个品牌。Ver2.0.1更新日志如下： 更名“品牌漆” 全新Logo 全新启动界面 新增50个品牌，现共550个品牌 全面中文版（英文被很多人吐槽看不懂( ╯□╰ )） 界面UI调整 新旧版对比：中文版 完成界面 新的启动界面 分享界面 可以在Win10应用商店中搜索“品牌漆”进行下载，或点击此处。","tags":[{"name":"Code","slug":"Code","permalink":"https://ex2tron.github.io/tags/Code/"},{"name":"Brand7","slug":"Brand7","permalink":"https://ex2tron.github.io/tags/Brand7/"},{"name":"品牌漆","slug":"品牌漆","permalink":"https://ex2tron.github.io/tags/品牌漆/"}]},{"title":"软件+影视汁源贴(updating...)","date":"2017-11-15T11:53:46.000Z","path":"2017/11/15/软件-影视汁源贴-updating/","text":"经常有人跟我要一些软件和电影的资源，毕竟我是老司机( ╯□╰ )特此整理，有时间会不断更新。 I’ve always believed with hard work and a little bit of luck, it’s only a matter of time before I’m discovered! ——《Ratatouille》我总是相信勤奋与努力外加一点点幸运就能换来成功，我的天分被发现只是时间的问题。——《料理鼠王》 软件汁源首先列出一些常用网站，后面我只列出常用的软件和官网，请大家优先选择官网进行下载，因为官网版本一般都是最新的，也比较安全。官网进不去，可以点击我给出的版本下载： 常用资源站 Windows装机必备、网易开源镜像站 善用佳软、精品绿色便携软件 俺下载、逛电驴、ED2000资源共享 微软官方系统 Windows 10创意者更新秋季版：64位(4.42 GB)、32位(3.31 GB) Windows 7 With SP1 简体中文旗舰版：64位(3.19 GB)、32位(2.47 GB) 激活工具：优先OEM10，密码：c6wz Office办公套件 Office Pro Plus 2016批量授权版：64位、32位 Visio Pro 2016 批量授权版：64位、32位 Office Pro Plus 2016 即点即用版 Visio Pro 2016 即点即用版 激活工具：优先OEM10，密码：c6wz 开发工具 Visual Studio 2017 Community 15.4：官网 Android Studio：3.0、2.3.3 Qt 5.8.0 mingw：官网 Matlab：R2017a x64 dvd1、R2017a x64 dvd2、破解工具 Python相关： 官网、Python相关包（如tensorflow）：源1、源2 Anaconda：官网、5.0.1 Python 3.6 x86_x64、5.0.1 Python 3.6 x86 MySQL：官网、MySQL Installer 5.7.20 WampServer：官网、3.1.0 x64、3.1.0 x86 开发组件： 串口抓包工具AccessPort：官网、1.37 protobuf：官网(需翻墙) ffmpeg：官网 媒体 Adobe CC 2017：精简版 密码：f7yt 实用工具我平常整理的一些各类有用的工具：密码：806j 影视汁源资源站 6v电影网 字幕组（原人人影视） ED2000资源共享 电影天堂 飘花电影网 电影榜单 IMDB电影排行榜：TOP250 豆瓣电影排行榜：TOP250 全球电影票房排行榜：中文版、英文版 电影合集 诺兰电影合集 漫威电影合集","tags":[{"name":"Lens","slug":"Lens","permalink":"https://ex2tron.github.io/tags/Lens/"},{"name":"软件","slug":"软件","permalink":"https://ex2tron.github.io/tags/软件/"},{"name":"影视","slug":"影视","permalink":"https://ex2tron.github.io/tags/影视/"}]},{"title":"计量史：时间之旅","date":"2017-11-08T13:35:51.000Z","path":"2017/11/08/计量史：时间之旅/","text":"这篇文章也是我一年前研一《计量史》课上的小论文，感觉不错，也放在博客上，哈哈。 Whoever find a friend, find a treasure. ——《Cars2》一个朋友，一个宝。——《汽车总动员2》 宇宙大爆炸的那一刻就注定了这个世界充满着平凡与不平凡，宇宙的变迁、星云的诞生，看似杂乱无章但又井然有序，一切都注入了时间的长河中。而随着一个奇迹：生命的诞生，人类意识、情感的快速升华，人类开始认识到了“时间”，并随着时间的流逝，逐渐认识这个世界。通过自然界的周期现象——日出日落，季节的轮换，潮汐的涨落，来有意识地进行活动。于是，当我们尝试去考量时间的时候，就促使了时间计量产生。作为《时间之谜》的阅读报告，我摘录了一部分原书材料来表述时间计量的科学演变，最后结合自己的经历和见识表达了自己对科学研究和时间计量意义的一些想法。 时间，从来就不是一个很好形容或定义的概念。每当我们想去探讨它时，总会陷入困境，就像有人让你解释你是怎么走路的一样。《时间之谜》 从实用和客观的角度探讨了时间计量的科学演变。通过人们尝试对时间进行测定的手段、时间的使用以及时间对于数学、物理学、天文学的影响等各种客观事实材料，来启发我们对于时间的思考。 I. “时间”的科学演变如今，科学一词早已被大众所认知，并赋予崇高的含义。我想大多数人孩童时候的梦想就是成为一名科学家。而Science一词最早出现在19世纪，像牛顿当时被称为自然哲学家，而非科学家。可以看出，科学溯源于大自然规律的必然性。那么“时间”从哪儿来的呢？ 远古人民往往利用自然界的周期现象——日出日落，季节轮换，甚至潮汐的涨落来进行着人类的日常生活。我小时候在家乡的时候，就是鸡鸣时刻起床，黄昏时刻结束农耕作业。不同于现在城市的生活，那时的我们并不会过分关注具体的“钟表时间”。这种主导人们规律作息生活的自然之力，无疑引起了远古人们对它的神秘、畏惧和崇拜之感。于是，人们内心的欲望和探索心理驱动着我们去开始去关心天文和自然。 然而时间不同于长度、质量或温度，“我们能辨别距离，感受到重量和温度，但人体的任何感官都不能感知时间，我们见不到它，听不到它，嗅不到它，也尝不到它，而只能通过意识，或者通过观测它的效应来理解它。”（《时间之谜》）观测，这就是最开始单纯的“自然界的钟”的产生，也就是通过有意识地观测太阳、月亮和星星的这种大的、显式的运动，来确立时间的原型。之后人们认识到了运动的规律，产生了能否利用以恒定速率运转物体的时间间隔来对时间单位进行计数的问题，于是便有了“钟”。中国古代出现的利用水的推动力造的水钟、十四世纪出现的利用重锤驱动的机械钟以及惠更斯研制的摆钟等等都是探索过程中朝着精密性、易用性的改进。随着人们对自然界的深入了解，特别是对电、磁和物质的原子结构的了解，诸如石英钟、原子钟等一些新的方案得以发展和实现。 现在再去回顾历史，很容易就可以看出时间计量对工业、科学研究和当今世界诸多事务的影响。约翰•哈里逊时钟克服了海洋的颠簸、温度变化和咸水的溅射，大大改善了船只导航。对晶体谐振频率的研究有了如今改变世界的半导体。从“定性上的为什么”到“定量上的多准确”的科学演变，促使了精密测量的需求，进而影响到了数学、物理学、天文学……那么如今的我们需要再去思考“时间”吗？ II. 阿尔法到欧米伽（始与终）太过普世、默会的科学往往会被我们所忽略掉。拿起杯子喝口水，对于人来说，无疑再简单不过，但如果要造一个可以端起杯子喝水的机器人呢？显然，这是一个相对有难度并且复杂的任务，其中所涉及到的运动学、控制学、人体工程学等等科学知识都不是随便说说那么简单。因此，回溯历史能够使我们对那些在日常生活中扮演着最基本角色的事物产生认知，并进一步引领我们去思考。时间，它就扮演着使得人类的一切活动有秩序、有组织地进行着的角色。我想试图去了解时间，可以帮助我们更好的规划工作和生活。 虽然当今社会的物质财富已经相对丰富，但大多数人却丧失了求真求知，我们经常被当下的现实琐碎问题所困。这种局限使得人们疲于现实，而缺少创造和求知的勇气。假设我们可以做一次时间的旅行，“水母、鳄鱼胚胎、星云、犹他州的峡谷和木卫三；第一缕生命的信号、细菌、细胞起源、初恋感觉、意识诞生、人类进化、生与死。”（纪录片《时间之旅》）从宇宙大爆炸的那一刻开始到人类高级智慧的诞生，就注定了人类在漫漫时间长河中探索和认识这个世界的过程。在这个漫长的过程中，时间见证了无数人的探索求真精神，有始有终，从阿尔法到欧米伽，驱动着人类的进步。 我想时间就是一个很好的例子，来溯源支配当今社会行为准则的起源与内涵。正如同天平这种衡器的诞生以及后人对它的不断改进与完善，就是人们对公平与公正追求的一种体现。这种以此来扩充我们见识的过程，有助于锻炼我们的思维，突破一些困扰我们的现实问题，尝试新思路，并最终试图解决我们一直在思考的问题：自我存在。起码这种思维方法对我自己很有帮助：我是工作后考的研究生。考研期间，我没有用智能手机，由于一个人很难坚持下来，于是尝试每天早上7：15到7：45期间用静坐的方式来保持心态的平和。这种方法却意外之外了我的一笔人生财富，因为静坐的时候，我会尝试去想一些平静的事，慢慢地就会回忆起那些很久之前早就遗忘的事情。我想那个时候我就在进行着一趟回溯自己的时间之旅。每件事，好的，坏的都有始有终，总会过去，自己的心态也就变得好起来。静坐之后，洗漱完，8点准时出发，开始一天的学习生活……到现在读研期间，我依旧保持了考研时的一些习惯。 III. 结束语正如同泰伦斯•马力克执导的纪录片《时间之旅》所传达的哲学信息：“如果你在寻找上帝，仔细观察时间的一切就够了。”我想这就是时间对我们个体的意义。","tags":[{"name":"Lens","slug":"Lens","permalink":"https://ex2tron.github.io/tags/Lens/"},{"name":"计量","slug":"计量","permalink":"https://ex2tron.github.io/tags/计量/"},{"name":"时间之旅","slug":"时间之旅","permalink":"https://ex2tron.github.io/tags/时间之旅/"}]},{"title":"摄影之魅：瞬间是一面\"镜子\"","date":"2017-11-08T12:56:32.000Z","path":"2017/11/08/摄影之魅：瞬间是一面镜子/","text":"这篇文章其实是我一年前研一《摄影艺术》课上的小论文，感觉写的还行，放在博客上。 Not everyone can become a great artist, but a great artist can come from anywhere. ——《Ratatouille》并非是谁都能成为伟大的艺术家，不过伟大的艺术家却可能来自任何角落。——《料理鼠王》 19世纪30年代末期，达盖尔发明银版照相法，尼埃普斯拍摄了世界上第一张照片，影像开始可以被记录下来。卢米埃尔兄弟在《火车进站》中开启了24帧的艺术之旅——“电影”。如今，影像无处不在，传递着无穷无尽、千变万化的讯息。这一切都源于定格影像的瞬间——摄影术的独特魅力。 I. 艺术源于生活、艺术高于生活在选修“摄影艺术”这门课程之前，我刚刚入手了一款入门级单反：宾得PENTAX K-50。本着对摄影的爱好，在入手单反之前就经常用手机去拍一些小东西。所以，理所当然，选修这门课程就是希望自己能够拍出“好看”的照片，即追求表意上的拍摄技法。最初，刚接触摄影的我迫切想积累诸如快门、光圈、感光度、景深、构图等等各种专业术语。不可否认的是，这种“量”的层面上的堆积确实有助于提升拍摄认知和水平，但往往会也会束缚我们，缺少创造力、缺少对摄影“质”的理解。自己对摄影的认知也停留在肤浅的“这张照片拍的好，但说不出所以然来”上面。很高兴，这门课程改变了我的很多想法。 人是爱“美”的。如今，拍照是一件及其简单的事。一方面，得益于智能手机的发展，我们只需要按下手机上的拍照按钮，就会捕获一张照片，接近零成本。另一方面，由于拍摄的简便性，对生活中事物的记录变得极其频繁，这某种程度上降低了我们独立思考和赏析的能力。我们往往会赞美一张“好看”的照片，被照片所表现出来的第一观感所牵引，有些人虽然会对拍摄的技法做一些分析，获取经验，但却极少表达对照片的理解。并且，这些赞美和分析通常都只是建立在一张“美”的照片上。之所以强调了多次“美”的照片，是因为摄影不仅仅只是最终呈现出的照片的观感，摄影更多的含义是一个过程，这一过程的目的往往是真实地或艺术地反映出现实，并表现出拍摄者的情感寄托。当然，摄影术发明的目的就是代替画像，它源于生活，更是高于生活，因此，摄影是个庞杂的体系，前面的理解或许只是一种粗浅的认识。对于不同的摄影类别，诸如纪实摄影、风光摄影、商业时尚摄影等等，摄影都有不同的目的和表现方式，但摄影本身又是绝对的自由，它代表这一种艺术、创造力和想象力。 规则是用来打破的，但打破规则之前，我们必需清楚这个规则。得益于课堂之上邱老师介绍的各类摄影大师以及他们的作品，我了解了很多摄影的历史和大师级摄影师的风格。他们能够在摄影史上留下名字，通常都是某种风格的开创者，有着自己个性鲜明的摄影语言并对一个时代产生深远的影响。 II. 以小见大，“决定性瞬间”——布列松 “摄影这一门，你进去时是ABC，出来时是HCB（Henri Cartier-Bresson：亨利·卡蒂埃·布列松）”——《日本摄影》杂志。 图1 布列松本人及其作品 其实，对于一位被冠以“他的摄影定义了20世纪”、“新闻摄影之父”称号的大师级摄影师来说，无需多言。然而布列松提出的“决定性瞬间”的摄影艺术确确实实让我略微滤清了以往杂乱无章的“瞬间”摄影认知。在此之前，我一直很崇尚抓拍。可能是因为最初自己并不是特别了解一些摄影技法，在拍摄一些故事性很强的场景时，拍出的照片通常描述或还原不了那一时刻的故事。很多时候，摆拍的人物表情很不自然，一般也表现不出很强的故事性。“决定性瞬间”：“在一秒钟的很小一部分中，以一种精确的形式呈现出某一事件的重要性，使它成为这一事件的最恰当的描述。”布列松的作品总是恰到好处地抓住了事件最微妙的一瞬间。这或许与他自身的经历大大相关。 布列松曾前往法国的非洲殖民地科特迪瓦并以打猎为主。在打猎的过程中，他形成了贯穿他一生的摄影技巧——准备，等待，等待，等待…，最后扣动扳机（按下快门）。这一过程，造就了布列松面对巨大压力之下的沉着和冷静。他的作品就仿佛一直等在主体那里拍摄这一场景一般，这均得益于布列松的耐心、完美的拍摄时刻和一种无人可以匹敌的直觉。 图2 布列松作品:< 布列松习作>（左）、（右，前景中跳跃的男子与背后的跳跃女郎互相呼应） 《布列松习作》(上图)作为布列松的一幅名作，一方面以其娴熟的抓拍功底丰富而自然地表现出拍摄瞬间的故事性：小男孩情绪十分自然，踌躇满志的抱着两个大酒瓶回家，身后的小女孩也投来羡慕的目光…另一方面，这幅作品也很好的体现了布列松的摄影理念：“不论一幅作品技术多么到位，画面多么“好看”，如果它远离了爱，远离了对人类的理解，远离了对人类命运的认知，那么它一定不是一件成功的作品。”布列松的镜头虽然对准的是现实小场景，但他的立意高远，致力于以小见大，“最小的事物可以成为伟大的主题”。 III. 瞬间是一面“镜子” 图3 (上)、(下) 摄影大师的作品中往往呈现出非常鲜明的个性特征，赋予了其作品与众不同的表现力和故事性。摄影师在按下快门的那一刻，CCD/CMOS上接收的那些信号就变成了一张转瞬即逝一瞬间的记录。通常，摄影师抓拍的那一刻场景，很难再去复现，再加之摄影师独特的拍摄手法和艺术风格，使得每一张照片都变得独一无二，这也是瞬间反映的价值所在。因此，当我们去鉴赏这些作品、这些瞬间时，我们会被其表现出的感染力所吸引，《饥饿的苏丹》带给我们巨大的震撼，《时代广场的胜利》让我们体验到二战胜利的狂喜……。当然很多作品所表现出来的往往并不是“好看”的第一观感，它就如同一面可以窥视我们人类、社会、自然各种善恶丑美的镜子。直面这样的一面镜子，我们不免会产生强烈的情感冲击，因为这样的作品并不是单纯的、好看的、无意义的，而是承载着某些人文情怀和哲学思考。当我们深刻去理解它的时候，理所当然就会被其所揭示的内在所折服。 不过，摄影终归是自由的表现力、创造力的象征，这也是摄影术的魅力所在。我们需要不断学习和模仿经典作品的拍摄，但却不能有所束缚，当深刻地了解了这些规则后，就可以尝试打破这些规则，形成自己的风格！ “Not everyone can become a great artist, but a great artist can come from anywhere.”, “Everyone Can Cook！”（《料理鼠王》电影台词） “摄影艺术”这门课程改变了我很多的认识和想法，或许最大的感受便是：“Everyone Can Shoot！”每个人都有对其生活环境、人生观、世界观、价值观的独特理解，每个人也都可以拿起手中的设备拍出自己独特的风格。对大师作品的品鉴和艺术赏析都有助于提升自身的艺术品位，但关键在于去拍、去学习、去发现、去创造。我想这门课程给了我信心可以站在巨人的肩膀上努力拍出自己的作品，毕竟摄影是自由的，这才是摄影术之魅力！","tags":[{"name":"Lens","slug":"Lens","permalink":"https://ex2tron.github.io/tags/Lens/"},{"name":"摄影","slug":"摄影","permalink":"https://ex2tron.github.io/tags/摄影/"},{"name":"布列松","slug":"布列松","permalink":"https://ex2tron.github.io/tags/布列松/"}]},{"title":"小白深度学习笔记3：浅层神经网络","date":"2017-10-13T07:15:18.000Z","path":"2017/10/13/小白深度学习笔记3：浅层神经网络/","text":"logistic回归可以看作是只有1层1个神经元的神经网络，那么一般的神经网络是怎么样的呢？ 因为国民不富裕就不能受法律保护，就不能享受民主，这种说法我是无法接受的。 ——《辩护人》 本文是我在观看吴恩达老师的《神经网络和深度学习》视频课程时，相关的笔记整理，大佬勿喷！ 神经网络前面学习了logistic回归，可以把logistic看作只有1层1个神经元的神经网络，如下图： logistic_regression_singal_neural_network_sample 这个神经元做两个操作： 计算\\(z=w^Tx+b\\) 计算\\(\\hat{y}=a=\\sigma(z)\\) 而一般的神经网路包括输入层、隐藏层和输出层。如下图所示，是一个两层神经网络。层数从隐藏层(Hidden Layer)开始算，也就是这个图中，第1层是隐藏层，第2层是输出层(Output Layer)。可以把输入层(Input Layer)称为第0层。 two_layers_neural_network_samples 浅层神经网络是相较于深层神经网络而言的，深层神经网络中，隐藏层的个数&gt;=2，层数越多，也就越深。 激活函数如果把2层的神经网络看作是logistic回归的堆叠的话，那么这个神经网络的正向传播应该是下面这样的公式： $$z^{[1]}=W^{[1]}x+b^{[1]}\\tag{1}$$$$a^{[1]}=\\sigma(z^{[1]})\\tag{2}$$$$z^{[2]}=W^{[2]}x+b^{[2]}\\tag{3}$$$$a^{[2]}=\\sigma(z^{[2]})\\tag{4}$$ 其中，sigmoid函数就是激活函数(Activation Function)。激活函数不一定是sigmoid函数，有的非线性函数要比sigmoid函数更好，这里介绍两种：tanh和ReLU。 common_activation_functions tanhtanh(Hyperbolic Tangent Function)双曲正切函数，\\(a=tanh(z)=\\frac{e^z-e^{-z}}{e^z+e^{-z}}\\)。tanh往往比sigmoid表现更好，从上图中可以看出，这个激活函数的平均值更接近于0。但是输出层如果是二类分类的话，结果要么是0要么是1，那么我们预测值应该介于0~1之间，所以这种情况下，输出层的激活函数依然用sigmoid函数。 ReLU如果仔细观察sigmoid和tanh函数曲线的话，就会发现，自变量z比较大或比较小时，这个函数的斜率就会很小，接近于0，这样会拖慢梯度下降法的速度。所以，另外一个经常使用到的激活函数是ReLU(Rectified Linear Unit)。\\(a=max(0,z)\\)，z为正时，导数为1，z为负时，导数为0。 所以，总结三种激活函数， 一般不使用sigmoid做激活函数，除非是二类分类，可用在输出层 tanh普遍效果要比sigmoid更好 最常用的默认激活函数是ReLU 正向传播如果我们选择tanh作为激活函数的话，开头那个2层神经网络的正向传播就是： $$Z^{[1]}=W^{[1]}X+b^{[1]}\\tag{1}$$$$A^{[1]}=tanh(Z^{[1]})\\tag{2}$$$$Z^{[2]}=W^{[2]}X+b^{[2]}\\tag{3}$$$$A^{[2]}=tanh(Z^{[2]})\\tag{4}$$ 反向传播反向传播的推导跟logistic回归一样，只不过进行两次： $$dZ^{[2]}=A^{[2]}-Y\\tag{1}$$$$dW^{[2]}=\\frac{1}{m}dZ^{[2]}A^{[1]^T}\\tag{2}$$$$db^{[2]}=\\frac{1}{m}np.sum(dZ^{[2]},axis=1,keepdims=True)\\tag{3}$$$$dZ^{[1]}=W^{[2]^T}dZ^{[2]}*tanh^{’[1]}(Z^{[1]})\\tag{4}$$$$dW^{[1]}=\\frac{1}{m}dZ^{[1]}X^T\\tag{5}$$$$db^{[1]}=\\frac{1}{m}np.sum(dZ^{[1]},axis=1,keepdims=True)\\tag{6}$$ 随机初始化之前在logistic回归中，我们可以将权重W初始化为0，但是对于神经网络而言，W都初始化为0的话，是无效的。 no_zero_initialized_sample 举例来说，对于上图中的神经网络，隐藏层神经元个数是2，如果W全部初始化为0的话，那么： $$ W^{[1]}= \\begin{bmatrix} 0 &amp; 0 \\newline 0 &amp; 0 \\end{bmatrix}$$ 因为\\(z^{[1]}=W^{[1]}x+b\\)，这样的话\\(z_1^{[1]}=z_2^{[1]}\\)，\\(a_1^{[1]}=a_2^{[1]}\\)，也就是说，两个神经元的功能完全一样，计算相同的值，这样1个神经元和n个神经元对神经网络的作用是一样的，其他n-1个是多余的。 所以，在神经网络的参数初始化中，权重W是不能全部初始化为0的，b的话无所谓，都可以。","tags":[{"name":"Code","slug":"Code","permalink":"https://ex2tron.github.io/tags/Code/"},{"name":"神经网络","slug":"神经网络","permalink":"https://ex2tron.github.io/tags/神经网络/"},{"name":"深度学习","slug":"深度学习","permalink":"https://ex2tron.github.io/tags/深度学习/"}]},{"title":"numpy中几种矩阵的乘法","date":"2017-10-11T02:26:09.000Z","path":"2017/10/11/numpy中几种矩阵的乘法/","text":"最近在手动实现神经网络模型的时候，老是混淆numpy中几种矩阵乘法区别，所以特此记录一下。 With great power comes great responsibility ——《Spider-Man》能力越大，责任越大。——《蜘蛛侠》 首先，这里规定一下，我们用numpy定义矩阵时全部采用标准的形式，举例如下： 12345678import numpy as np# 不推荐的方式a = np.array([1,2,3])print(a.shape)# 推荐的方式b = np.array([[1,2,3]])print(b.shape) 上面代码a的形状是(3,)，b的形状(1,3)，即1行3列的一个矩阵。 np.dotnp.dot(A,B)就是实现同线性代数里面的矩阵乘法，也就是说，A的列数要等于B的行数才可以相乘： 12345import numpy as npa = np.array([[1,2,3],[4,5,6]])b = np.array([[1],[2],[3]])print(np.dot(a,b)) a是(2,3)，b是(3,1)，所以输出结果是：[[14], [32]]。 np.multiplynp.multiply(A,B)和A*B效果一样，实现对应位置元素相乘。 12345678910111213import numpy as np# 示例一a = np.array([[1,2,3]])b = np.array([[4,5,6]])print(a*b)print(np.multiply(a,b))# 示例二c = np.array([[1,2,3],[4,5,6]])d = np.array([[1],[2]])print(c*d)print(np.multiply(c,d)) 示例一输出结果是[[4 10 18]]，即[[1*4 2*5 3*6]]。示例二输出结果是[[1 2 3], [8 10 12]]，这里涉及到一个numpy中广播的概念：因为c是(2,3)，而d是(2,1)，为了实现对应元素相乘，numpy会把d的列复制扩展成(2,3)，于是就有了上面的结果。 np.innernp.inner(A,B) 实现A,B的内积，要求A,B矩阵最后一维是相同的，如果是2维矩阵，即A,B矩阵的列数要相同。 12345import numpy as npa = np.array([[1,2,3]])b = np.array([[4,5,6]])print(np.inner(a,b)) 结果为[[32]]，即1*4 + 2*10 + 3*6。 np.outernp.outer(A,B)即A,B的外积： 12345import numpy as npa = np.array([[1,2,3]])b = np.array([[4,5,6]])print(np.outer(a,b)) 结果为[[4 5 6], [8 10 12], [12 15 18]]，即[[1*4 1*5 1*6], [2*4 2*5 2*6], [3*4 3*5 3*6]]。","tags":[{"name":"Code","slug":"Code","permalink":"https://ex2tron.github.io/tags/Code/"},{"name":"numpy","slug":"numpy","permalink":"https://ex2tron.github.io/tags/numpy/"},{"name":"Python","slug":"Python","permalink":"https://ex2tron.github.io/tags/Python/"},{"name":"矩阵","slug":"矩阵","permalink":"https://ex2tron.github.io/tags/矩阵/"}]},{"title":"小白深度学习笔记2：Python实现logistic回归","date":"2017-10-09T01:52:11.000Z","path":"2017/10/09/小白深度学习笔记2：Python实现logistic回归/","text":"上一篇了解了一些logistic回归的原理，现在我们用Python实现一个用于鉴别是否是一张猫的图片的分类器！ 本文是我在观看吴恩达老师的《神经网络和深度学习》视频课程时，相关的笔记整理，大佬勿喷！ You’re not worried？ Would it help？ ——《Bridge of Spies》你不担心吗？有用吗？——《间谍之桥》 首先，回顾一下，logistic回归其实就相当于只有一层的最简单的神经网络，如下图，正向传播计算出预测值和成本函数，而反向传播计算出的dw和db： logistic_forward_backword_propagation p.s.本文其实是吴恩达老师第二周教程的作业，没答案，这里提供我写的，仅供参考！ 导入包首先import我们要使用的包，其中lr_utils和数据样本点此处下载： 1234567import numpy as npimport matplotlib.pyplot as pltimport h5pyimport scipyfrom PIL import Imagefrom scipy import ndimagefrom lr_utils import load_dataset 得到样本集我们的训练样本和测试样本都在前面下载的文件中： 12# 加载样本train_set_x_orig,train_set_y,test_set_x_orig,test_set_y,classes = load_dataset() 因为我们直接加载的样本集还需要进行处理，所以变量名上加了_orig。此时，train_set_x_orig中的每一个元素就是一副图片，可以用下面的方式让它显示出来： 1234# 显示第11张图片plt.figure()plt.imshow(train_set_x_orig[10])plt.show() 如果打印出train_set_x_orig的形状，结果为：(209,64,64,3)。可知训练样本的个数m_train=209，图片的宽和高都是num_px=64。 1print(train_set_x_orig.shape) 还记得上一篇中提到如果把图片量化吗？如果图片的维数是(num_px,num_px,3)，我们要变成(num_px*num_px*3,1)的形状。也就是说要把形状为(a,b,c,d)的矩阵变成形状数组为(b*c*d,a)的矩阵数组，这里可以用下面的一个小技巧： 1X_flatten = X.reshape(X.shape[0], -1).T 12train_set_x_flatten = train_set_x_orig.reshape(train_set_x_orig.shape[0],-1).Ttest_set_x_flatten = test_set_x_orig.reshape(test_set_x_orig.shape[0],-1).T 编写神经网络的代码中经常出现的错误便是把矩阵的维数搞错，所以随时可以通过shape属性进行检查，经过上面的语句后，train_set_x_flatten的形状应该是(12288,209)，test_set_x_flatten的形状应该是(12288,50)。 因为像素值最大是255，为了避免数据过大，可以将数据归一化得到最终的训练/测试集样本： 12train_set_x = train_set_x_flatten/255test_set_x = test_set_x_flatten/255 编写各个模块sigmoid函数这里注意python自带math模块中的exp函数和numpy中的exp函数的区别，math.exp是没有广播功能的，不适合此处的矩阵运算。123def sigmoid(x): s = 1/(1+np.exp(-x)) return s 测试：1print(sigmoid(np.array([0,2]))) 结果应为[0.5 0.88079708] 初始化w和b因为logistic回归相当于只有一个输出层的神经网络，根据上一篇的分析，w的形状是(nx,1)，b的形状是(1,1)，这里我们统一初始化为0：1234def initialize_with_zeros(dim): w = np.zeros([dim,1]) b = 0. return w, b 正/反向传播这里的函数就是本文开头那张图上显示的正向传播和反向传播：1234567891011121314def propagate(w, b, X, Y): m = X.shape[1] # 正向传播 A = sigmoid(np.dot(w.T,X)+b) # 成本函数 cost = -np.sum(Y*np.log(A)+(1-Y)*np.log(1-A),axis=1)/m cost = np.squeeze(cost) # 反向传播 dw = np.dot(X,(A-Y).T)/m db = np.sum(A-Y,axis=1)/m grads = &#123;\"dw\":dw,\"db\":db&#125; return cost,grads 测试：123w,b,X,Y = np.array([[1],[2]]),2,np.array([[1,2],[3,4]]),np.array([[1,0]])cost,grads = propagate(w,b,X,Y)print(cost,grads) 结果应为：6.000064773192205 {&#39;dw&#39;: array([[0.99993216], [ 1.99980262]]), &#39;db&#39;: array([0.49993523])} 优化器反向传播完，我们需要更新w，b的值，即应用梯度下降法进行优化： 12345678910111213141516171819def optimize(w,b,X,Y,num_iterations,learning_rate,print_cost=False): costs = [] for i in range(num_iterations): cost,grads = propagate(w,b,X,Y) dw = grads['dw'] db = grads['db'] # 更新w和b的值 w = w-learning_rate*dw b = b-learning_rate*db # 每隔100次，记录下成本函数的值 if(i%100 == 0): costs.append(cost) if(print_cost): print(\"cost after iteration %i:%f\"%(i,cost)) params=&#123;'w':w,'b':b&#125; grads=&#123;'dw':dw,'db':db&#125; return params,grads,costs 测试：12params, grads, costs = optimize(w, b, X, Y, num_iterations= 100, learning_rate = 0.009, print_cost = False)print(params,grads,costs) 结果应为{&#39;w&#39;: array([[0.1124579 ],[0.23106775]]), &#39;b&#39;: array([ 1.55930492])} {&#39;dw&#39;: array([[ 0.90158428],[1.76250842]]), &#39;db&#39;: array([ 0.43046207])} [array(6.000064773192205)] 预测函数通过优化器得到w和b参数之后，就可以用这两个参数预测X了，如果预测值&gt;=0.5，那结果就为1，即是一张有猫的图片，反之，结果为0，是一张没有猫的图片： 123456789def predict(w,b,X): m = X.shape[1] Y_predictions = np.zeros([1,m]) A = sigmoid(np.dot(w.T,X)+b) for i in range(A.shape[1]): Y_predictions[0,i] = 1 if A[0,i]&gt;=0.5 else 0 return Y_predictions 分类模型这样我们就编写好了所有的模块了，最后，把它们整合在一起，就是logistic回归的二类分类模型了：12345678910111213141516171819202122def model(X_train,Y_train,X_test,Y_test,num_iterations=2000,learning_rate=0.5,print_cost=False): w,b = initialize_with_zeros(X_train.shape[0]) params,grads,costs = optimize(w,b,X_train,Y_train,num_iterations,learning_rate,print_cost) w = params['w'] b = params['b'] Y_prediction_test = predict(w,b,X_test) Y_prediction_train = predict(w,b,X_train) print(\"train accuracy:&#123;&#125; %\".format(100-np.mean(np.abs(Y_prediction_train-Y_train))*100)) print(\"test accuracy:&#123;&#125; %\".format(100-np.mean(np.abs(Y_prediction_test-Y_test))*100)) d = &#123;\"costs\": costs, \"Y_prediction_test\": Y_prediction_test, \"Y_prediction_train\" : Y_prediction_train, \"w\" : w, \"b\" : b, \"learning_rate\" : learning_rate, \"num_iterations\": num_iterations&#125; return d 现在，可以把我们真正的样本数据传入这个模型，看它最后训练的结果：1d = model(train_set_x, train_set_y, test_set_x, test_set_y, num_iterations = 2000, learning_rate = 0.005, print_cost = True) 如果一切正常，会打印出最后模型在训练集和测试集上的准确率：12train accuracy:99.04306220095694 %test accuracy:70.0 % 验证和分析结果可以看到当前的训练结果其实是过拟合的，测试集上的准确率并不高，但暂时足够了。我们可以显示和打印出真实的图片结果进行对比。比如说这里我们打开测试集上的第5张图片，并将学习率曲线画出来：123456789index = 4plt.imshow(test_set_x[:,index].reshape([num_px,num_px,3]))print(\"real result = \"+str(test_set_y[0,index])+\" and your predict = \"+str(d['Y_prediction_test'][0,index]))plt.figure()plt.plot(np.squeeze(d['costs']))plt.ylabel('cost')plt.xlabel('iterations(per hundreds)')plt.title(\"learning rate = \"+str(d['learning_rate']))plt.show() 最后，源代码中包含了一段针对不同的学习率得到不同的训练结果的代码，大家可以参考下噢！~ o(￣▽￣)o 本文源代码：python_implement_logistic_regression.py","tags":[{"name":"Code","slug":"Code","permalink":"https://ex2tron.github.io/tags/Code/"},{"name":"神经网络","slug":"神经网络","permalink":"https://ex2tron.github.io/tags/神经网络/"},{"name":"深度学习","slug":"深度学习","permalink":"https://ex2tron.github.io/tags/深度学习/"},{"name":"logistic回归","slug":"logistic回归","permalink":"https://ex2tron.github.io/tags/logistic回归/"}]},{"title":"【利器篇】GitKraken——顶级酷炫Git图像化客户端","date":"2017-10-05T09:33:20.000Z","path":"2017/10/05/【利器篇】GitKraken——顶级酷炫Git图像化工具/","text":"不喜欢敲命令？那么这款酷炫的Git客户端让你逼格满满！ 真正的忘记是不需要努力的。——《大鱼海棠》 首先废话一段：以前我上班的时候，公司里的SCM用的是perforce，你应该、可能没听过( ╯□╰ )。总之，就是集中式版本管理系统，相比于git的分布式有很多缺陷，具体可以看廖雪峰的这篇文章：“集中式vs分布式”。但作为一款商业软件，perforce提供的优秀客户端体验还是相当不错的。使用git后，一直都是敲命令的，一是因为习惯，毕竟码代码逼格高嘛，二是因为git的GUI客户端要不很丑，要不功能捉急，总之不想用。之后，在微博上看到这款软件，又同类似的SourceTree相比体验了一下，无奈，我，还是喜欢颜值高的~ o(￣▽￣)o另外，以前外教老师提问说《加勒比海盗2》中的那个怪物叫啥，阅片无数的我，那天竟然没回答上，装逼失败，所以对这只“挪威海怪kraken”影响特别深刻。好了，开始正题吧，扯远了~ 官网/下载：GitKraken GitKraken对Windows/Linux/Mac三大主流平台都支持，其方便之处在于，它不需要安装配置，双击打开就可以了。打开之后，可以选择用Github账号登陆，需要Github授权： gitkraken_sign_in_with_github 打开/克隆/初始化GitKranken支持打开本地仓库，从指定的URL或Github、Gitlab、Bitbucket等上面直接克隆。前面我们已经用Github直接登陆了，所以，从Github克隆时，会直接列出你当前的所有仓库项目，非常方便。当然，也可以连接到Gitlab/Bitbucket平台： gitkraken_clone_from_github 初始化/新建项目也非常方便，在Init选项中，可以选择初始化一个本地仓库或类似Github之类的远程仓库。GitKraken初始化时还提供了.gitignore的文件的相关模板： gitkraken_init_github_repo 界面/功能打开一个仓库后，主界面如下图，酷炫简洁，顶部提供了常用的Git功能，就不细说了。我主要提及一下，如何进行版本差分： gitkraken_main_ui 在提交日志的主界面，如果要比较任意两个版本之间的差分，按住Ctrl键，选择要比较的版本，右边会自动列出两个版本之间所修改的文件，点击文件就可以看到diff了： gitkraken_view_commits_diff gitkraken_view_file_diff 当然，最新版本（本文使用的是3.1版本）的GitKraken提供了Merge和Diff工具的自定义（File-Preferences-General中设置），比如说我最常用的Merge工具是WinMerge，就可以在这里配置。 抛砖引玉，大致介绍了一下，其实熟悉Git的话，这个工具使用起来还是蛮简单的~ o(￣▽￣)o","tags":[{"name":"Code","slug":"Code","permalink":"https://ex2tron.github.io/tags/Code/"},{"name":"利器篇","slug":"利器篇","permalink":"https://ex2tron.github.io/tags/利器篇/"},{"name":"Git","slug":"Git","permalink":"https://ex2tron.github.io/tags/Git/"},{"name":"GitKraken","slug":"GitKraken","permalink":"https://ex2tron.github.io/tags/GitKraken/"}]},{"title":"小白深度学习笔记1：logistic回归","date":"2017-10-02T13:06:32.000Z","path":"2017/10/02/小白深度学习笔记1：logistic回归/","text":"开启神经网络与深度学习之坑！本篇内容包含部分数学公式，需要用MathJax脚本渲染，所以页面需等待加载完成后，才可完整显示公式。 When life ends up breathtakingly fucked, you can generally trace it back to one big, bad decision.——《DeadPool》当你的生活变成一坨屎的时候，通常都是因为你当时做的傻逼决定。——《死侍》 本文是我在观看吴恩达老师的《神经网络和深度学习》视频课程时，相关的笔记整理，大佬勿喷！ 二类分类比如说分析一张图片中有猫还是没猫，这就是一个二类分类（Binary Classification）问题。这里，我们用输出y=1表示有猫，y=0表示没有猫。输入是一张图片，做过图像处理的同学应该知道图片是以RGB三个矩阵存储的，把RGB三分量的值提取出来，作为X，如下图： rgb_convert_input_x 那么当有m个样本时，X就是一个(nx,m)，即nx行、m列的矩阵，而输出Y的形状（形状就是指矩阵的行数和列数）是(1,m)。 logistic回归logistic回归（Logistic Regression）就是一个用于二类分类的学习算法：假定给出输入的特征向量\\(x_1\\)（如一张图片），我们希望程序给出一个预测值\\(\\hat{y}\\)，它指出这张图片中有猫还是没猫的概率，即：$$\\hat{y}=P(y=1\\ or\\ 0\\mid x)$$ 既然\\(\\hat{y}\\)是一个概率，那么\\(\\hat{y}\\in[0,1]\\)。如果按照线性回归，输出值应该是：\\(\\hat{y}=w^Tx+b\\)，w形状是(nx,1)，b形状是(1,1)，但是这个值可能远比1大或者出现负数，所以，需要用一个sigmoid函数做限定，最终输出为：$$\\hat{y}=\\sigma(w^Tx+b)$$ 观察sigmoid函数\\(\\sigma(z)=\\frac{1}{1+e^{-z}}\\)的曲线图： \\(z\\rightarrow\\infty,\\sigma(z)\\rightarrow1;z\\rightarrow-\\infty,\\sigma(z)\\rightarrow0;z=0,\\sigma(z)=0.5\\) sigmoid_function_graph 损失函数既然我们的目标就是训练得到logistic回归函数中的w和b参数，那么怎么衡量算法的运行情况呢？我们可以用损失函数（Loss Function）L表示预测值与真值的接近程度。最简单的损失函数可以定义成\\(L(\\hat{y},y)=\\hat{y}-y\\)。但是不会这样用，因为要考虑到优化算法的运算速度和效率，排除多个局部最优解。一般，损失函数定义为：$$L(\\hat{y},y)=-[y\\log\\hat{y}+(1-y)\\log(1-\\hat{y})]$$ 显然，损失函数越小，结果越好。那么这个损失函数如何起作用的呢？ 假设真值y=1，那么上式就会变成：\\(L(\\hat{y},1)=-\\log\\hat{y}\\)，要让损失函数尽量小，那么\\(\\log\\hat{y}\\)尽量大，也就是说\\(\\hat{y}\\)尽量大，由于\\(\\hat{y}\\in[0,1]\\)，所以，这个损失函数会使预测值\\(\\hat{y}\\)尽量接近1，即真值。同样，大家可以推一下真值y=0的情况。 成本函数前面所说的损失函数是针对单个训练样本定义的，我们可以用成本函数（Cost Function）来定义全体训练样本上的算法运行情况，定义如下：$$J(w,b)=\\frac{1}{m}\\sum_{i=1}^mL(\\hat{y^i},y^i)$$ 梯度下降法好，到这里，先总结一下： logistic回归模型是用于二类分类的一种学习算法 损失函数衡量参数w和b在单个训练样本的效果 成本函数衡量参数w和b在全体训练样本的效果 训练目标：找到使成本函数J尽可能小的参数w和b 那么w和b参数是怎么调整的呢？为了说明梯度下降法（Gradient Descent），吴恩达老师假定w和b都是实数，那么J(w,b)的函数图形类似下图： cost_function_graph 一般，先随机初始化w和b，然后朝着最快下降的方向不断按下面的公式调整w和b参数，最后得到最优解（:=表示更新w的值）： $$w:=w-\\alpha\\frac{dJ(w,b)}{dw}$$$$b:=b-\\alpha\\frac{dJ(w,b)}{db}$$ \\(\\alpha\\)成为学习率（Learning Rate），表示梯度下降法的步长。 好了，这就是相关的logistic回归的简单理论笔记。","tags":[{"name":"Code","slug":"Code","permalink":"https://ex2tron.github.io/tags/Code/"},{"name":"神经网络","slug":"神经网络","permalink":"https://ex2tron.github.io/tags/神经网络/"},{"name":"深度学习","slug":"深度学习","permalink":"https://ex2tron.github.io/tags/深度学习/"},{"name":"logistic回归","slug":"logistic回归","permalink":"https://ex2tron.github.io/tags/logistic回归/"}]},{"title":"【算法贴】三点定位算法","date":"2017-09-29T10:58:31.000Z","path":"2017/09/29/【算法贴】三点定位算法/","text":"已知三个点的坐标和未知点到这三个点的距离，求未知点？ 过去的如果就这么过去了，以后只会越来越糟。——《驴得水》 p.s.本文引用了mathjax脚本用来显示数学公式，所以需等待加载完成才能显示正常。 算法解析如下图所示，以三个已知点为圆心，d1,d2,d3为半径作圆，交点便是要求解的未知点： trilateration_sample 刚开始百度了一下，各种稀奇的算法，包括将三角形平移、旋转啥的，其实不用这么麻烦，直接通过勾股定理死算就可以了。 $$(x_1-x_0)^2+(y_1-y_0)^2=d_1^2$$ $$(x_2-x_0)^2+(y_2-y_0)^2=d_2^2$$ $$(x_3-x_0)^2+(y_3-y_0)^2=d_3^2$$ 将上面三个式子展开： $$x_1^2+x_0^2-2x_0x_1+y_1^2+y_0^2-2y_0y_1=d_1^2 ①$$$$x_2^2+x_0^2-2x_0x_2+y_2^2+y_0^2-2y_0y_2=d_2^2 ②$$$$x_3^2+x_0^2-2x_0x_3+y_3^2+y_0^2-2y_0y_3=d_3^2 ③$$ 显然通过三个式子中的任意两个相减，比如①-③和②-③就可以得到两个未知数的两个式子： $$x_1^2-x_3^2-2x_0(x_1-x_3)+y_1^2-y_3^2-2y_0(y_1-y_3)=d_1^2-d_3^2$$$$x_2^2-x_3^2-2x_0(x_2-x_3)+y_2^2-y_3^2-2y_0(y_2-y_3)=d_2^2-d_3^2$$ 接下来就不用说了，其实这都是初中数学的问题( ╯□╰ ) 算法实现CSharp根据上面的推导，我们的算法就很好写了。先定义一个Point的结构体或类，然后编写一个函数，将已知的三个点和三个距离传入： 12345678910111213141516171819202122232425262728293031/// &lt;summary&gt;/// 定义Point结构体/// &lt;/summary&gt;public struct Point&#123; public double X; public double Y;&#125;static Point GetMobilePoint(Point p1, Point p2, Point p3, double d1, double d2, double d3)&#123; //相当于①式-③式 double A = p1.X - p3.X; double B = p1.Y - p3.Y; double C = Math.Pow(p1.X, 2) - Math.Pow(p3.X, 2) + Math.Pow(p1.Y, 2) - Math.Pow(p3.Y, 2) + Math.Pow(d3, 2) - Math.Pow(d1, 2); //相当于②式-③式 double D = p2.X - p3.X; double E = p2.Y - p3.Y; double F = Math.Pow(p2.X, 2) - Math.Pow(p3.X, 2) + Math.Pow(p2.Y, 2) - Math.Pow(p3.Y, 2) + Math.Pow(d3, 2) - Math.Pow(d2, 2); //计算结果 double x0 = (B * F - E * C) / (2 * B * D - 2 * A * E); double y0 = (A * F - D * C) / (2 * A * E - 2 * B * D); Point resultPoint; resultPoint.X = x0; resultPoint.Y = y0; return resultPoint;&#125;","tags":[{"name":"Code","slug":"Code","permalink":"https://ex2tron.github.io/tags/Code/"},{"name":"三角定位","slug":"三角定位","permalink":"https://ex2tron.github.io/tags/三角定位/"},{"name":"算法贴","slug":"算法贴","permalink":"https://ex2tron.github.io/tags/算法贴/"}]},{"title":"构建法、杀死变量","date":"2017-09-28T13:23:45.000Z","path":"2017/09/28/构建法、杀死变量/","text":"如果你仔细回想一下，平日阅读代码的时候，是什么占用了你大量的时间和精力？毫无疑问：变量。 Why do we fall, Bruce? So we can learn to pick ourselves up. ——《Batman Begins》我们为何会跌倒？这样我们才可以学会自己爬起来。——《蝙蝠侠：侠影之谜》 如果一个变量在代码中很分散，阅读者在同一时间内考虑的代码行数势必会增加，编写者引入Bug的概率也会增大。那么，该如何从减少变量的作用域角度提高代码质量呢？ p.s.本文相关内容仍旧是我阅读《代码大全》时的笔记与总结，大佬勿喷！ 变量跨度与存活时间建议一：把对变量的引用尽可能集中在一起，使变量局部化12345a = 0; b = 0;c = 0;a = b + c;b += 1; 跨度（span）是衡量变量不同引用点靠近程度的一种方法。比如说上面的代码，对a的第一次引用和第二次引用之间有2行代码，那么变量a的跨度就是2。引用多次的话，可以取平均跨度。如b的第一次和第二次引用之间行数为1，第二次和第三次引用之间行数为0，所以平均跨度span(b)=(1+0)/2=0.5。 另外一个概念是：存活时间（live time）。跟跨度类似，不过存活时间只跟变量第一次和最后一次引用有关。比如对于上面代码中的b变量，跨度是0.5，但是存活时间是4条语句。 显然，我们的目标就是缩短变量的跨度和存活时间。如果用这两个概念考察全局变量，就会发现全局变量的跨度和存活时间都很长，这也是为什么避免使用全局变量的原因之一。 减小作用域的建议建议二：把相关语句放在一起把变量的引用点集中在一起，使代码易于自上而下的阅读，举例来说： 12345678910111213141516//跳来跳去的糟糕代码MarketingData marketingData;SalesData salesData;TravelData travelData;travelData.ComputeWeekly();salesData.ComputeWeekly();marketingData.ComputeWeekly();salesData.ComputeAnnually();travelData.ComputeAnnually();marketingData.ComputeAnnually();salesData.print();travelData.print();marketingData.print(); 显然，如果你要想知道marketingData的计算流程，就必须在这段代码的不同行数跳跃。所以，这样组织代码会更好： 123456789101112131415//组织良好，从上而下阅读MarketingData marketingData;marketingData.ComputeWeekly();marketingData.ComputeAnnually();marketingData.print();SalesData salesData;salesData.ComputeWeekly();salesData.ComputeAnnually();salesData.print();TravelData travelData;travelData.ComputeWeekly();travelData.ComputeAnnually();travelData.print(); 《代码大全》中介绍了一种简便的检查相关语句是否组成得当的方法，把你的代码片段打印出来，然后把相关的语句画上框，组织得当的话， 这些框是不会重叠的： good_grouping_related_statements 建议三：把相关语句提取成单独的子程序更短的子程序相比长的子程序，变量的跨度和存活时间更小。比如，可以尝试这样重构上面的代码： 123456//重构，提取子程序ComputeMarketingData();ComputeSalesData();ComputeTravelData(); 建议四：开始使用最小的作用域，然后根据需求再扩展一句话解释就是：把全局变量转换为成员局部变量要比局部变量转换为全局变量难的多。因此，在设计程序时，如果对变量的作用域犹豫不决时，优先倾向于最小的作用域。 建议五：循环开始之前再去初始化循环变量一个不好的编程习惯就是在程序开头初始化好循环所使用的变量，如int i = 0,j = 0;。而在很后面才使用到循环。这样做的坏处一是查看循环时需要跳到开头才知道循环变量的值，另外，如果要修改这个循环，往往会忘记同时修改循环变量。 往期【构建法】系列回顾： 构建法、单点控制 构建法、表驱动法","tags":[{"name":"Code","slug":"Code","permalink":"https://ex2tron.github.io/tags/Code/"},{"name":"构建法","slug":"构建法","permalink":"https://ex2tron.github.io/tags/构建法/"},{"name":"变量","slug":"变量","permalink":"https://ex2tron.github.io/tags/变量/"},{"name":"作用域","slug":"作用域","permalink":"https://ex2tron.github.io/tags/作用域/"}]},{"title":"【片单】诺兰神作集","date":"2017-09-24T12:37:41.000Z","path":"2017/09/24/【片单】诺兰神作集/","text":"有的导演，虽然没拿过奥斯卡，作品不多，但每部却都被影迷奉为神作。没错，说的就是诺神：克里斯托弗·诺兰 克里斯托弗·诺兰今天周末，回顾了下诺神的蝙蝠侠和盗梦空间，加上前段时间刚看完敦刻尔克，按耐不住，就分享下诺兰的神作电影下载链接吧。 作品按时间排序，点击片名或者右键复制链接即可： 敦刻尔克 | Dunkirk Dunkirk 星际穿越 | Interstellar Interstellar 蝙蝠侠：黑暗骑士崛起 | The Dark Knight Rises The Dark Knight Rises 盗梦空间 | Inception Inception 蝙蝠侠：黑暗骑士 | The Dark Knight The Dark Knight 致命魔术 | The Prestige The Prestige 蝙蝠侠.侠影之谜 | Batman Begins Batman Begins 记忆碎片 | Memento Memento p.s.本文所有的图片均来自TMDB，如果你觉得很酷炫的话，我会在后期开发一款专门下载影视壁纸的APP，敬请期待！","tags":[{"name":"Lens","slug":"Lens","permalink":"https://ex2tron.github.io/tags/Lens/"},{"name":"片单","slug":"片单","permalink":"https://ex2tron.github.io/tags/片单/"},{"name":"诺兰","slug":"诺兰","permalink":"https://ex2tron.github.io/tags/诺兰/"},{"name":"蝙蝠侠","slug":"蝙蝠侠","permalink":"https://ex2tron.github.io/tags/蝙蝠侠/"},{"name":"敦刻尔克","slug":"敦刻尔克","permalink":"https://ex2tron.github.io/tags/敦刻尔克/"},{"name":"盗梦空间","slug":"盗梦空间","permalink":"https://ex2tron.github.io/tags/盗梦空间/"},{"name":"星际穿越","slug":"星际穿越","permalink":"https://ex2tron.github.io/tags/星际穿越/"}]},{"title":"【利器篇】七牛云——用做每月免费10G的图床","date":"2017-09-18T11:55:38.000Z","path":"2017/09/18/【利器篇】七牛云——用做每月免费10G的图床/","text":"随着越来越多的人开始使用Markdown写自己的独立博客，一个好用稳定的图床是必不可少的了。 对比在七牛云之前，我使用过国外的Cloud App和阿里云的oss对象存储。 首先，国外的东西在国内稳定性和速度都是相对较差的，我试着在阿里云和Cloud App上上传同一张图片并生成外链，Cloud App要比阿里的加载速度延迟1-2s，阿里基本秒开。 阿里的oss对象存储虽然很稳定，但是并不提供免费的空间。相对来说，七牛云提供的每月10G免费流量，对于博客来说，绰绰有余了。 另外，七牛云提供了诸多的图片处理接口，如水印、格式转换、缩放等，很实用，很强大。 使用注册并登陆七牛云，在七牛云的产品列表中，添加一个对象存储，如这里取名为picblog： create_new_bucket 创建好之后，七牛云会自动生成一个测试域名： test_domain_name 这个域名就是你文件的前缀了。比如，我们点击内容管理，点击上传文件，选择一幅图片上传。上传完成后，复制该文件的外链地址： copy_file_link 这个地址就是你的图片地址辣，你可以在浏览器中访问该地址，比如你可以访问我的这个：mysql_demo 绑定域名添加二级域名如同前面那张图上所说，七牛云默认的测试域名有很多限制。所以，你如果已经购买了域名的话，可以在这里绑定自己的二级域名，这样既好记又方便管理。 比如，这里我已经在万网上购买了ex2tron.xin的域名，这里我演示如何将七牛云的存储空间绑定pic.ex2tron.xin这个域名。 在七牛云的存储空间页面，点击绑定域名，只需要在加速域名处填写要绑定的域名，其他项保持默认即可：1加速域名： pic.ex2tron.xin bucket_binding_domain_name 创建后，系统会配置一段时间，等待处理完成，会显示一个诸如xxx.qiniudns.com的CNAME记录值，记下此值，后面要用到。 cname_for_binding 添加域名解析打开万网的域名控制台，添加一条CNAME的解析：1234记录类型：CNAME主机记录：pic记录值：xxx.qiniudns.com# 其他选型保持默认 add_dns_for_qiniu 这样，你上传的图片外链就是：http://pic.ex2tron.xin/filename.png之类的了。 添加图片样式利用七牛云做图床的另外一个强大之处在于丰富的图片样式。点击图片样式-新建图片样式，七牛云提供了如下很多种场景： api_for_image_process 比如，这里我们选择指定宽高，强行缩放+打图片水印，然后添加一个文字水印，可以调整文字的字体样式，位置等等： add_water_mark_api 调整好之后，为样式取个名称，如webpic，这样，只要在原来外链的后面添加-webpic就可以了： 1http://pic.ex2tron.xin/filename.png-webpic 其中-这个连接符可以通过存储空间控制面板的样式分隔符设置中进行修改。 图床工具对于七牛云，每张图片都在网页端上传还是比较麻烦的，所以用一些图床客户端工具会更加快速。 这里推荐使用MPic图床神器。打开软件后，设置好自己的AK和SK（可在七牛云的个人中心-密钥管理中看到）。MPic支持文件拖拽上传，点击复制就可以复制外链，非常方便： mpic_qiniu","tags":[{"name":"Code","slug":"Code","permalink":"https://ex2tron.github.io/tags/Code/"},{"name":"利器篇","slug":"利器篇","permalink":"https://ex2tron.github.io/tags/利器篇/"},{"name":"qiniu","slug":"qiniu","permalink":"https://ex2tron.github.io/tags/qiniu/"},{"name":"七牛云","slug":"七牛云","permalink":"https://ex2tron.github.io/tags/七牛云/"},{"name":"图床","slug":"图床","permalink":"https://ex2tron.github.io/tags/图床/"}]},{"title":"Hexo+Github Pages轻松搭博客(2)——在Github上部署","date":"2017-09-13T12:15:47.000Z","path":"2017/09/13/Hexo-Github-Pages轻松搭博客-2-——在Github上部署/","text":"使用免费的Github Pages服务或者部署在自己服务器上，别人就可以访问你的博客啦！ 如果你已经有配置好的云服务器，直接可以将Hexo博客生成的public目录文件放在服务器上就好了。比如我购买的是阿里云服务器（apache），只需要将public下的文件放在/var/www/html/下面就可以用你服务器地址访问博客了。很容易，不过，考虑到云服务器的价格，这里我们还是用免费的Github吧。 关联Github首先登陆Github，没有账号的话，先注册一个。新建一个名为username.github.io的仓库，username必须与你的账户名相同，比如我的就是ex2tron.github.io，这就是你博客的域名地址了（绑定独立域名之后再说）。新建时注意勾选”Initialize this repository with a README“，因为这个仓库必须不能为空。 如果你是git新用户的话，推荐看：廖雪峰的Git教程-远程仓库 create_github_pages_repository 接下来打开博客目录下的_config.yml配置文件，定位到最后的deploy选项，修改如下：1234deploy: type: git repository: git@github.com:ex2tron/ex2tron.github.io.git branch: master 注意冒号后面有个空格，不然会出错滴~~~配置好之后，使用下面的命令就可以部署到Github上了：123$ hexo clean$ hexo g$ hexo d 这样通过Github提供的域名地址（如我的：https://ex2tron.github.io）就可以访问你的博客了，简单快速高效！ 发布新博客博客搭建起来之后，就可以用Markdown写博客辣，使用下面的命令，创建新博客（如名为：我的第一篇博客）：1$ hexo new '我的第一篇博客' 此命令会在博客目录\\source_posts\\h下生成“我的第一篇博客.md”文件，这就是你的博客源文件啦，文件开头如下，记得冒号后面有空格噢，不然会出错：12345---title: 我的第一篇博客date: 2017-09-13 20:15:47tags: #文章标签，格式：[1,2,3]--- 不熟悉Markdown语法的可以看：Markdown 语法说明。写完之后依然使用之前的三条命令发布：123$ hexo clean$ hexo g$ hexo d 后面两条指令也可以简化为一条：1$ hexo g -d 常出现的问题 在hexo d进行部署时，如果出现ERROR Deployer not found: git的问题，可以先用下面的命令修复： 1$ npm install hexo-deployer-git --save 如果你没配置过ssh导致部署失败（可以通过ssh -T username@example.com来测试ssh有无配置成功），可以参考这篇文章：针对github权限导致hexo部署失败的解决方案","tags":[{"name":"Code","slug":"Code","permalink":"https://ex2tron.github.io/tags/Code/"},{"name":"Hexo","slug":"Hexo","permalink":"https://ex2tron.github.io/tags/Hexo/"},{"name":"Github","slug":"Github","permalink":"https://ex2tron.github.io/tags/Github/"}]},{"title":"Hexo+Github Pages轻松搭博客(1)","date":"2017-09-13T08:07:06.000Z","path":"2017/09/13/Hexo-Github-Pages轻松搭博客-1/","text":"想用Github Pages轻松搭建自己的博客，用Hexo，10分钟！ 废话区域：我在接触Hexo（可以读作Hack So）之前，绝对没少尝试建立一个完全自由、自己说了算的独立博客：WordPress定位重量级，功能强大，生成的是动态网站，依赖数据库……太繁琐了，放弃~而Jekyll和Hexo都是静态建站工具，但Jekyll的依赖项也很多，也不简约，不想用~最后才是名气相对不高的Hexo，相信我，熟练的情况下，10分钟就可以搭出来： 简介Hexo是一个免费的静态Blog生成工具。简单来说，就是把你写的Markdown博客文件生成静态网页，把这个网页放在Github或者你自己的服务器上就可以快速访问了。软件界，从来不缺自动化工具(ง •_•)ง 安装官网文档：Hexo Docs Hexo安装前，你的电脑上需要先有下面这两个东西： Node.js Git 如果已经安装了的话，命令行下一句话就好啦：1$ npm install -g hexo-cli 初始化博客目录在你的本地新建一个存放博客的目录，比如”D:\\MyHexoBlog“，然后在这个目录右键，选择”Git Bash Here“，输入下面两条命令进行初始化：12$ hexo init$ npm install 初始化完成之后，你的目录结构应该是这样的：12345678.├── _config.yml├── package.json├── scaffolds├── source| ├── _drafts| └── _posts└── themes 如果没有出错的话，继续执行下面的指令启动服务：12$ hexo g $ hexo s 启动之后，在浏览器中访问：http://localhost:4000/，是不是看到了漂亮的Hexo博客页面了。不过目前这个博客还是运行在你本机上的，下篇我们看一下怎么样让别人也能访问这个博客。 default_hexo_index 参考资料： Hexo Docs Hexo+Github搭建个人博客(一)——开始搭建","tags":[{"name":"Code","slug":"Code","permalink":"https://ex2tron.github.io/tags/Code/"},{"name":"Hexo","slug":"Hexo","permalink":"https://ex2tron.github.io/tags/Hexo/"},{"name":"Github","slug":"Github","permalink":"https://ex2tron.github.io/tags/Github/"}]},{"title":"【利器篇】用VS Code写Markdown","date":"2017-09-11T07:11:22.000Z","path":"2017/09/11/【利器篇】用VSCode写Markdown/","text":"Markdown以其简洁、优雅整齐的风格，成为目前非常流行的博客文件格式。甚至有人说：每个人都应该用Markdown写博客。关于Markdown相较富文本的优势，我就不细说了。 Markdown编辑器支持Markdown的工具有很多，大家可以参考网上，如这篇文章：码字必备：18 款优秀的 Markdown 写作工具 | 2015 年度盘点。就我自己目前在Windows上使用的而言有：简书、有道云笔记、Typora、VSCode 简书本身就是一个博客平台，有道云笔记是类似OneNote和印象笔迹的应用。如果你已经在使用这两个平台的话，就不用多说了。但如果只是想用一个单纯的Markdown编辑器的话，推荐极致简洁的Typora。虽说界面简洁，但功能强大，不仅内置了常见的一些Markdown样式，还支持PDF/HTML等多种格式导出： markdown_in_typora 你是一枚文青的话，千万不要错过这款编辑器。不过，对于程序猿来说，VSCode才显得更有味道。 用VSCode写MarkdownVSCode就不过多介绍了，我之前也写过关于它的介绍： Visual Studio Code Preview初体验 Visual Studio Code Preview深度体验、使用技巧 现在版本的VSCode默认已经支持Markdown预览，不需要下载插件。用VSCode打开md文件或将当前文件更改为Markdown格式就可以开始书写了： markdown_in_vscode VSCode支持两种预览方式： 按下Ctrl+K V，像上图一样左右同步实时预览 按下Ctrl+Shift+V，只预览最终渲染结果 editor_preview_Synchronization 如上图，编写和预览界面是实时同步的，不需要的话，可以按下Ctrl+,组合键，添加如下两条设置： 12\"markdown.preview.scrollEditorWithPreview\": false,\"markdown.preview.scrollPreviewWithEditorSelection\": false 另外，目前VSCode预览样式中，中文的显示很别扭，这里推荐下载Github风格的CSS 下载完成后，配置css文件的设置如下即可： 123\"markdown.styles\": [ \"file:///D:/markdown-github.css\"] 另外，VSCode中有很多Markdown相关的插件，如”Markdown All in One”和”Markdown Theme Kit”等，大家可以下载下来尝试一下哈！ 参考资料：Markdown editing with Visual Studio Code","tags":[{"name":"Code","slug":"Code","permalink":"https://ex2tron.github.io/tags/Code/"},{"name":"利器篇","slug":"利器篇","permalink":"https://ex2tron.github.io/tags/利器篇/"},{"name":"Markdown","slug":"Markdown","permalink":"https://ex2tron.github.io/tags/Markdown/"},{"name":"VSCode","slug":"VSCode","permalink":"https://ex2tron.github.io/tags/VSCode/"}]},{"title":"【利器篇】MyCLI——自动补全和语法高亮的MySQL命令行工具","date":"2017-09-11T06:32:14.000Z","path":"2017/09/11/【利器篇】MyCLI——自动补全和语法高亮的MySQL命令行工具/","text":"mycli是MySQL命令行工具，支持关键字语法高亮和自动补全，看下面的动图你就知道了： mycli_demo mycli不仅会提示MySQL的关键字，更牛掰的是数据库名、表名、字段名都可以提示，非常方便。如果你经常在命令行里码MySQL命令，相信这款工具一定会让你满意。 官网：MyCLI 安装其实mycli是一个Python的包，所以你已经安装了Python(pip)的话，用下面一条指令就好了： 1&gt; pip install mycli 如果出现问题，可以参考官网，有详细的说明。 install_mycli 使用安装好之后，在cmd下，将以往登陆MySQL用的mysql换成mycli就可以了： login_with_mycli 好了，大家觉得好用的话，欢迎扩散噢！ Never give up. Never stop fighting. Excelsior!","tags":[{"name":"Code","slug":"Code","permalink":"https://ex2tron.github.io/tags/Code/"},{"name":"利器篇","slug":"利器篇","permalink":"https://ex2tron.github.io/tags/利器篇/"},{"name":"MyCLI","slug":"MyCLI","permalink":"https://ex2tron.github.io/tags/MyCLI/"},{"name":"MySQL","slug":"MySQL","permalink":"https://ex2tron.github.io/tags/MySQL/"}]},{"title":"博客新篇章！Brave New World","date":"2017-08-23T12:56:32.000Z","path":"2017/08/23/博客新篇章！/","text":"从2014/08/23在lofter上写我的第一篇博客开始，已经过去了整整三年…… 再见，lofterlofter是一个非常不错的轻博客平台，我喜欢它的设计和定位。但lofter终究不适合程序猿，长久以来不支持markdown也让我很头痛。现在，终于还是要说再见了! http://ex2tron.lofter.com 旧的66篇博客【Code/编程/开发】构建法、单点控制 构建法、表驱动法 【云端漫步】一起上“阿里云”（1）、购买学生党套餐 【云端漫步】一起上“阿里云”（2）、远程登陆服务器 【云端漫步】一起上“阿里云”（3）、LAMP环境搭建 【云端漫步】一起上“阿里云”（4）、搭建Git服务器 【云端漫步】一起上“阿里云”（5）、域名购买和解析 Python多字节二进制文件读取 C#中集合List的深浅拷贝 C#中常用的集合List去重方法 C#多字节二进制文件读取 深入理解C#（01）：堆栈、值类型和引用类型、值传递和引用传递 宽字符 编程命名法 编程字体推荐 Json序列化与反序列化（1）-JavaScriptSerializer Json序列化与反序列化（2）-Json.Net Json序列化与反序列化（3）-DataContractJsonSerializer CR与LF（操作系统“下一行”的不同） Visual Studio Code Preview初体验 Visual Studio Code Preview深度体验、使用技巧 Brand7-品牌漆上架商店啦！ UWP应用Brand7开发小记（1）、判断App是否是第一次启动 UWP应用Brand7开发小记（2）、用Excel和Json初始化本地数据源Part1 UWP应用Brand7开发小记（2）、用Excel和Json初始化本地数据源Part2 UWP 应用Brand7开发小记（3）、判断GridView的滚动方向 UWP应用Brand7开发小记（4）、集合控件的虚拟化问题 UWP 应用Brand7开发小记（5）、控件嵌入标题栏 MySQL学习小记（1）-不能启动MySQL服务 MySQL学习小记（2）-添加远程访问权限详解 MySQL学习小记（3）-外键的使用 MySQL学习小记（4）-最大连接数 MySQL学习小记（5）-主从服务器同步 VS至强插件ReSharper指南01、安装入门 【视觉与图像】【视觉与图像】摄像头篇（1）、CCD靶面尺寸 【视觉与图像】摄像头篇（2）、焦距和视角 CMake编译OpenCV3.2（Qt平台） Qt+OpenCV环境搭建 【Design/演示/设计】玩转PPT放映第一篇、演示者视图 玩转PPT放映第二篇、快捷键 玩转PPT放映第三篇、自定义放映 【PPT动画】钟摆效果 【PPT动画】模糊渐变切换效果 【PPT动画】制作左、右浮入效果 PPT制作画中画效果 PPT绘制长阴影图标 PPT三维立体图形绘制 PPT巧用矩形等分区域（黄金分割线） 【Lens/摄影/影视】家乡 | 黑白 | PENTAX K-50 | 看见不一样 看见，时光（延时摄影短片） 我那时的“计量”（一），黑白质感 我那时的“计量”（二），迎新色彩 Lumia 1520 by iPhone6s 历届奥斯卡最佳动画长片下载（1） 历届奥斯卡最佳动画长片下载（2） 「精品」皮克斯15部动画长片下载 【Other/科普/发现】PPI与DPI USB接口类型（2.0概述） Type-C和USB3.0（3.1） 发现Win10 Bug两枚（均得微软官方确认，一枚已解决） 再战之后，这场旅途，只属于我 Win8以上系统安装PL2303驱动 硬盘容量计算的差别 硬盘整数分区原理及计算（附工具下载） 详解Windows运行组件第一篇、原理篇 详解Windows运行组件第二篇、自定义运行指令 Windows 10技术预览版体验视频 Never give up. Never stop fighting. Excelsior!","tags":[]}]