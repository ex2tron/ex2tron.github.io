{"meta":{"title":"ex2tron's Blog","subtitle":"Excelsior!","description":null,"author":"Tony Wong","url":"http://ex2tron.coding.me"},"pages":[{"title":"About","date":"2017-12-20T07:06:25.000Z","updated":"2017-12-22T02:24:35.237Z","comments":true,"path":"about/index.html","permalink":"http://ex2tron.coding.me/about/index.html","excerpt":"","text":"我工科男一枚，但也非常喜欢艺术，不冲突 讨厌没有意义的事和废话，喜欢直接“干”！！！ 主业：程序猿（机器视觉与深度学习） 副业：啥都喜欢（电影、摄影、设计、艺术、羽毛球、乒乓、鸡血……）"},{"title":"categories","date":"2017-12-20T07:06:09.000Z","updated":"2017-12-20T08:17:21.571Z","comments":true,"path":"categories/index.html","permalink":"http://ex2tron.coding.me/categories/index.html","excerpt":"","text":""},{"title":"tags","date":"2017-12-20T07:06:09.000Z","updated":"2017-12-20T08:17:40.499Z","comments":true,"path":"tags/index.html","permalink":"http://ex2tron.coding.me/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"构建：查表法","slug":"构建：表驱动法","date":"2018-04-08T10:54:04.000Z","updated":"2018-04-09T00:17:12.266Z","comments":true,"path":"2018/04/08/构建：表驱动法/","link":"","permalink":"http://ex2tron.coding.me/2018/04/08/构建：表驱动法/","excerpt":"每次谈到查表，我都会先想到下面这个简单的例子：","text":"每次谈到查表，我都会先想到下面这个简单的例子： 宁在一思进，莫在一思停。——《一代宗师》 示例如果你需要根据月份计算当月的天数（不考虑闰年），你会怎么写？ 如果使用if语句，你的代码可能会像这样： 12345678910111213141516171819202122232425# Python示例（其他语言中Switch/case也一样）if (month == 1): day = 31elif (month == 2): day = 28elif(month == 3): day = 31elif (month == 4): day = 30elif (month == 5): day = 31elif (month == 6): day = 30elif (month == 7): day = 31elif (month == 8): day = 31elif (month == 9): day = 30elif(month == 10): day = 31elif (month == 11): day = 30elif (month == 12): day = 31 很显然，这是一种既冗长又比较笨的方法，那如何更简洁和优雅呢？这就要用到“表”了，为什么强调简洁和优雅？因为人生苦短呀( ╯□╰ )： 12dayOfMonth = [31, 28, 31, 30, 31, 30, 31, 31, 30, 31, 30, 31]day = dayOfMonth[month - 1] 怎么样，2行够简洁了吗？ 本文内容是我阅读《代码大全：表驱动法p411》时的笔记，加入了自己的案例和总结。 概述 表驱动法：从表中查找信息而不是使用逻辑语句（if/else/switch/case），也可称查表法。 对于简单的情况，逻辑判断更简单和易理解，但数据量和逻辑链增大的时候，查表法在灵活性、可维护性等方面有着显著的优势。 查表法的核心在于如果构建表。前面的例子中，月份不重复，以月份为索引建立一个数组即可。但如果逻辑判断是个区间，比如对于下面的考试成绩，应该如何建表呢？ 90-100分：优 | 70-90分：良 | 60-70分：及格 | 60分以下：不及格 直接查表月份的例子就是直接查表，查询的信息（月份）可以直接转为表中的索引，一目了然。下面再看个例子： 有一个根据汽车速度计算转弯距离的程序：速度30马以下，距离为固定值a；100马以上也为固定值b；31~99之间，每个速度对应1个数值。这时如何建表呢？ 1.重复数据，直接使用键值 第一种方式可以把a复制31次，100以上也复制多次，那表应该像这样： 显然，这种方式很蠢，不仅有很多冗余的数据，而且很容易出错。 2.转换键值 我们可以用一个函数将键值做下转换：因为0~30是同一值，所以将0~30转成一个键值，100以上转成一个键值，中间的数据本身作为键值。对于这种转换，可以一句话搞定： 12# Python语言示例newKey = max(min(100, speed), 30) 其他语言中max/min函数一般在Math相关模块中可以找到。这样完整的代码如下： 12distanceOfSpeed = [a, n31, n32, ……, n99, b]result = distanceOfSpeed[max(min(100, speed), 30) - 30] 阶梯查表前面考试成绩的例子，不同的成绩范围对应不同的数据，如同台阶一样： 这时可以使用阶梯查表：表内的数据是对应不同的数据范围，而不是对应不同的数据点。阶梯法查表就是循环检查每个区间的上限。当分数第一次超过某个区间的上限时，就可以得到想要的等级（留心端点的值噢：&lt;和&lt;=的区别）： 123456789101112# Python语言示例scoreLimit = [60.0, 70.0, 90.0, 100.0]grade = [\"不及格\", \"及格\", \"良\", \"优\"]score, index, result = 45, 0, '优'# 这个条件语句很重要噢！while (result == '优' and index &lt; len(grade) - 1): if (score &lt; scoreLimit[index]): result = grade[index] index += 1print(result) # 不及格 这种阶梯方法很适合处理区间、等级评价和键值无规则的场合。 除了上面两种方法外，还有索引查表法：相当于书的目录。先从目录中找到页码，再根据页码找到对应的记录。在程序中，就是先建一张索引表，从索引表中找出值，再在主表中查到数据，数据库经常用到，这里不详细介绍了。 另外，可以将表存储在外部，这样可以在不更改逻辑代码的情况下，改变表的值。 引用 本节源码 旧版：构建法——表驱动法","categories":[{"name":"Build篇","slug":"Build篇","permalink":"http://ex2tron.coding.me/categories/Build篇/"}],"tags":[{"name":"构建法","slug":"构建法","permalink":"http://ex2tron.coding.me/tags/构建法/"},{"name":"表驱动法","slug":"表驱动法","permalink":"http://ex2tron.coding.me/tags/表驱动法/"},{"name":"查表法","slug":"查表法","permalink":"http://ex2tron.coding.me/tags/查表法/"}]},{"title":"Python+OpenCV教程18：理解特征","slug":"Python-OpenCV教程18：理解特征","date":"2018-03-15T12:13:55.000Z","updated":"2018-03-15T14:12:22.045Z","comments":true,"path":"2018/03/15/Python-OpenCV教程18：理解特征/","link":"","permalink":"http://ex2tron.coding.me/2018/03/15/Python-OpenCV教程18：理解特征/","excerpt":"学习和了解图像特征的重要性。","text":"学习和了解图像特征的重要性。图片等可到源码处下载。 目标 理解图像特征 图像特征的重要性和用途 教程拼图游戏相信大部分人都玩过拼图游戏：根据散落的图片小块最终拼接成一副完整的图片。那么，你是怎么拼起来的呢？ 我们是通过小块间的相似性来拼的，但我们很难具体说出来这个”像”，谁叫我们的大脑已经被上帝编好程序了呢(￣_￣)。现在做个假设，如果能让计算机找到这些小块间的相似性，是不是也可以让计算机玩拼图游戏呢？ 理解特征那这些特征有哪些？如何找到这些特征呢？我们来看下这幅图片： 图的上面有6个小块，都是图中的某一部分。你能找到这6个小块在图中的具体位置吗？ A和B很难确定具体的位置，因为它们在原图中的很多地方都有。可以把这些地方称为扁平的区域。 C和D相对容易点，因为它们是建筑物的边缘。虽然也比较难确定具体位置，但可以找到一个大致的位置。 可以说边缘是比扁平区域更好的一种特征。 最后，E和F就好找多了，因为它们是建筑物的角点。在角点位置上，不论将小块怎么移动，都会得到不同的结果。 所以说角点是比边缘更好的一种特征。 可以简单地用下面这个图来表示这三种特征： 蓝色方块代表的扁平区域很难定位，因为不论移动到哪儿，结果都一样； 黑色方块表示边缘，如果我们垂直移动它，它就会改变，但水平移动，结果仍然不变； 最后红色方块表示角点，随便移动它，它都会改变，说明它是唯一的。所以，角点对图像来说就是一个比较好的特征。 现在我们就回答了”什么是特征？”这个问题，那么我们如何找到特征呢？其实不难发现，对于角点，我们可以通过移动图像中的一个小区域，找出图像中变化量最大的地方，这就叫特征检测。找到特征后，我们可以这样描述图片：图的上面是天空，下面是一个建筑物，建筑物外层是玻璃等等，这就叫特征描述。特征检测和特征描述就是我们接下来要学习的内容。 引用 Understanding Features","categories":[{"name":"机器视觉","slug":"机器视觉","permalink":"http://ex2tron.coding.me/categories/机器视觉/"}],"tags":[{"name":"OpenCV","slug":"OpenCV","permalink":"http://ex2tron.coding.me/tags/OpenCV/"},{"name":"Python","slug":"Python","permalink":"http://ex2tron.coding.me/tags/Python/"},{"name":"图像处理","slug":"图像处理","permalink":"http://ex2tron.coding.me/tags/图像处理/"},{"name":"特征","slug":"特征","permalink":"http://ex2tron.coding.me/tags/特征/"}]},{"title":"【片单】推荐几部优秀的传记电影","slug":"【片单】推荐几部优秀的传记电影","date":"2018-03-15T05:46:50.000Z","updated":"2018-03-15T07:43:52.335Z","comments":true,"path":"2018/03/15/【片单】推荐几部优秀的传记电影/","link":"","permalink":"http://ex2tron.coding.me/2018/03/15/【片单】推荐几部优秀的传记电影/","excerpt":"“Look up at the stars, not down at your feet.” ——Stephen Hawking 昨天看到霍金去世的新闻，无比震惊，走在路上，停留了片刻。也许就像很多人说的，他，属于星辰大海！","text":"“Look up at the stars, not down at your feet.” ——Stephen Hawking 昨天看到霍金去世的新闻，无比震惊，走在路上，停留了片刻。也许就像很多人说的，他，属于星辰大海！ 以下是我看过的一些优秀传记片，推荐给大家（大部分片源来自人人影视字幕组，点击片名即可下载）： 万物理论(The Theory of Everything) | 霍金 | 豆瓣8.1 模仿游戏(The Imitation Game) | 图灵 | 豆瓣8.5 美丽心灵(A Beautiful Mind) | 约翰·纳什 | 豆瓣8.9 霍金传(Hawing) | 霍金 | 豆瓣8.6 末代皇帝(The Last Emperor) | 爱新觉罗·溥仪 | 豆瓣8.9 当幸福来敲门(The Pursuit of Happyness) | 克里斯·加德纳 | 豆瓣8.9 钢琴家(The Pianist) | 席皮尔曼 | 豆瓣9.0 摔跤吧！爸爸(Dangal) | 马哈维亚·辛格·珀尕 | 豆瓣9.1 至暗时刻(Darkest Hour) | 丘吉尔 | 豆瓣8.6 国王的演讲(The King’s Speech) | 乔治六世 | 豆瓣8.3 弱点(The Blind Side) | 迈克尔·奥赫 | 豆瓣8.4 勇敢的心(Braveheart) | 威廉·华莱士 | 豆瓣8.8 启功(The Calligraphy Master) | 启功 | 豆瓣7.6 其实还有很多好的传记片，上面这几个是看过能立马想起来的，有机会再补充！","categories":[{"name":"谈电影","slug":"谈电影","permalink":"http://ex2tron.coding.me/categories/谈电影/"}],"tags":[{"name":"传记片","slug":"传记片","permalink":"http://ex2tron.coding.me/tags/传记片/"}]},{"title":"Python+OpenCV教程17：霍夫变换","slug":"Python-OpenCV教程17：霍夫变换","date":"2017-12-28T03:35:11.000Z","updated":"2017-12-29T02:59:29.861Z","comments":true,"path":"2017/12/28/Python-OpenCV教程17：霍夫变换/","link":"","permalink":"http://ex2tron.coding.me/2017/12/28/Python-OpenCV教程17：霍夫变换/","excerpt":"学习使用霍夫变换识别出图像中的直线和圆。","text":"学习使用霍夫变换识别出图像中的直线和圆。图片等可到源码处下载。 目标 理解霍夫变换的实现 分别使用霍夫线变换和圆变换检测图像中的直线和圆 OpenCV函数：cv2.HoughLines(), cv2.HoughLinesP(), cv2.HoughCircles() 教程理解霍夫变换霍夫变换常用来在图像中提取直线和圆等几何形状，实现原理在维基百科上解释的非常清楚：Hough transform，我来做个简易的解释，感兴趣的可以一看，否则划掉(●ˇ∀ˇ●)： 学过几何的都知道，直线可以分别用直角坐标系和极坐标系来表示： 那么经过某个点(x0,y0)的所有直线都可以用这个式子来表示：$ r_\\theta=x_0\\cdot\\cos \\theta+y_0\\cdot\\sin \\theta$ 也就是说每一个(r,θ)都表示一条经过(x0,y0)直线，那么同一条直线上的点必然会有同样的(r,θ)。如果将某个点所有的(r,θ)绘制成下面的曲线，那么同一条直线上的点的(r,θ)曲线会相交于一点： OpenCV中首先计算(r,θ) 累加数，累加数超过一定值后就认为在同一直线上（有点拗口，不懂也没关系，暂时会用就行）。 霍夫直线变换OpenCV中用cv2.HoughLines()在二值图上实现霍夫变换，函数返回的是一组直线的(r,θ)数据： 12345678# 1.加载图片，转为二值图img = cv2.imread('shapes.jpg')drawing = np.zeros(img.shape[:], dtype=np.uint8)gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)edges = cv2.Canny(gray, 50, 150)# 2.霍夫直线变换lines = cv2.HoughLines(edges, 0.8, np.pi / 180, 90) 函数中： 参数1：要检测的二值图（一般是阈值分割或边缘检测后的图） 参数2：距离r的精度，值越大，考虑越多的线 参数3：角度θ的精度，值越小，考虑越多的线 参数4：累加数阈值，值越小，考虑越多的线 12345678910111213# 3.将检测的线画出来（注意是极坐标噢）for line in lines: rho, theta = line[0] a = np.cos(theta) b = np.sin(theta) x0 = a * rho y0 = b * rho x1 = int(x0 + 1000 * (-b)) y1 = int(y0 + 1000 * (a)) x2 = int(x0 - 1000 * (-b)) y2 = int(y0 - 1000 * (a)) cv2.line(drawing, (x1, y1), (x2, y2), (0, 0, 255)) 统计概率霍夫直线变换前面的方法又称为标准霍夫变换，它会计算图像中的每一个点，计算量比较大，另外它得到的是整一条线（r和θ），并不知道原图中直线的端点。所以提出了统计概率霍夫直线变换(Probabilistic Hough Transform)，是一种改进的霍夫变换： 1234drawing = np.zeros(img.shape[:], dtype=np.uint8)# 3.统计概率霍夫线变换lines = cv2.HoughLinesP(edges, 0.8, np.pi / 180, 90, minLineLength=50, maxLineGap=10) 前面几个参数跟之前的一样，有两个可选参数： minLineLength：最短长度阈值，比这个长度短的线会被排除 maxLineGap：同一直线两点之间的最大距离 1234# 3.将检测的线画出来for line in lines: x1, y1, x2, y2 = line[0] cv2.line(drawing, (x1, y1), (x2, y2), (0, 255, 0), 1, lineType=cv2.LINE_AA) cv2.LINE_AA在之前绘图功能中讲解过，表示抗锯齿线型。 霍夫圆变换霍夫圆变换跟直线变换类似，只不过线是用(r,θ)表示，圆是用(x_center,y_center,r)来表示，从二维变成了三维，数据量变大了很多；所以一般使用霍夫梯度法减少计算量，对该算法感兴趣的同学可参考：Circle Hough Transform 1234drawing = np.zeros(img.shape[:], dtype=np.uint8)# 2.霍夫圆变换circles = cv2.HoughCircles(edges, cv2.HOUGH_GRADIENT, 1, 20, param2=30)circles = np.int0(np.around(circles)) 其中， 参数2：变换方法，一般使用霍夫梯度法，详情：HoughModes 参数3 dp=1：表示霍夫梯度法中累加器图像的分辨率与原图一致 参数4：两个不同圆圆心的最短距离 参数5：param2跟霍夫直线变换中的累加数阈值一样 1234# 将检测的圆画出来for i in circles[0, :]: cv2.circle(drawing, (i[0], i[1]), i[2], (0, 255, 0), 2) # 画出外圆 cv2.circle(drawing, (i[0], i[1]), 2, (0, 0, 255), 3) # 画出圆心 小结 霍夫变换用来提取图像中的直线和圆等几何形状 霍夫直线变换：cv2.HoughLines()（整条直线）, cv2.HoughLinesP() 霍夫圆变换：cv2.HoughCircles() 引用 本节源码 Hough Line Transform Hough Circle Transform","categories":[{"name":"机器视觉","slug":"机器视觉","permalink":"http://ex2tron.coding.me/categories/机器视觉/"}],"tags":[{"name":"OpenCV","slug":"OpenCV","permalink":"http://ex2tron.coding.me/tags/OpenCV/"},{"name":"Python","slug":"Python","permalink":"http://ex2tron.coding.me/tags/Python/"},{"name":"图像处理","slug":"图像处理","permalink":"http://ex2tron.coding.me/tags/图像处理/"},{"name":"霍夫变换","slug":"霍夫变换","permalink":"http://ex2tron.coding.me/tags/霍夫变换/"}]},{"title":"Python+OpenCV教程16：模板匹配","slug":"Python-OpenCV教程16：模板匹配","date":"2017-12-27T08:45:31.000Z","updated":"2018-01-18T02:14:14.760Z","comments":true,"path":"2017/12/27/Python-OpenCV教程16：模板匹配/","link":"","permalink":"http://ex2tron.coding.me/2017/12/27/Python-OpenCV教程16：模板匹配/","excerpt":"学习使用模板匹配在图像中寻找物体。","text":"学习使用模板匹配在图像中寻找物体。图片等可到源码处下载。 目标 使用模板匹配在图像中寻找物体 OpenCV函数：cv2.matchTemplate(), cv2.minMaxLoc() 教程模板匹配模板匹配就是用来在大图中找小图，也就是说在一副图像中寻找另外一张模板图像的位置： 用cv2.matchTemplate()实现模板匹配。首先我们来读入图片和模板： 123img = cv2.imread('lena.jpg', 0)template = cv2.imread('face.jpg', 0)h, w = template.shape[:2] # rows-&gt;h, cols-&gt;w 匹配函数返回的是一副灰度图，最白的地方表示最大的匹配。使用cv2.minMaxLoc()函数可以得到最大匹配值的坐标，以这个点为左上角角点，模板的宽和高画矩形就是匹配的位置了： 1234567# 相关系数匹配方法：cv2.TM_CCOEFFres = cv2.matchTemplate(img, template, cv2.TM_CCOEFF)min_val, max_val, min_loc, max_loc = cv2.minMaxLoc(res)left_top = max_loc # 左上角right_bottom = (left_top[0] + w, left_top[1] + h) # 右下角cv2.rectangle(img, left_top, right_bottom, 255, 2) # 画出矩形位置 原理 这部分可看可不看，不太理解也没关系，还记得前面的方法吗？不懂得就划掉(✿◕‿◕✿) 模板匹配的原理其实很简单，就是不断地在原图中移动模板图像去比较，有6种不同的比较方法，详情可参考：TemplateMatchModes 平方差匹配CV_TM_SQDIFF：用两者的平方差来匹配，最好的匹配值为0 归一化平方差匹配CV_TM_SQDIFF_NORMED 相关匹配CV_TM_CCORR：用两者的乘积匹配，数值越大表明匹配程度越好 归一化相关匹配CV_TM_CCORR_NORMED 相关系数匹配CV_TM_CCOEFF：用两者的相关系数匹配，1表示完美的匹配，-1表示最差的匹配 归一化相关系数匹配CV_TM_CCOEFF_NORMED 这些方法的对比代码可到源码处查看。模板匹配也是应用卷积来实现的：假设原图大小为W×H，模板图大小为w×h，那么生成图大小是(W-w+1)×(H-h+1)，生成图中的每个像素值表示原图与模板的匹配程度。 匹配多个物体前面我们是找最大匹配的点，所以只能匹配一次。我们可以设定一个匹配阈值来匹配多次： 123456789101112131415# 1.读入原图和模板img_rgb = cv2.imread('mario.jpg')img_gray = cv2.cvtColor(img_rgb, cv2.COLOR_BGR2GRAY)template = cv2.imread('mario_coin.jpg', 0)h, w = template.shape[:2]# 2.标准相关模板匹配res = cv2.matchTemplate(img_gray, template, cv2.TM_CCOEFF_NORMED)threshold = 0.8 # 3.这边是Python/Numpy的知识，后面解释loc = np.where(res &gt;= threshold) # 匹配程度大于%80的坐标y,xfor pt in zip(*loc[::-1]): # *号表示可选参数 right_bottom = (pt[0] + w, pt[1] + h) cv2.rectangle(img_rgb, pt, right_bottom, (0, 0, 255), 2) 第3步有几个Python/Numpy的重要知识，来大致看下： np.where在这里返回res中值大于0.8的所有坐标，如： 123x = np.arange(9.).reshape(3, 3)print(np.where(x &gt; 5))# 结果(先y坐标，再x坐标)：(array([2, 2, 2]), array([0, 1, 2])) zip函数，功能很强大到难以解释，举个简单例子就知道了： 123x = [1, 2, 3]y = [4, 5, 6]print(list(zip(x, y))) # [(1, 4), (2, 5), (3, 6)] 这样大家就能理解前面代码的用法了吧：因为loc是先y坐标再x坐标，所以用loc[::-1]翻转一下，然后再用zip函数拼接在一起。 练习 之前我们有学过形状匹配，不论形状旋转/缩放都可以匹配到。思考一下，图片旋转或缩放的话模板匹配还有作用吗？ 小结 模板匹配用来在大图中找小图 cv2.matchTemplate()用来进行模板匹配 引用 本节源码 Template Matching 模板匹配 TemplateMatchModes","categories":[{"name":"机器视觉","slug":"机器视觉","permalink":"http://ex2tron.coding.me/categories/机器视觉/"}],"tags":[{"name":"OpenCV","slug":"OpenCV","permalink":"http://ex2tron.coding.me/tags/OpenCV/"},{"name":"Python","slug":"Python","permalink":"http://ex2tron.coding.me/tags/Python/"},{"name":"图像处理","slug":"图像处理","permalink":"http://ex2tron.coding.me/tags/图像处理/"},{"name":"模板匹配","slug":"模板匹配","permalink":"http://ex2tron.coding.me/tags/模板匹配/"}]},{"title":"Python+OpenCV教程15：直方图","slug":"Python-OpenCV教程15：直方图","date":"2017-12-23T09:48:30.000Z","updated":"2017-12-26T05:29:28.740Z","comments":true,"path":"2017/12/23/Python-OpenCV教程15：直方图/","link":"","permalink":"http://ex2tron.coding.me/2017/12/23/Python-OpenCV教程15：直方图/","excerpt":"学习计算并绘制直方图，直方图均衡化等。","text":"学习计算并绘制直方图，直方图均衡化等。图片等可到源码处下载。 目标 计算并绘制直方图 （自适应）直方图均衡化 OpenCV函数：cv2.calcHist(), cv2.equalizeHist() 教程啥叫直方图直方图简单来说就是图像中每个像素值的个数统计，比如说一副灰度图中像素值为0的有多少个，1的多少个……直方图是一种分析图片的手段： 在计算直方图之前，有几个术语先来了解一下： dims：要计算的通道数，对于灰度图dims=1 range：要计算的像素值范围，一般为[0,256]（不包括256） bins：子区段数目，如果我们统计0~255每个像素值，bins=256；如果划分区间，比如0~15, 16~31…240~255这样16个区间，bins=16 计算直方图OpenCV和Numpy中都提供了计算直方图的函数，我们对比下它们的性能。 OpenCV中直方图计算使用cv2.calcHist(images, channels, mask, histSize, ranges)计算，其中： 参数1：要计算的原图，以方括号的传入，如：[img] 参数2：类似前面提到的dims，灰度图写[0]就行，彩色图B/G/R分别传入[0]/[1]/[2] 参数3：要计算的区域，计算整幅图的话，写None 参数4：前面提到的bins 参数5：前面提到的range 12img = cv2.imread('hist.jpg', 0)hist = cv2.calcHist([img], [0], None, [256], [0, 256]) # 性能：0.025288 s Numpy中直方图计算也可用Numpy的函数计算，其中ravel()函数将二维矩阵展平变成一维数组，之前有提到过： 1hist, bins = np.histogram(img.ravel(), 256, [0, 256]) # 性能：0.020628 s 经验之谈：Numpy中还有一种更高效的方式：（还记得怎么评估性能吗：番外篇：代码性能优化） 1hist = np.bincount(img.ravel(), minlength=256) # 性能：0.003163 s 计算出直方图之后，怎么把它画出来呢？ 绘制直方图其实Matplotlib自带了一个计算并绘制直方图的功能，不需要用到上面的函数： 12plt.hist(img.ravel(), 256, [0, 256])plt.show() 当然，也可以用前面计算出来的结果绘制： 1plt.plot(hist); plt.show() 从直方图上可以看到图片的大部分区域集中在150偏白的附近，这其实并不是很好的效果，下面我们来看看如何改善它。 使用OpenCV的画线功能也可以画直方图，不过太麻烦了，有兴趣的可以看下官方示例：hist.py 直方图均衡化一副效果好的图像通常在直方图上的分布比较均匀，直方图均衡化就是用来改善图像的全局亮度和对比度。其实从观感上就可以发现，前面那幅图对比度不高，偏灰白。对均衡化算法感兴趣的同学可参考：维基百科：直方图均衡化 1equ = cv2.equalizeHist(img) OpenCV中用cv2.equalizeHist()实现均衡化。我们把两张图片并排显示，对比一下： 12cv2.imshow('equalization', np.hstack((img, equ))) # 并排显示cv2.waitKey(0) 可以看到均衡化后图片的亮度和对比度效果明显好于原图。 自适应均衡化不难看出来，直方图均衡化是应用于整幅图片的，会有什么问题呢？看下图： 很明显，因为全局调整亮度和对比度的原因，脸部太亮，大部分细节都丢失了。 自适应均衡化就是用来解决这一问题的：它在每一个小区域内（默认8×8）进行直方图均衡化。当然，如果有噪点的话，噪点会被放大，需要对小区域内的对比度进行了限制，所以这个算法全称叫：对比度受限的自适应直方图均衡化CLAHE Contrast Limited Adaptive Histogram Equalization 123# 自适应均衡化，参数可选clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))cl1 = clahe.apply(img) 练习 cv2.calcHist()函数中的参数3是指要计算的区域(mask：目标区域白色，其余黑色)，编写一个只计算图片左上角200×200区域直方图的程序 小结 直方图是一种分析图像的手段 cv2.calcHist()和numpy.bincount()均可用来计算直方图，使用Matplotlib绘制直方图 均衡化用来使图像的直方图分布更加均匀，提升亮度和对比度 引用 本节源码 Histograms - 1 : Find, Plot, Analyze !!! Histograms - 2: Histogram Equalization 维基百科：直方图均衡化 维基百科：自适应直方图均衡化 Cambridge in Color website","categories":[{"name":"机器视觉","slug":"机器视觉","permalink":"http://ex2tron.coding.me/categories/机器视觉/"}],"tags":[{"name":"OpenCV","slug":"OpenCV","permalink":"http://ex2tron.coding.me/tags/OpenCV/"},{"name":"Python","slug":"Python","permalink":"http://ex2tron.coding.me/tags/Python/"},{"name":"图像处理","slug":"图像处理","permalink":"http://ex2tron.coding.me/tags/图像处理/"},{"name":"直方图","slug":"直方图","permalink":"http://ex2tron.coding.me/tags/直方图/"}]},{"title":"Python+OpenCV教程14：轮廓特征","slug":"Python-OpenCV教程14：轮廓特征","date":"2017-12-20T10:46:19.000Z","updated":"2018-01-22T08:19:33.291Z","comments":true,"path":"2017/12/20/Python-OpenCV教程14：轮廓特征/","link":"","permalink":"http://ex2tron.coding.me/2017/12/20/Python-OpenCV教程14：轮廓特征/","excerpt":"学习计算轮廓特征，如面积、周长、最小外接矩形等。","text":"学习计算轮廓特征，如面积、周长、最小外接矩形等。图片等可到源码处下载。 目标 计算物体的周长、面积、质心、最小外接矩形等 OpenCV函数：cv2.contourArea(), cv2.arcLength(), cv2.approxPolyDP() 等 教程在计算轮廓特征之前，我们先用上一节的代码把轮廓找到： 123456img = cv2.imread('handwriting.jpg', 0)_, thresh = cv2.threshold(img, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)image, contours, hierarchy = cv2.findContours(thresh, 3, 2)# 以数字3的轮廓为例cnt = contours[0] 为了便于绘制，我们创建出两幅彩色图，并把轮廓画在第一幅图上： 123img_color1 = cv2.cvtColor(image, cv2.COLOR_GRAY2BGR)img_color2 = np.copy(img_color1)cv2.drawContours(img_color1, [cnt], 0, (0, 0, 255), 2) 轮廓面积1area = cv2.contourArea(cnt) # 4386.5 注意轮廓特征计算的结果并不等同于像素点的个数，而是根据几何方法算出来的，所以有小数。 如果统计二值图中像素点个数，应尽量避免循环，可以使用cv2.countNonZero()，更加高效 轮廓周长1perimeter = cv2.arcLength(cnt, True) # 585.7 参数2表示轮廓是否封闭，显然我们的轮廓是封闭的，所以是True。 图像矩矩可以理解为图像的各类几何特征，详情请参考：[Image Moments] 1M = cv2.moments(cnt) M中包含了很多轮廓的特征信息，比如M[&#39;m00&#39;]表示轮廓面积，与前面cv2.contourArea()计算结果是一样的。质心也可以用算： 1cx, cy = M['m10'] / M['m00'], M['m01'] / M['m00'] # (205, 281) 外接矩形形状的外接矩形有两种，如下图，绿色的叫外接矩形，表示不考虑旋转并且能包含整个轮廓的矩形。蓝色的叫最小外接矩，考虑了旋转： 12x, y, w, h = cv2.boundingRect(cnt) # 外接矩形cv2.rectangle(img_color1, (x, y), (x + w, y + h), (0, 255, 0), 2) 123rect = cv2.minAreaRect(cnt) # 最小外接矩形box = np.int0(cv2.boxPoints(rect)) # 矩形的四个角点取整cv2.drawContours(img_color1, [box], 0, (255, 0, 0), 2) 其中np.int0(x)是把x取整的操作，比如377.93就会变成377，也可以用x.astype(np.int) 最小外接圆外接圆跟外接矩形一样，找到一个能包围物体的最小圆： 123(x, y), radius = cv2.minEnclosingCircle(cnt)(x, y, radius) = np.int0((x, y, radius)) # 圆心和半径取整cv2.circle(img_color2, (x, y), radius, (0, 0, 255), 2) 拟合椭圆我们可以用得到的轮廓拟合出一个椭圆： 12ellipse = cv2.fitEllipse(cnt)cv2.ellipse(img_color2, ellipse, (255, 255, 0), 2) 形状匹配cv2.matchShapes()可以检测两个形状之间的相似度，返回值越小，越相似。先读入下面这张图片： 1234img = cv2.imread('shapes.jpg', 0)_, thresh = cv2.threshold(img, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)image, contours, hierarchy = cv2.findContours(thresh, 3, 2)img_color = cv2.cvtColor(thresh, cv2.COLOR_GRAY2BGR) # 用于绘制的彩色图 图中有3条轮廓，我们用A/B/C表示： 1234cnt_a, cnt_b, cnt_c = contours[0], contours[1], contours[2]print(cv2.matchShapes(cnt_b, cnt_b, 1, 0.0)) # 0.0print(cv2.matchShapes(cnt_b, cnt_c, 1, 0.0)) # 2.17e-05print(cv2.matchShapes(cnt_b, cnt_a, 1, 0.0)) # 0.418 可以看到BC相似程度比AB高很多，并且图形的旋转或缩放并没有影响。其中，参数3是匹配方法，详情可参考：ShapeMatchModes，参数4是OpenCV的预留参数，暂时没有实现，可以不用理会。 形状匹配是通过图像的Hu矩来实现的(cv2.HuMoments())，大家如果感兴趣，可以参考：Hu-Moments 练习 前面我们是对图片中的数字3进行轮廓特征计算的，大家换成数字1看看 （选做）用形状匹配比较两个字母或数字（这相当于很简单的一个OCR噢） 小结常用的轮廓特征： cv2.contourArea()算面积，cv2.arcLength()算周长，cv2.boundingRect()算外接矩 cv2.minAreaRect()算最小外接矩，cv2.minEnclosingCircle()算最小外接圆 cv2.matchShapes()进行形状匹配 引用 本节源码 Contour Features Contours : More Functions","categories":[{"name":"机器视觉","slug":"机器视觉","permalink":"http://ex2tron.coding.me/categories/机器视觉/"}],"tags":[{"name":"OpenCV","slug":"OpenCV","permalink":"http://ex2tron.coding.me/tags/OpenCV/"},{"name":"Python","slug":"Python","permalink":"http://ex2tron.coding.me/tags/Python/"},{"name":"图像处理","slug":"图像处理","permalink":"http://ex2tron.coding.me/tags/图像处理/"},{"name":"轮廓","slug":"轮廓","permalink":"http://ex2tron.coding.me/tags/轮廓/"}]},{"title":"Python+OpenCV教程番外篇10：凸包及更多轮廓特征","slug":"Python-OpenCV教程番外篇10：凸包及更多轮廓特征","date":"2017-12-20T05:41:11.000Z","updated":"2018-01-19T06:08:20.571Z","comments":true,"path":"2017/12/20/Python-OpenCV教程番外篇10：凸包及更多轮廓特征/","link":"","permalink":"http://ex2tron.coding.me/2017/12/20/Python-OpenCV教程番外篇10：凸包及更多轮廓特征/","excerpt":"计算凸包及更多轮廓特征。","text":"计算凸包及更多轮廓特征。图片等可到源码处下载。 多边形逼近前面我们学习过最小外接矩和最小外接圆，那么可以用一个最小的多边形包围物体吗？当然可以： 123456789101112# 1.先找到轮廓img = cv2.imread('unregular.jpg', 0)_, thresh = cv2.threshold(img, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)image, contours, hierarchy = cv2.findContours(thresh, 3, 2)cnt = contours[0]# 2.进行多边形逼近，得到多边形的角点approx = cv2.approxPolyDP(cnt, 3, True)# 3.画出多边形image = cv2.cvtColor(image, cv2.COLOR_GRAY2BGR)cv2.polylines(image, [approx], True, (0, 255, 0), 2) 其中cv2.approxPolyDP()的参数2(epsilon)是一个距离值，表示多边形的轮廓接近实际轮廓的程度，值越小，越精确；参数3表示是否闭合。 凸包凸包跟多边形逼近很像，只不过它是物体最外层的”凸”多边形：集合A内连接任意两个点的直线都在A的内部，则称集合A是凸形的。如下图，红色的部分为手掌的凸包，双箭头部分表示凸缺陷(Convexity Defects)，凸缺陷常用来进行手势识别等： 123456789101112# 1.先找到轮廓img = cv2.imread('convex.jpg', 0)_, thresh = cv2.threshold(img, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)image, contours, hierarchy = cv2.findContours(thresh, 3, 2)cnt = contours[0]# 2.寻找凸包，得到凸包的角点hull = cv2.convexHull(cnt)# 3.绘制凸包image = cv2.cvtColor(image, cv2.COLOR_GRAY2BGR)cv2.polylines(image, [hull], True, (0, 255, 0), 2) 其中函数cv2.convexHull()有个可选参数returnPoints，默认是True，代表返回角点的x/y坐标；如果为False的话，表示返回轮廓中是凸包角点的索引，比如说： 1234print(hull[0]) # [[362 184]]（坐标）hull2 = cv2.convexHull(cnt, returnPoints=False)print(hull2[0]) # [510]（cnt中的索引）print(cnt[510]) # [[362 184]] 当使用cv2.convexityDefects()计算凸包缺陷时，returnPoints需为False，详情可参考：Convexity Defects 另外可以用下面的语句来判断轮廓是否是凸形的： 1print(cv2.isContourConvex(hull)) # True 点到轮廓距离cv2.pointPolygonTest()函数计算点到轮廓的最短距离（也就是垂线），又称多边形测试： 1dist = cv2.pointPolygonTest(cnt, (100, 100), True) # -3.53 其中参数3为True时表示计算距离值：点在轮廓外面值为负，点在轮廓上值为0，点在轮廓里面值为正；参数3为False时，只返回-1/0/1表示点相对轮廓的位置，不计算距离。 更多轮廓特征，如当量直径、平均强度等，我目前也没用到过，以后用到再写吧，感兴趣的可以参看：Contour Properties、Contours Hierarchy 引用 本节源码 Convexity Defects Contour Properties Contours Hierarchy","categories":[{"name":"机器视觉","slug":"机器视觉","permalink":"http://ex2tron.coding.me/categories/机器视觉/"}],"tags":[{"name":"OpenCV","slug":"OpenCV","permalink":"http://ex2tron.coding.me/tags/OpenCV/"},{"name":"Python","slug":"Python","permalink":"http://ex2tron.coding.me/tags/Python/"},{"name":"图像处理","slug":"图像处理","permalink":"http://ex2tron.coding.me/tags/图像处理/"},{"name":"凸包","slug":"凸包","permalink":"http://ex2tron.coding.me/tags/凸包/"}]},{"title":"Python+OpenCV教程番外篇9：轮廓层级","slug":"Python-OpenCV教程番外篇9：轮廓层级","date":"2017-12-20T04:41:11.000Z","updated":"2018-01-19T06:08:20.571Z","comments":true,"path":"2017/12/20/Python-OpenCV教程番外篇9：轮廓层级/","link":"","permalink":"http://ex2tron.coding.me/2017/12/20/Python-OpenCV教程番外篇9：轮廓层级/","excerpt":"了解轮廓间的层级关系。","text":"了解轮廓间的层级关系。图片等可到源码处下载。 前面我们使用cv2.findContours()寻找轮廓时，参数3表示轮廓的寻找方式(RetrievalModes)，当时我们传入的是cv2.RETR_TREE，它表示什么意思呢？另外，函数返回值hierarchy有什么用途呢？下面我们就来回答这两个问题。 理解轮廓层级很多情况下，图像中的形状之间是有关联的，比如说下图： 图中总共有8条轮廓，2和2a分别表示外层和里层的轮廓，3和3a也是一样。从图中看得出来： 轮廓0/1/2是最外层的轮廓，我们可以说它们处于同一轮廓等级：0级 轮廓2a是轮廓2的子轮廓，反过来说2是2a的父轮廓，轮廓2a算一个等级：1级 同样3是2a的子轮廓，轮廓3处于一个等级：2级 类似的，3a是3的子轮廓，等等………… 这里面OpenCV关注的就是两个概念：同一轮廓等级和轮廓间的子属关系。 OpenCV中轮廓等级的表示如果我们打印出cv2.findContours()函数的返回值hierarchy，会发现它是一个包含4个值的数组：[Next, Previous, First Child, Parent] Next：与当前轮廓处于同一层级的下一条轮廓 举例来说，前面图中跟0处于同一层级的下一条轮廓是1，所以Next=1；同理，对轮廓1来说，Next=2；那么对于轮廓2呢？没有与它同一层级的下一条轮廓了，此时Next=-1。 Previous：与当前轮廓处于同一层级的上一条轮廓 跟前面一样，对于轮廓1来说，Previous=0；对于轮廓2，Previous=1；对于轮廓1，没有上一条轮廓了，所以Previous=-1。 First Child：当前轮廓的第一条子轮廓 比如对于轮廓2，第一条子轮廓就是轮廓2a，所以First Child=2a；对轮廓3a，First Child=4。 Parent：当前轮廓的父轮廓 比如2a的父轮廓是2，Parent=2；轮廓2没有父轮廓，所以Parent=-1。 下面我们通过代码验证一下： 1234567891011# 1.读入图片img = cv2.imread('hierarchy.jpg')img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)_, thresh = cv2.threshold(img_gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)# 2.寻找轮廓image, contours, hierarchy = cv2.findContours(thresh, cv2.RETR_TREE, 2)# 3.绘制轮廓print(len(contours),hierarchy) # 8条cv2.drawContours(img, contours, -1, (0, 0, 255), 2) 经验之谈：OpenCV中找到的轮廓序号跟前面讲的不同噢，如下图： 现在既然我们了解了层级的概念，那么类似cv2.RETR_TREE的轮廓寻找方式又是啥意思呢？ 轮廓寻找方式OpenCV中有四种轮廓寻找方式RetrievalModes，下面分别来看下： 1. RETR_LIST这是最简单的一种寻找方式，它不建立轮廓间的子属关系，也就是所有轮廓都属于同一层级。这样的话，hierarchy中的后两个值[First Child, Parent]都为-1。比如同样的图，我们使用RETR_LIST来寻找轮廓： 1234567891011_, _, hierarchy = cv2.findContours(thresh, cv2.RETR_LIST, 2)print(hierarchy)# 结果如下[[[ 1 -1 -1 -1] [ 2 0 -1 -1] [ 3 1 -1 -1] [ 4 2 -1 -1] [ 5 3 -1 -1] [ 6 4 -1 -1] [ 7 5 -1 -1] [-1 6 -1 -1]]] 因为没有从属关系，所以轮廓0的下一条是1，1的下一条是2…… 经验之谈：如果你不需要轮廓层级信息的话，cv2.RETR_LIST更推荐使用，因为性能更好 2. RETR_TREEcv2.RETR_TREE就是之前我们一直在使用的方式，它会完整建立轮廓的层级从属关系，前面已经详细说明过了。 3. RETR_EXTERNAL这种方式只寻找最高层级的轮廓，也就是它只会找到前面我们所说的3条0级轮廓： 1234567_, contours, hierarchy = cv2.findContours(thresh, cv2.RETR_EXTERNAL, 2)print(len(contours), hierarchy, sep='\\n')# 结果如下3[[[ 1 -1 -1 -1] [ 2 0 -1 -1] [-1 1 -1 -1]]] 4. RETR_CCOMP相比之下cv2.RETR_CCOMP比较难理解，但其实也很简单：它把所有的轮廓只分为2个层级，不是外层的就是里层的。结合代码和图片，我们来理解下： 1234567891011_, contours, hierarchy = cv2.findContours(thresh, cv2.RETR_CCOMP, 2)print(hierarchy)# 结果如下[[[ 1 -1 -1 -1] [ 2 0 -1 -1] [ 4 1 3 -1] [-1 -1 -1 2] [ 6 2 5 -1] [-1 -1 -1 4] [ 7 4 -1 -1] [-1 6 -1 -1]]] 注意：使用这个参数找到的轮廓序号与之前不同 图中括号里面1代表外层轮廓，2代表里层轮廓。比如说对于轮廓2，Next就是4，Previous是1，它有里层的轮廓3，所以First Child=3，但因为只有两个层级，它本身就是外层轮廓，所以Parent=-1。大家可以针对其他的轮廓自己验证一下。 练习 如下图，找到3个圆环的内环，然后填充成(180,215,215)这种颜色： 引用 本节源码 Contours Hierarchy","categories":[{"name":"机器视觉","slug":"机器视觉","permalink":"http://ex2tron.coding.me/categories/机器视觉/"}],"tags":[{"name":"OpenCV","slug":"OpenCV","permalink":"http://ex2tron.coding.me/tags/OpenCV/"},{"name":"Python","slug":"Python","permalink":"http://ex2tron.coding.me/tags/Python/"},{"name":"图像处理","slug":"图像处理","permalink":"http://ex2tron.coding.me/tags/图像处理/"},{"name":"轮廓层级","slug":"轮廓层级","permalink":"http://ex2tron.coding.me/tags/轮廓层级/"}]},{"title":"Python+OpenCV教程13：轮廓","slug":"Python-OpenCV教程13：轮廓","date":"2017-12-20T01:44:23.000Z","updated":"2018-01-22T08:19:33.291Z","comments":true,"path":"2017/12/20/Python-OpenCV教程13：轮廓/","link":"","permalink":"http://ex2tron.coding.me/2017/12/20/Python-OpenCV教程13：轮廓/","excerpt":"学习如何寻找并绘制轮廓。","text":"学习如何寻找并绘制轮廓。图片等可到源码处下载。 目标 了解轮廓概念 寻找并绘制轮廓 OpenCV函数：cv2.findContours(), cv2.drawContours() 教程啥叫轮廓轮廓是一系列相连的点组成的曲线，代表了物体的基本外形。 谈起轮廓不免想到边缘，它们确实很像。简单的说，轮廓是连续的，边缘并不全都连续（下图）。其实边缘主要是作为图像的特征使用，比如可以用边缘特征可以区分脸和手，而轮廓主要用来分析物体的形态，比如物体的周长和面积等，可以说边缘包括轮廓。 寻找轮廓的操作一般用于二值化图，所以通常会使用阈值分割或Canny边缘检测先得到二值图。 经验之谈：寻找轮廓是针对白色物体的，一定要保证物体是白色，而背景是黑色，*不然很多人在寻找轮廓时会找到图片最外面的一个框 寻找轮廓使用cv2.findContours()寻找轮廓： 1234567img = cv2.imread('handwriting.jpg')img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)ret, thresh = cv2.threshold(img_gray, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)# 寻找二值化图中的轮廓image, contours, hierarchy = cv2.findContours( thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)print(len(contours)) # 结果应该为2 参数2：轮廓的查找方式，一般使用cv2.RETR_TREE，表示提取所有的轮廓并建立轮廓间的层级。更多请参考：RetrievalModes 参数3：轮廓的近似方法。比如对于一条直线，我们可以存储该直线的所有像素点，也可以只存储起点和终点。使用cv2.CHAIN_APPROX_SIMPLE就表示用尽可能少的像素点表示轮廓。更多请参考：ContourApproximationModes 简便起见，这两个参数也可以直接用真值3和2表示。 函数有3个返回值，image还是原来的二值化图片，hierarchy是轮廓间的层级关系（番外篇：轮廓层级），这两个暂时不用理会。我们主要看contours，它就是找到的轮廓了，以数组形式存储，记录了每条轮廓的所有像素点的坐标(x,y)。 绘制轮廓轮廓找出来后，为了方便观看，可以像前面图中那样用红色画出来：cv2.drawContours() 1cv2.drawContours(img, contours, -1, (0, 0, 255), 2) 其中参数2就是得到的contours，参数3表示要绘制哪一条轮廓，-1表示绘制所有轮廓，参数4是颜色（B/G/R通道，所以(0,0,255)表示红色），参数5是线宽，之前在绘制图形中介绍过。 经验之谈：很多人画图时明明用了彩色，但没有效果，请检查你是在哪个图上画，画在灰度图和二值图上显然是没有彩色的(⊙o⊙) 一般情况下，我们会首先获得要操作的轮廓，再进行轮廓绘制及分析： 12cnt = contours[1]cv2.drawContours(img, [cnt], 0, (0, 0, 255), 2) 小结 轮廓特征非常有用，使用cv2.findContours()寻找物体的轮廓，cv2.drawContours()绘制轮廓 引用 本节源码 Contours : Getting Started","categories":[{"name":"机器视觉","slug":"机器视觉","permalink":"http://ex2tron.coding.me/categories/机器视觉/"}],"tags":[{"name":"OpenCV","slug":"OpenCV","permalink":"http://ex2tron.coding.me/tags/OpenCV/"},{"name":"Python","slug":"Python","permalink":"http://ex2tron.coding.me/tags/Python/"},{"name":"图像处理","slug":"图像处理","permalink":"http://ex2tron.coding.me/tags/图像处理/"},{"name":"轮廓","slug":"轮廓","permalink":"http://ex2tron.coding.me/tags/轮廓/"}]},{"title":"Python+OpenCV教程12：腐蚀与膨胀","slug":"Python-OpenCV教程12：腐蚀与膨胀","date":"2017-12-19T12:52:23.000Z","updated":"2018-01-22T08:17:22.194Z","comments":true,"path":"2017/12/19/Python-OpenCV教程12：腐蚀与膨胀/","link":"","permalink":"http://ex2tron.coding.me/2017/12/19/Python-OpenCV教程12：腐蚀与膨胀/","excerpt":"学习常用形态学操作：腐蚀膨胀，开运算和闭运算。","text":"学习常用形态学操作：腐蚀膨胀，开运算和闭运算。图片等可到源码处下载。 目标 了解形态学操作的概念 学习膨胀、腐蚀、开运算和闭运算等形态学操作 OpenCV函数：cv2.erode(), cv2.dilate(), cv2.morphologyEx() 教程啥叫形态学操作形态学操作其实就是改变物体的形状，比如腐蚀就是”变瘦”，膨胀就是”变胖”，看下图就明白了： 形态学操作一般作用于二值化图，来连接相邻的元素或分离成独立的元素。腐蚀和膨胀是针对图片中的白色部分！ 腐蚀腐蚀的效果是把图片”变瘦”，其原理是在原图的小区域内取局部最小值。因为是二值化图，只有0和255，所以小区域内有一个是0该像素点就为0： 这样原图中边缘地方就会变成0，达到了瘦身目的（小胖福利(●ˇ∀ˇ●)） OpenCV中用cv2.erode()函数进行腐蚀，只需要指定核的大小就行： 123img = cv2.imread('j.bmp', 0)kernel = np.ones((5, 5), np.uint8)erosion = cv2.erode(img, kernel) # 腐蚀 这个核也叫结构元素，因为形态学操作其实也是应用卷积来实现的。结构元素可以是矩形/椭圆/十字形，可以用cv2.getStructuringElement()来生成不同形状的结构元素，比如： 123kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (5, 5)) # 矩形结构kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 5)) # 椭圆结构kernel = cv2.getStructuringElement(cv2.MORPH_CROSS, (5, 5)) # 十字形结构 膨胀膨胀与腐蚀相反，取的是局部最大值，效果是把图片”变胖”： 1dilation = cv2.dilate(img, kernel) # 膨胀 开/闭运算先腐蚀后膨胀叫开运算（因为先腐蚀会分开物体，这样容易记住），其作用是：分离物体，消除小区域。这类形态学操作用cv2.morphologyEx()函数实现： 1234kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (5, 5)) # 定义结构元素img = cv2.imread('j_noise_out.bmp', 0)opening = cv2.morphologyEx(img, cv2.MORPH_OPEN, kernel) # 开运算 闭运算则相反：先膨胀后腐蚀（先膨胀会使白色的部分扩张，以至于消除/“闭合”物体里面的小黑洞，所以叫闭运算） 12img = cv2.imread('j_noise_in.bmp', 0)closing = cv2.morphologyEx(img, cv2.MORPH_CLOSE, kernel) # 闭运算 经验之谈：很多人对开闭运算的作用不是很清楚（好吧，其实是比较容易混◑﹏◐），但看上图↑，不用怕：如果我们的目标物体外面有很多无关的小区域，就用开运算去除掉；如果物体内部有很多小黑洞，就用闭运算填充掉 接下来的3种形态学操作并不常用，大家有兴趣可以看看（因为较短，没有做成番外篇）： 其他形态学操作 形态学梯度：膨胀图减去腐蚀图，dilation - erosion，这样会得到物体的轮廓： 12img = cv2.imread('school.bmp', 0)gradient = cv2.morphologyEx(img, cv2.MORPH_GRADIENT, kernel) 顶帽：原图减去开运算后的图：src - opening 1tophat = cv2.morphologyEx(img, cv2.MORPH_TOPHAT, kernel) 黑帽：闭运算后的图减去原图：closing - src 1blackhat = cv2.morphologyEx(img, cv2.MORPH_BLACKHAT, kernel) 小结 形态学操作就是改变物体的形状，如腐蚀使物体”变瘦”，膨胀使物体”变胖” 先腐蚀后膨胀会分离物体，所以叫开运算，常用来去除小区域物体 先膨胀后腐蚀会消除物体内的小洞，所以叫闭运算。开/闭理解了之后很容易记忆噢(⊙o⊙) 引用 本节源码 Morphological Operations Computer Vision: Algorithms and Applications","categories":[{"name":"机器视觉","slug":"机器视觉","permalink":"http://ex2tron.coding.me/categories/机器视觉/"}],"tags":[{"name":"OpenCV","slug":"OpenCV","permalink":"http://ex2tron.coding.me/tags/OpenCV/"},{"name":"Python","slug":"Python","permalink":"http://ex2tron.coding.me/tags/Python/"},{"name":"图像处理","slug":"图像处理","permalink":"http://ex2tron.coding.me/tags/图像处理/"},{"name":"腐蚀","slug":"腐蚀","permalink":"http://ex2tron.coding.me/tags/腐蚀/"},{"name":"膨胀","slug":"膨胀","permalink":"http://ex2tron.coding.me/tags/膨胀/"},{"name":"形态学","slug":"形态学","permalink":"http://ex2tron.coding.me/tags/形态学/"}]},{"title":"Python+OpenCV教程11：边缘检测","slug":"Python-OpenCV教程11：边缘检测","date":"2017-12-18T09:11:48.000Z","updated":"2018-01-05T04:39:30.831Z","comments":true,"path":"2017/12/18/Python-OpenCV教程11：边缘检测/","link":"","permalink":"http://ex2tron.coding.me/2017/12/18/Python-OpenCV教程11：边缘检测/","excerpt":"学习使用Canny获取图像的边缘。","text":"学习使用Canny获取图像的边缘。图片等可到源码处下载。 目标 Canny边缘检测的简单概念 OpenCV函数：cv2.Canny() 教程废话不多说，直接上12img = cv2.imread('handwriting.jpg', 0)edges = cv2.Canny(img, 30, 70) # canny边缘检测 cv2.Canny()进行边缘检测，参数2、3表示最低、高阈值，看完后面的理论就理解了。 经验之谈：之前我们用低通滤波的方式模糊了图片，那如果反过来，想得到物体的边缘，就需要用到高通滤波。如果你要理解接下来要说的Canny检测原理，请先阅读：番外篇：图像梯度 Canny边缘检测Canny边缘检测方法常被誉为边缘检测的最优方法，具体步骤如下： 1，使用5×5高斯滤波消除噪声： 边缘检测本身属于锐化操作，对噪点比较敏感，所以需要进行平滑处理。 2，计算图像梯度的方向： 首先使用Sobel算子计算梯度Gx和Gy，然后算出梯度的方向：θ=arctan(Gy/Gx)，保留这四个方向的梯度：0°/45°/90°/135°，有什么用呢？我们接着看。 3，取局部极大值： 梯度其实已经表示了轮廓，为了进一步筛选，可以在上面的四个角度方向上再取局部极大值： 比如，A点在45°方向上大于B/C点，那就保留它，把B/C设置为0。 4，滞后阈值： 经过前面三步，就只剩下0和可能的边缘像素值了，为了最终确定下来，需要设定高低阈值： 像素点的值大于最高阈值，那肯定是边缘（上图A） 同理像素值小于最低阈值，那肯定不是边缘 像素值介于两者之间，如果与高于最高阈值的点连接，也算边缘，所以上图中C算，B不算 Canny推荐的高低阈值比在2:1到3:1之间。 先阈值分割其实很多情况下，阈值分割后再检测边缘，效果会更好： 12_, thresh = cv2.threshold(img, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)edges = cv2.Canny(thresh, 30, 70) 代码中我用了番外篇：Otsu阈值法中的自动阈值分割，如果你不太了解，大可以使用传统的方法，不过如果是下面这种图片，推荐用Otsu阈值法。另外Python中某个值不用的话，就写个下划线’_’。 练习 （选做）如果你不太理解高低阈值的效果，创建两个滑动条来调节它们的值看看： 小结 Canny是用的最多的边缘检测算法，用cv2.Canny()实现 引用 本节源码 Canny Edge Detection Canny 边缘检测","categories":[{"name":"机器视觉","slug":"机器视觉","permalink":"http://ex2tron.coding.me/categories/机器视觉/"}],"tags":[{"name":"OpenCV","slug":"OpenCV","permalink":"http://ex2tron.coding.me/tags/OpenCV/"},{"name":"Python","slug":"Python","permalink":"http://ex2tron.coding.me/tags/Python/"},{"name":"图像处理","slug":"图像处理","permalink":"http://ex2tron.coding.me/tags/图像处理/"},{"name":"边缘","slug":"边缘","permalink":"http://ex2tron.coding.me/tags/边缘/"},{"name":"Canny","slug":"Canny","permalink":"http://ex2tron.coding.me/tags/Canny/"}]},{"title":"Python+OpenCV教程番外篇8：图像梯度","slug":"Python-OpenCV教程番外篇8：图像梯度","date":"2017-12-18T02:51:43.000Z","updated":"2018-01-19T05:36:11.748Z","comments":true,"path":"2017/12/18/Python-OpenCV教程番外篇8：图像梯度/","link":"","permalink":"http://ex2tron.coding.me/2017/12/18/Python-OpenCV教程番外篇8：图像梯度/","excerpt":"了解图像梯度和边缘检测的相关概念。","text":"了解图像梯度和边缘检测的相关概念。图片等可到源码处下载。 还记得前面平滑图像中提到的滤波与模糊的区别吗？我们说低通滤波器是模糊，高通滤波器是锐化，这节我们就来看看高通滤波器。 图像梯度如果你还记得高数中用一阶导数来求极值的话，就很容易理解了：把图片想象成连续函数，因为边缘部分的像素值是与旁边像素明显有区别的，所以对图片局部求极值，就可以得到整幅图片的边缘信息了。不过图片是二维的离散函数，导数就变成了差分，这个差分就称为图像的梯度。 当然，大部分人应该是早忘记高数了(￣▽￣)”，所以看不懂的话，就把上面的解释划掉，我们重新从卷积的角度来看看。 垂直边缘提取滤波是应用卷积来实现的，卷积的关键就是卷积核，我们来考察下面这个卷积核： $$k1 = \\left[ \\begin{matrix} -1 &amp; 0 &amp; 1 \\newline -2 &amp; 0 &amp; 2 \\newline -1 &amp; 0 &amp; 1 \\end{matrix} \\right]$$ 这个核是用来提取图片中的垂直边缘的，怎么做到的呢？看下图： 当前列左右两侧的元素进行差分，由于边缘的值明显小于（或大于）周边像素，所以边缘的差分结果会明显不同，这样就提取出了垂直边缘。同理，把上面那个矩阵转置一下，就是提取水平边缘。这种差分操作就叫图像的梯度计算： $$k2 = \\left[ \\begin{matrix} -1 &amp; -2 &amp; -1 \\newline 0 &amp; 0 &amp; 0 \\newline 1 &amp; 2 &amp; 1 \\end{matrix} \\right]$$ 还记得滤波函数cv2.filter2D()吗？（番外篇：卷积基础）我们来手动实现上面的功能： 123456789101112img = cv2.imread('sudoku.jpg', 0)# 自己进行垂直边缘提取kernel = np.array([[-1, 0, 1], [-2, 0, 2], [-1, 0, 1]], dtype=np.float32)dst_v = cv2.filter2D(img, -1, kernel)# 自己进行水平边缘提取dst_h = cv2.filter2D(img, -1, kernel.T)# 横向并排对比显示cv2.imshow('edge', np.hstack((img, dst_v, dst_h)))cv2.waitKey(0) Sobel算子上面的这种差分方法就叫Sobel算子，它先在垂直方向计算梯度Gx=k1×src，再在水平方向计算梯度Gy=k2×src，最后求出总梯度：\\(G=\\sqrt{Gx^2+Gy^2}\\) 我们可以把前面的代码用Sobel算子更简单地实现： 12sobelx = cv2.Sobel(img, -1, 1, 0, ksize=3) # 只计算x方向sobely = cv2.Sobel(img, -1, 0, 1, ksize=3) # 只计算y方向 经验之谈：很多人疑问，Sobel算子的卷积核这几个值是怎么来的呢？事实上，并没有规定，你可以用你自己的。当然，3×3下另外一个卷积核相比Sobel更好用，叫Scharr算子，大家可以了解下： $$K = \\left[ \\begin{matrix} -3 &amp; 0 &amp; 3 \\newline -10 &amp; 0 &amp; 10 \\newline -3 &amp; 0 &amp; 3 \\end{matrix} \\right]$$ Laplacian算子好开心，又要扯到高数的东西辣(￣_,￣ )高数中用一阶导数求极值，在这些极值的地方，二阶导数为0，所以可以通过求二阶导计算梯度：\\(dst=\\frac{\\partial^2 f}{\\partial x^2}+\\frac{\\partial^2 f}{\\partial y^2}\\) 这就是Laplacian算子，了解了之后，最关键的是要会用： 1laplacian = cv2.Laplacian(img, -1) # 使用Laplacian算子 练习 （选做）同志们有空补补高数姿势（知识）呗！(✿◕‿◕✿) 引用 本节源码 Image Gradients Sobel导数","categories":[{"name":"机器视觉","slug":"机器视觉","permalink":"http://ex2tron.coding.me/categories/机器视觉/"}],"tags":[{"name":"OpenCV","slug":"OpenCV","permalink":"http://ex2tron.coding.me/tags/OpenCV/"},{"name":"Python","slug":"Python","permalink":"http://ex2tron.coding.me/tags/Python/"},{"name":"图像处理","slug":"图像处理","permalink":"http://ex2tron.coding.me/tags/图像处理/"},{"name":"梯度","slug":"梯度","permalink":"http://ex2tron.coding.me/tags/梯度/"},{"name":"Sobel","slug":"Sobel","permalink":"http://ex2tron.coding.me/tags/Sobel/"}]},{"title":"Python+OpenCV教程10：平滑图像","slug":"Python-OpenCV教程10：平滑图像","date":"2017-12-15T01:44:24.000Z","updated":"2018-01-22T08:16:47.654Z","comments":true,"path":"2017/12/15/Python-OpenCV教程10：平滑图像/","link":"","permalink":"http://ex2tron.coding.me/2017/12/15/Python-OpenCV教程10：平滑图像/","excerpt":"学习模糊/平滑图像，消除噪点。","text":"学习模糊/平滑图像，消除噪点。图片等可到源码处下载。 目标 模糊/平滑图片来消除图片噪声 OpenCV函数：cv2.blur(), cv2.GaussianBlur(), cv2.medianBlur(), cv2.bilateralFilter() 教程滤波与模糊推荐大家先阅读：番外篇：卷积基础(图片边框)，有助于理解卷积和滤波的概念。 关于滤波和模糊，很多人分不清，我来给大家理理（虽说如此，我后面也会混着用,,ԾㅂԾ,,）： 它们都属于卷积，不同滤波方法之间只是卷积核不同（对线性滤波而言） 低通滤波器是模糊，高通滤波器是锐化 低通滤波器就是允许低频信号通过，在图像中边缘和噪点都相当于高频部分，所以低通滤波器用于去除噪点、平滑和模糊图像。高通滤波器则反之，用来增强图像边缘，进行锐化处理。 常见噪声有椒盐噪声和高斯噪声，椒盐噪声可以理解为斑点，随机出现在图像中的黑点或白点；高斯噪声可以理解为拍摄图片时由于光照等原因造成的噪声；这样解释并不准确，只要能简单分辨即可 均值滤波均值滤波是一种最简单的滤波处理，它取的是卷积核区域内元素的均值，用cv2.blur()实现，如3×3的卷积核： $$ kernel = \\frac{1}{9}\\left[ \\begin{matrix} 1 &amp; 1 &amp; 1 \\newline 1 &amp; 1 &amp; 1 \\newline 1 &amp; 1 &amp; 1 \\end{matrix} \\right]$$ 12img = cv2.imread('lena.jpg')blur = cv2.blur(img, (3, 3)) # 均值模糊 所有的滤波函数都有一个可选参数borderType，还记得吗？这个参数就是我们在番外篇：卷积基础(图片边框)中所说的边框填充方式。 方框滤波方框滤波跟均值滤波很像，如下面的公式。用cv2.boxFilter()函数实现，事实上，当可选参数normalize为True的时候，方框滤波就是均值滤波，如3×3的核，a就等于1/9；normalize为False的时候，a=1，相当于求区域内的像素和。 $$ k = a\\left[ \\begin{matrix} 1 &amp; 1 &amp; 1 \\newline 1 &amp; 1 &amp; 1 \\newline 1 &amp; 1 &amp; 1 \\end{matrix} \\right]$$ 12# 前面的均值滤波也可以用方框滤波实现：normalize=Trueblur = cv2.boxFilter(img, -1, (3, 3), normalize=True) 高斯滤波前面两种滤波方式，卷积核内的每个值都一样，相当于图像区域中每个像素的权重也就一样。高斯滤波的卷积核权重并不相同，中间像素点权重最高，越远离中心的像素权重越小。（其原理是一个2维高斯函数，可以参考：Gaussian Filter） 高斯滤波相比均值滤波效率要慢，但可以有效消除高斯噪声，能保留更多的图像细节，所以经常被称为最有用的滤波器。 1234img = cv2.imread('gaussian_noise.bmp')# 均值滤波vs高斯滤波blur = cv2.blur(img, (5, 5)) # 均值滤波gaussian = cv2.GaussianBlur(img, (5, 5), 1) # 高斯滤波 均值滤波与高斯滤波的对比结果如下（均值滤波丢失的细节更多）： GaussianBlur()中参数3是σx，值越大，模糊效果越明显，0代表默认值0.8：getGaussianKernel() 中值滤波中值又叫中位数，是所有值排序后取中间的值。中值滤波就是用区域内的中值来代替本像素值，所以那种孤立的斑点，如0或255很容易消除掉，适用于去除椒盐噪声和斑点噪声。中值是一种非线性操作，效率相比前面几种线性滤波要慢。 比如下面这张斑点噪声图，用中值滤波显然更好： 1234img = cv2.imread('salt_noise.bmp', 0)# 均值滤波vs中值滤波blur = cv2.blur(img, (5, 5)) # 均值滤波median = cv2.medianBlur(img, 5) # 中值滤波 双边滤波模糊操作基本都会损失掉图像细节信息，尤其前面介绍的线性滤波器，图像的边缘信息很难保留下来。然而，边缘edge信息是图像中很重要的一个特征，所以这才有了双边滤波。用cv2.bilateralFilter()函数实现： 1234img = cv2.imread('lena.jpg')# 双边滤波vs高斯滤波gau = cv2.GaussianBlur(img, (5, 5), 0) # 高斯滤波blur = cv2.bilateralFilter(img, 9, 75, 75) # 双边滤波 可以看到，双边滤波明显保留了更多边缘信息。 小结 在不知道用什么滤波器好的时候，优先高斯滤波cv2.GaussianBlur()，然后均值滤波cv2.blur() 斑点和椒盐噪声优先使用中值滤波cv2.medianBlur() 要去除噪点的同时尽可能保留更多的边缘信息，使用双边滤波cv2.bilateralFilter() 线性滤波方式：均值滤波、方框滤波、高斯滤波（速度相对快） 非线性滤波方式：中值滤波、双边滤波（速度相对慢） 引用 本节源码 Smoothing Images 图像平滑处理","categories":[{"name":"机器视觉","slug":"机器视觉","permalink":"http://ex2tron.coding.me/categories/机器视觉/"}],"tags":[{"name":"OpenCV","slug":"OpenCV","permalink":"http://ex2tron.coding.me/tags/OpenCV/"},{"name":"Python","slug":"Python","permalink":"http://ex2tron.coding.me/tags/Python/"},{"name":"图像处理","slug":"图像处理","permalink":"http://ex2tron.coding.me/tags/图像处理/"},{"name":"模糊","slug":"模糊","permalink":"http://ex2tron.coding.me/tags/模糊/"}]},{"title":"Python+OpenCV教程番外篇7：卷积基础(图片边框)","slug":"Python-OpenCV教程番外篇7：卷积基础-图片边框","date":"2017-12-14T08:27:45.000Z","updated":"2018-01-19T05:35:53.894Z","comments":true,"path":"2017/12/14/Python-OpenCV教程番外篇7：卷积基础-图片边框/","link":"","permalink":"http://ex2tron.coding.me/2017/12/14/Python-OpenCV教程番外篇7：卷积基础-图片边框/","excerpt":"了解卷积/滤波的基础知识，给图片添加边框。","text":"了解卷积/滤波的基础知识，给图片添加边框。如果你已了解相关理论，请直接跳到添加边框部分。 卷积的概念其实很好理解，下面我就用图文给大家做个最简单的解释，绝对轻松加愉快的辣o(￣▽￣)o 卷积什么是二维卷积呢？看下面一张图就一目了然： 卷积就是循环对图像跟一个核逐个元素相乘再求和得到另外一副图像的操作，比如结果图中第一个元素5是怎么算的呢？原图中3×3的区域与3×3的核逐个元素相乘再相加：1×1 + 2×0 + 1×0 + 0×0 + 1×0 + 1×0 + 3×0 + 0×0 + 2×2 = 5。算完之后，整个框再往右移一步继续计算，横向计算完后，再往下移一步继续计算……网上有一副很经典的动态图，方便我们理解卷积： padding不难发现，前面我们用3×3的核对一副6×6的图像进行卷积，得到的是4×4的图，图片缩小了！那怎么办呢？我们可以把原图扩充一圈，再卷积，这个操作叫padding。 事实上，原图为n×n，卷积核为f×f，最终结果图大小为(n-f+1) × (n-f+1) 那么扩展的这一层应该填充什么值呢？OpenCV中有好几种填充方式，都使用cv2.copyMakeBorder()函数实现，一起来看看。 添加边框cv2.copyMakeBorder()用来给图片添加边框，它有下面几个参数： src：要处理的原图 top, bottom, left, right：上下左右要扩展的像素数 borderType：边框类型，这个就是需要关注的填充方式，详情请参考：BorderTypes 其中默认方式和固定值方式最常用，我们详细说明一下： 固定值填充顾名思义，cv2.BORDER_CONSTANT这种方式就是边框都填充成一个固定的值，比如下面的程序都填充0： 123456img = cv2.imread('6_by_6.bmp', 0)print(img)# 固定值边框，统一都填充0也称为zero paddingcons = cv2.copyMakeBorder(img, 1, 1, 1, 1, cv2.BORDER_CONSTANT, value=0)print(cons) 默认边框类型默认边框cv2.BORDER_DEFAULT其实是取镜像对称的像素填充，比较拗口，一步步解释： 12default = cv2.copyMakeBorder(img, 1, 1, 1, 1, cv2.BORDER_DEFAULT)print(default) 首先进行上下填充，填充成与原图像边界对称的值，如下图： 同理再进行左右两边的填充，最后把四个顶点补充上就好了： 一般情况下默认方式更加合理，因为边界的像素值更加接近，当然应视场合而定 OpenCV进行卷积OpenCV中用cv2.filter2D()实现卷积操作，比如我们的核是下面这样（3×3区域像素的和除以10）： $$ M = \\frac{1}{10}\\left[ \\begin{matrix} 1 &amp; 1 &amp; 1 \\newline 1 &amp; 1 &amp; 1 \\newline 1 &amp; 1 &amp; 1 \\end{matrix} \\right] \\tag{3}$$ 12345img = cv2.imread('lena.jpg')# 定义卷积核kernel = np.ones((3, 3), np.float32) / 10# 卷积操作，-1表示通道数与原图相同dst = cv2.filter2D(img, -1, kernel) 可以看到这个核对图像进行了模糊处理，这是卷积的众多功能之一。当然卷积还有很多知识没有学到，后面我们再继续深入。 练习 尝试给”lena.jpg”添加几种不同的边框类型，对比下效果 引用 本节源码) Basic Operations on Images 图像卷积与滤波的一些知识点","categories":[{"name":"机器视觉","slug":"机器视觉","permalink":"http://ex2tron.coding.me/categories/机器视觉/"}],"tags":[{"name":"OpenCV","slug":"OpenCV","permalink":"http://ex2tron.coding.me/tags/OpenCV/"},{"name":"Python","slug":"Python","permalink":"http://ex2tron.coding.me/tags/Python/"},{"name":"图像处理","slug":"图像处理","permalink":"http://ex2tron.coding.me/tags/图像处理/"},{"name":"卷积","slug":"卷积","permalink":"http://ex2tron.coding.me/tags/卷积/"},{"name":"边框","slug":"边框","permalink":"http://ex2tron.coding.me/tags/边框/"}]},{"title":"Python+OpenCV教程","slug":"Python-OpenCV教程","date":"2017-12-12T15:04:43.021Z","updated":"2018-03-15T07:06:32.666Z","comments":true,"path":"2017/12/12/Python-OpenCV教程/","link":"","permalink":"http://ex2tron.coding.me/2017/12/12/Python-OpenCV教程/","excerpt":"图文版 | 简洁版","text":"图文版 | 简洁版 入门篇 1. 简介与安装 了解并安装OpenCV-Python番外篇1：代码性能优化 2. 基本元素-图片 载入图片，显示并保存番外篇2：Matplotlib显示图像 3. 打开摄像头 打开摄像头捕获图片，播放本地视频，保存视频番外篇3：滑动条 4. 图像基本操作 访问像素点，ROI感兴趣区域，多通道分离和合并 5. 颜色空间转换 颜色空间转换，追踪视频中特定颜色的物体 6. 阈值分割 阈值分割，二值化图像番外篇4：Otsu阈值法 7. 图像几何变换 旋转，平移，缩放图像，仿射变换和透视变换 8. 绘图功能 画直线，画圆/椭圆，画矩形和添加文字番外篇5：鼠标绘图 基础篇 9. 图像混合 图像的算数运算、按位运算，图像混合番外篇6：亮度与对比度 10. 平滑图像 卷积基础，滤波和图像模糊降噪番外篇7：卷积基础(图片边框) 11. 边缘检测 Canny边缘检测，Sobel算子番外篇8：图像梯度 12. 腐蚀与膨胀 形态学操作：腐蚀和膨胀，开运算和闭运算，顶帽和黑帽 13. 轮廓 寻找并绘制物体轮廓 番外篇9：轮廓层级 14. 轮廓特征 轮廓特征：面积，周长，最小外接矩和最小外接圆，几何形状匹配 番外篇10：凸包及更多轮廓特征 15. 直方图 了解，计算并绘制直方图，（自适应）直方图均衡化 16. 模板匹配 使用模板匹配在大图中找到小图 17. 霍夫变换 提取图像中的直线和圆","categories":[{"name":"机器视觉","slug":"机器视觉","permalink":"http://ex2tron.coding.me/categories/机器视觉/"}],"tags":[{"name":"OpenCV","slug":"OpenCV","permalink":"http://ex2tron.coding.me/tags/OpenCV/"},{"name":"Python","slug":"Python","permalink":"http://ex2tron.coding.me/tags/Python/"},{"name":"图像处理","slug":"图像处理","permalink":"http://ex2tron.coding.me/tags/图像处理/"}]},{"title":"Python+OpenCV教程9：图像混合","slug":"Python-OpenCV教程9：图像混合","date":"2017-12-10T06:13:10.000Z","updated":"2018-01-05T04:39:02.734Z","comments":true,"path":"2017/12/10/Python-OpenCV教程9：图像混合/","link":"","permalink":"http://ex2tron.coding.me/2017/12/10/Python-OpenCV教程9：图像混合/","excerpt":"学习图片间的数学运算，图像混合。","text":"学习图片间的数学运算，图像混合。图片等可到源码处下载。 目标 图片间的数学运算，如相加、按位运算等 OpenCV函数：cv2.add(), cv2.addWeighted(), cv2.bitwise_and() 教程首先，恭喜你已经完成了入门篇的学习噢，接下来我们学习一些OpenCV的基础内容，加油(ง •_•)ง 图片相加要叠加两张图片，可以用cv2.add()函数，相加两幅图片的形状（高度/宽度/通道数）必须相同。numpy中可以直接用res = img + img1相加，但这两者的结果并不相同： 1234x = np.uint8([250])y = np.uint8([10])print(cv2.add(x, y)) # 250+10 = 260 =&gt; 255print(x + y) # 250+10 = 260 % 256 = 4 如果是二值化图片（只有0和255），两者结果是一样的（用numpy的方式更简便一些）。 图像混合图像混合cv2.addWeighted()也是一种图片相加的操作，只不过两幅图片的权重不一样，γ相当于一个修正值： dst = α*img1 + β*img2 + γ 123img1 = cv2.imread('lena_small.jpg')img2 = cv2.imread('opencv-logo-white.png')res = cv2.addWeighted(img1, 0.6, img2, 0.4, 0) 经验之谈：α和β都等于1时，就相当于图片相加 按位操作按位操作包括按位与/或/非/异或操作，有什么用途呢？比如说我们要实现下图的效果： 如果将两幅图片直接相加会改变图片的颜色，如果用图像混合，则会改变图片的透明度，所以我们需要用按位操作。首先来了解一下掩膜（mask）的概念：掩膜是用一副二值化图片对另外一幅图片进行局部的遮挡，看下图就一目了然了： 所以我们的思路就是把原图中要放logo的区域抠出来，再把logo放进去就行了： 12345678910111213141516img1 = cv2.imread('lena.jpg')img2 = cv2.imread('opencv-logo-white.png')# 把logo放在左上角，所以我们只关心这一块区域rows, cols = img2.shape[:2]roi = img1[:rows, :cols]# 创建掩膜img2gray = cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY)ret, mask = cv2.threshold(img2gray, 10, 255, cv2.THRESH_BINARY)mask_inv = cv2.bitwise_not(mask)# 保留除logo外的背景img1_bg = cv2.bitwise_and(roi, roi, mask=mask_inv)dst = cv2.add(img1_bg, img2) # 进行融合img1[:rows, :cols] = dst # 融合后放在原图上 小结 cv2.add()用来叠加两幅图片，cv2.addWeighted()也是叠加两幅图片，但两幅图片的权重不一样 cv2.bitwise_and(), cv2.bitwise_not(), cv2.bitwise_or(), cv2.bitwise_xor()分别执行按位与/或/非/异或运算。掩膜就是用来对图片进行全局或局部的遮挡 引用 本节源码 掩膜 Arithmetic Operations on Images","categories":[{"name":"机器视觉","slug":"机器视觉","permalink":"http://ex2tron.coding.me/categories/机器视觉/"}],"tags":[{"name":"OpenCV","slug":"OpenCV","permalink":"http://ex2tron.coding.me/tags/OpenCV/"},{"name":"Python","slug":"Python","permalink":"http://ex2tron.coding.me/tags/Python/"},{"name":"图像处理","slug":"图像处理","permalink":"http://ex2tron.coding.me/tags/图像处理/"},{"name":"图像混合","slug":"图像混合","permalink":"http://ex2tron.coding.me/tags/图像混合/"}]},{"title":"Python+OpenCV教程番外篇6：亮度与对比度","slug":"Python-OpenCV教程番外篇6：亮度与对比度","date":"2017-12-10T06:05:10.000Z","updated":"2018-01-19T05:35:33.827Z","comments":true,"path":"2017/12/10/Python-OpenCV教程番外篇6：亮度与对比度/","link":"","permalink":"http://ex2tron.coding.me/2017/12/10/Python-OpenCV教程番外篇6：亮度与对比度/","excerpt":"学习如何调整图片的亮度和对比度。","text":"学习如何调整图片的亮度和对比度。图片等可到源码处下载。 亮度与对比度亮度调整是将图像像素的强度整体变大/变小，对比度调整指的是图像暗处的像素强度变低，亮出的变高，从而拓宽某个区域内的显示精度。 OpenCV中亮度和对比度应用这个公式来计算：g(x) = αf(x) + β，其中：α(&gt;0)、β常称为增益与偏置值，分别控制图片的对比度和亮度。 经验之谈：此处对α/β控制对比度和亮度有争议，具体请参考：OpenCV关于对比度和亮度的误解 1234567img = cv2.imread('lena.jpg')# 此处需注意，请参考后面的解释res = np.uint8(np.clip((1.5 * img + 10), 0, 255))tmp = np.hstack((img, res)) # 两张图片横向合并（便于对比显示）cv2.imshow('image', tmp)cv2.waitKey(0) 还记得图像混合那一节中numpy对数据溢出的取模处理吗？250+10 = 260 =&gt; 260%256=4，它并不适用于我们的图像处理，所以用np.clip()函数将数据限定：a&lt;0 =&gt; a=0, a&gt;255 =&gt; a=255 练习 创建两个滑动条分别调整对比度和亮度（对比度范围：0~0.3，亮度：0~100）。提示：因为滑动条没有小数，所以可以设置为0~300，然后乘以0.01 亮度/对比度用C++实现也很有趣，推荐阅读：OpenCV改变图像亮度和对比度以及优化 引用 本节源码 numpy.clip() OpenCV关于对比度和亮度的误解 OpenCV改变图像亮度和对比度以及优化 Mat::convertTo","categories":[{"name":"机器视觉","slug":"机器视觉","permalink":"http://ex2tron.coding.me/categories/机器视觉/"}],"tags":[{"name":"OpenCV","slug":"OpenCV","permalink":"http://ex2tron.coding.me/tags/OpenCV/"},{"name":"Python","slug":"Python","permalink":"http://ex2tron.coding.me/tags/Python/"},{"name":"图像处理","slug":"图像处理","permalink":"http://ex2tron.coding.me/tags/图像处理/"},{"name":"亮度","slug":"亮度","permalink":"http://ex2tron.coding.me/tags/亮度/"},{"name":"对比度","slug":"对比度","permalink":"http://ex2tron.coding.me/tags/对比度/"}]},{"title":"Python+OpenCV教程番外篇5：鼠标绘图","slug":"Python-OpenCV教程番外篇5：鼠标绘图","date":"2017-12-09T09:28:34.000Z","updated":"2018-01-19T05:35:16.056Z","comments":true,"path":"2017/12/09/Python-OpenCV教程番外篇5：鼠标绘图/","link":"","permalink":"http://ex2tron.coding.me/2017/12/09/Python-OpenCV教程番外篇5：鼠标绘图/","excerpt":"学习如何用鼠标实时绘图。","text":"学习如何用鼠标实时绘图。图片等可到源码处下载。 目标 捕获鼠标事件 OpenCV函数：cv2.setMouseCallback() 教程知道鼠标在哪儿OpenCV中，我们需要创建一个鼠标的回调函数来知道鼠标当前的位置，当前的事件如左键按下、左键释放或是右键单击等等，然后执行相应的功能。 使用cv2.setMouseCallback()来创建鼠标的回调函数，比如我们在左键单击的时候，打印出当前鼠标的位置： 12345678910111213141516171819import cv2import numpy as np# 鼠标的回调函数def mouse_event(event, x, y, flags, param): # 通过event判断具体是什么事件，这里是左键按下 if event == cv2.EVENT_LBUTTONDOWN: print((x, y))img = np.zeros((512, 512, 3), np.uint8)cv2.namedWindow('image')# 定义鼠标的回调函数cv2.setMouseCallback('image', mouse_event)while(True): cv2.imshow('image', img) # 按下ESC键退出 if cv2.waitKey(20) == 27: break 上面的代码先定义鼠标的回调函数mouse_event()，然后在回调函数中判断是否是左键单击事件EVENT_LBUTTONDOWN，是的话就打印出坐标。需要注意的是，回调函数的参数格式是固定的，不要随意更改。 那除了左键单击之外，还有哪些事件呢？可以用下面的代码打印出来： 123# 获取所有的事件events = [i for i in dir(cv2) if 'EVENT' in i]print(events) 综合实例现在我们来实现一个综合的例子，这个实例会帮助你理解图像交互的一些思想： 在图像上用鼠标画图，可以画圆或矩形，按m键在两种模式下切换。左键按下时开始画图，移动到哪儿画到哪儿，左键释放时结束画图。听上去很复杂，是吗？一步步分析下： 用鼠标画图：需要定义鼠标的回调函数mouse_event 画圆或矩形：需要定义一个画图的模式mode 左键单击、移动、释放：需要捕获三个不同的事件 开始画图，结束画图：需要定义一个画图的标记位drawing 好，开始coding吧： 1234567891011121314151617181920212223242526272829303132333435363738394041import cv2import numpy as npdrawing = False # 是否开始画图mode = True # True：画矩形，False：画圆start = (-1, -1)def mouse_event(event, x, y, flags, param): global start, drawing, mode # 左键按下：开始画图 if event == cv2.EVENT_LBUTTONDOWN: drawing = True start = (x, y) # 鼠标移动，画图 elif event == cv2.EVENT_MOUSEMOVE: if drawing: if mode: cv2.rectangle(img, start, (x, y), (0, 255, 0), 1) else: cv2.circle(img, (x, y), 5, (0, 0, 255), -1) # 左键释放：结束画图 elif event == cv2.EVENT_LBUTTONUP: drawing = False if mode: cv2.rectangle(img, start, (x, y), (0, 255, 0), 1) else: cv2.circle(img, (x, y), 5, (0, 0, 255), -1)img = np.zeros((512, 512, 3), np.uint8)cv2.namedWindow('image')cv2.setMouseCallback('image', mouse_event)while(True): cv2.imshow('image', img) # 按下m切换模式 if cv2.waitKey(1) == ord('m'): mode = not mode elif cv2.waitKey(1) == 27: break 效果应该如下图所示： 小结 要用鼠标绘图，需要用cv2.setMouseCallback()定义回调函数，然后在回调函数中根据不同的event事件，执行不同的功能 练习 （选做）实现用鼠标画矩形，跟实例差不多，但只实时画一个，类似下面动图： （选做）做一个在白色面板上绘图的简单程序，可用滑动条调整颜色和笔刷大小。 引用 本节源码 Mouse as a Paint-Brush","categories":[{"name":"机器视觉","slug":"机器视觉","permalink":"http://ex2tron.coding.me/categories/机器视觉/"}],"tags":[{"name":"OpenCV","slug":"OpenCV","permalink":"http://ex2tron.coding.me/tags/OpenCV/"},{"name":"Python","slug":"Python","permalink":"http://ex2tron.coding.me/tags/Python/"},{"name":"图像处理","slug":"图像处理","permalink":"http://ex2tron.coding.me/tags/图像处理/"},{"name":"绘图","slug":"绘图","permalink":"http://ex2tron.coding.me/tags/绘图/"}]},{"title":"Python+OpenCV教程8：绘图功能","slug":"Python-OpenCV教程8：绘图功能","date":"2017-12-09T03:29:48.000Z","updated":"2018-01-22T08:19:33.291Z","comments":true,"path":"2017/12/09/Python-OpenCV教程8：绘图功能/","link":"","permalink":"http://ex2tron.coding.me/2017/12/09/Python-OpenCV教程8：绘图功能/","excerpt":"学习画线、圆和矩形等多种几何形状，给图片添加文字。","text":"学习画线、圆和矩形等多种几何形状，给图片添加文字。图片等可到源码处下载。 目标 绘制各种几何形状、添加文字 OpenCV函数：cv2.line(), cv2.circle(), cv2.rectangle(), cv2.ellipse(), cv2.putText() 教程参数说明绘制形状的函数有一些共同的参数，提前在此说明一下： img：要绘制形状的图片 color：绘制的颜色，绘制彩色就传入BGR的一组值，如(255,0,0)；灰度图，传入一个灰度值就行 thickness：线宽，默认为1；对于矩形/圆之类的封闭形状而言，传入-1表示填充形状 模块导入和显示图片的通用代码，相信你已经很熟悉了，为节约篇幅，后面我会省略掉噢： 123456import cv2import numpy as npimport matplotlib.pyplot as pltcv2.imshow('img', img)cv2.waitKey(0) 上图就是本教程绘制的最终效果，下面一步步来看： 画线画线只需知道起点和终点的坐标就行： 1234# 创建一副黑色的图片img = np.zeros((512, 512, 3), np.uint8)# 画一条线宽为5的蓝色直线，参数2：起点，参数3：终点cv2.line(img, (0, 0), (512, 512), (255, 0, 0), 5) 经验之谈：所有绘图函数均会直接影响原图片，这点要注意 画矩形画矩形需要知道左上角和右下角的坐标： 12# 画一个绿色边框的矩形，参数2：左上角坐标，参数3：右下角坐标cv2.rectangle(img, (384, 0), (510, 128), (0, 255, 0), 3) 画圆画圆需要指定圆心和半径，注意下面的例子中线宽=-1代表填充： 12# 画一个填充红色的圆，参数2：圆心坐标，参数3：半径cv2.circle(img, (447, 63), 63, (0, 0, 255), -1) 画椭圆画椭圆需要的参数比较多，请对照后面的代码理解这几个参数： 参数2：椭圆中心(x,y) 参数3：x/y轴的长度 参数4：angle–椭圆的旋转角度 参数5：startAngle–椭圆的起始角度 参数6：endAngle–椭圆的结束角度 经验之谈：这里的角度是以顺时针方向计算的 12# 在图中心画一个填充的半圆cv2.ellipse(img, (256, 256), (100, 50), 0, 0, 180, (255, 0, 0), -1) 画多边形画多边形需要指定一系列多边形的顶点坐标，相当于从第一个点到第二个点画直线，再从第二个点到第三个点画直线…. OpenCV中需要先将多边形的顶点坐标需要变成顶点数×1×2维的矩阵，再来绘制： 12345# 定义四个顶点坐标pts = np.array([[10, 5], [50, 10], [70, 20], [20, 30]], np.int32)# 顶点个数：4，矩阵变成4*1*2维pts = pts.reshape((-1, 1, 2))cv2.polylines(img, [pts], True, (0, 255, 255)) cv2.polylines()的参数3如果是False的话，多边形就不闭合。 经验之谈：如果需要绘制多条直线，使用cv2.polylines()要比cv2.line()高效很多，例如： 12345# 使用cv2.polylines()画多条直线line1 = np.array([[100, 20], [300, 20]], np.int32).reshape((-1, 1, 2))line2 = np.array([[100, 60], [300, 60]], np.int32).reshape((-1, 1, 2))line3 = np.array([[100, 100], [300, 100]], np.int32).reshape((-1, 1, 2))cv2.polylines(img, [line1, line2, line3], True, (0, 255, 255)) 添加文字使用cv2.putText()添加文字，它的参数也比较多，同样请对照后面的代码理解这几个参数： 参数2：要添加的文本 参数3：文字的起始坐标（左下角为起点） 参数4：字体 参数5：文字大小（缩放比例） 1234# 添加文字font = cv2.FONT_HERSHEY_SIMPLEXcv2.putText(img, 'ex2tron', (10, 500), font, 4, (255, 255, 255), 2, lineType=cv2.LINE_AA) 这里有个线型lineType参数，LINE_AA表示抗锯齿线型，具体可见LineTypes 小结 cv2.line()画直线，cv2.circle()画圆，cv2.rectangle()画矩形，cv2.ellipse()画椭圆，cv2.polylines()画多边形，cv2.putText()添加文字 画多条直线时，cv2.polylines()要比cv2.line()高效很多 练习 你能用已学的绘图功能画出OpenCV的logo吗？(提示：椭圆和圆) 引用 本节源码 LineTypes Drawing Functions in OpenCV","categories":[{"name":"机器视觉","slug":"机器视觉","permalink":"http://ex2tron.coding.me/categories/机器视觉/"}],"tags":[{"name":"OpenCV","slug":"OpenCV","permalink":"http://ex2tron.coding.me/tags/OpenCV/"},{"name":"Python","slug":"Python","permalink":"http://ex2tron.coding.me/tags/Python/"},{"name":"图像处理","slug":"图像处理","permalink":"http://ex2tron.coding.me/tags/图像处理/"},{"name":"绘图","slug":"绘图","permalink":"http://ex2tron.coding.me/tags/绘图/"}]},{"title":"Python+OpenCV教程7：图像几何变换","slug":"Python-OpenCV教程7：图像几何变换","date":"2017-12-08T06:36:53.000Z","updated":"2018-01-29T05:19:37.033Z","comments":true,"path":"2017/12/08/Python-OpenCV教程7：图像几何变换/","link":"","permalink":"http://ex2tron.coding.me/2017/12/08/Python-OpenCV教程7：图像几何变换/","excerpt":"学习如何旋转、平移和缩放图片，了解仿射/透视变换。","text":"学习如何旋转、平移和缩放图片，了解仿射/透视变换。图片等可到源码处下载。 目标 实现旋转、平移和缩放图片 了解仿射变换和透视变换 OpenCV函数：cv2.resize(), cv2.warpAffine(), cv2.warpPerspective() 教程缩放图片缩放就是调整图片的大小，使用cv2.resize()函数实现缩放。可以按照比例缩放，也可以按照指定的大小缩放： 12345678910111213import cv2import numpy as npimport matplotlib.pyplot as pltimg = cv2.imread('drawing.jpg')# 按照指定的宽度、高度缩放图片res = cv2.resize(img, (132, 150))# 按照比例缩放，如x,y轴均放大一倍res2 = cv2.resize(img, None, fx=2, fy=2, interpolation=cv2.INTER_LINEAR)cv2.imshow('shrink', res), cv2.imshow('zoom', res2)cv2.waitKey(0) 我们也可以指定缩放方法interpolation，更专业点叫插值方法，默认是INTER_LINEAR，全部可以参考：InterpolationFlags 平移图片这里涉及到仿射变换的概念，大家不用知道它的意思，只需要了解下面三点： 仿射变换后，原图中平行的线依然平行 用cv2.warpAffine()实现仿射变换 仿射变换需要定义一个2*3维的变换矩阵 要平移图片，我们需要定义下面这样一个矩阵，tx,ty是向x和y方向平移的距离： $$ M = \\left[ \\begin{matrix} 1 &amp; 0 &amp; tx \\newline 0 &amp; 1 &amp; ty \\end{matrix} \\right] \\tag{3}$$ 1234567891011# 平移图片rows, cols = img.shape[:2]# 定义平移矩阵，需要是numpy的float32类型# x轴平移100，y轴平移50M = np.float32([[1, 0, 100], [0, 1, 50]])# 用仿射变换实现平移dst = cv2.warpAffine(img, M, (cols, rows))cv2.imshow('shift', dst)cv2.waitKey(0) 再次强调一下：图片的高度（y方向）是rows，宽度（x方向）是cols，请勿混淆 旋转图片旋转同平移一样，也需要定义一个变换矩阵。OpenCV直接提供了cv2.getRotationMatrix2D()函数用来生成这个矩阵，对这个矩阵的形式感兴趣的童鞋可以去引用查看： 123456# 45°旋转图片并缩小一半M = cv2.getRotationMatrix2D((cols / 2, rows / 2), 45, 0.5)dst = cv2.warpAffine(img, M, (cols, rows))cv2.imshow('rotation', dst)cv2.waitKey(0) cv2.getRotationMatrix2D()函数有三个参数： 参数1：图片的旋转中心 参数2：旋转角度 参数3：缩放比例，该例中0.5表示我们缩小一半 翻转图片如果我们镜像翻转图片，可以用cv2.flip()函数： 1dst = cv2.flip(img, 1) 其中参数2 = 0：垂直翻转(沿x轴)，参数2 &gt; 0: 水平翻转(沿y轴)，参数2 &lt; 0: 水平垂直翻转。 仿射变换除了平移和旋转，如何实现任意的图像变换呢？同样的道理，我们需要一个变换矩阵。 要生成这个变换矩阵，需要定义变换前后的三个点，比如说： 123456789101112# 变换前的三个点pts1 = np.float32([[50, 65], [150, 65], [210, 210]])# 变换后的三个点pts2 = np.float32([[50, 100], [150, 65], [100, 250]])# 生成变换矩阵M = cv2.getAffineTransform(pts1, pts2)dst = cv2.warpAffine(img, M, (cols, rows))plt.subplot(121), plt.imshow(img), plt.title('input')plt.subplot(122), plt.imshow(dst), plt.title('output')plt.show() 变换前后的三个点我已经标记出来了。用cv2.getAffineTransform()生成变换矩阵，接下来再用cv2.warpAffine()实现变换。大家可以修改下变换后的三个点坐标看看效果： 透视变换透视变换绝对是一项很酷的功能。我们经常会用手机去拍身份证和文件，无论你怎么拍，貌似都拍不正或者有边框。如果你使用过手机上面一些扫描类软件，比如”扫描全能王“，”Office Lens“，它们能很好地矫正图片。这些软件就是应用透视变换实现的，跟仿射变换一样，我们不用知道它的具体原理。 透视变换后，原图中的直线依旧是直线。如下图，我们实现这个功能： 1234567891011121314151617181920import cv2import numpy as npimport matplotlib.pyplot as pltimg = cv2.imread('card.jpg')rows, cols = img.shape[:2]# 原图中卡片的四个角点pts1 = np.float32([[148, 80], [437, 114], [94, 247], [423, 288]])# 变换后分别在左上、右上、左下、右下四个点pts2 = np.float32([[0, 0], [320, 0], [0, 178], [320, 178]])# 生成透视变换矩阵M = cv2.getPerspectiveTransform(pts1, pts2)# 进行透视变换dst = cv2.warpPerspective(img, M, (320, 178))plt.subplot(121), plt.imshow(img[:, :, ::-1]), plt.title('input')plt.subplot(122), plt.imshow(dst[:, :, ::-1]), plt.title('output')plt.show() 透视变换需要前后四个点来生成3*3的变换矩阵，用cv2.getPerspectiveTransform()实现。然后再用cv2.warpPerspective()进行变换。代码中有个img[:, :, ::-1]还记得吗？忘记的话，请看练习。 是不是很简单？当然，我们后面学习了特征提取之后，就可以自动识别角点了。 小结 cv2.resize()缩放图片，可以按指定大小缩放，亦可以按比例缩放 平移和旋转是靠cv2.warpAffine()仿射变换实现的，也可以自己定义变换前后的点，实现任意变换 透视变换常用于矫正图片，是一个很酷的功能 练习 透视变换代码中有个img[:, :, ::-1]，还记得吗？请复习：Matplotlib显示图像 引用 本节源码 Geometric Transformations of Images","categories":[{"name":"机器视觉","slug":"机器视觉","permalink":"http://ex2tron.coding.me/categories/机器视觉/"}],"tags":[{"name":"OpenCV","slug":"OpenCV","permalink":"http://ex2tron.coding.me/tags/OpenCV/"},{"name":"Python","slug":"Python","permalink":"http://ex2tron.coding.me/tags/Python/"},{"name":"图像处理","slug":"图像处理","permalink":"http://ex2tron.coding.me/tags/图像处理/"},{"name":"几何变换","slug":"几何变换","permalink":"http://ex2tron.coding.me/tags/几何变换/"}]},{"title":"Python+OpenCV教程番外篇4：Otsu阈值法","slug":"Python-OpenCV教程番外篇4：Otsu阈值法","date":"2017-12-08T04:48:05.000Z","updated":"2018-01-19T06:08:20.571Z","comments":true,"path":"2017/12/08/Python-OpenCV教程番外篇4：Otsu阈值法/","link":"","permalink":"http://ex2tron.coding.me/2017/12/08/Python-OpenCV教程番外篇4：Otsu阈值法/","excerpt":"大部分图像处理任务都需要先二值化操作，所以阈值的选取很关键，Otsu阈值法会自动计算阈值。","text":"大部分图像处理任务都需要先二值化操作，所以阈值的选取很关键，Otsu阈值法会自动计算阈值。 Otsu阈值法（日本人提出的，也可以叫大津算法）会自动计算阈值，它适用于双峰图片，啥意思呢？ 什么是双峰图片？双峰图片就是指图片的灰度直方图上有两个峰值，直方图就是每个值（0~255）的像素点个数统计，如黑色点0有多少个等等，后面会详细介绍。 Otsu算法假设这副图片由前景色和背景色组成，通过统计学方法（最大类间方差）选取一个阈值，将前景和背景尽可能分开，算法详解：Otsu’s Method(wikipedia) 代码示例下面这段代码对比了使用固定阈值和Otsu阈值后的不同结果： 另外，对含噪点的图像，先进行滤波操作效果会更好。 1234567891011121314import cv2from matplotlib import pyplot as pltimg = cv2.imread('noisy.jpg', 0)# 固定阈值法ret1, th1 = cv2.threshold(img, 100, 255, cv2.THRESH_BINARY)# Otsu阈值法ret2, th2 = cv2.threshold(img, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)# 先进行高斯滤波，再使用Otsu阈值法blur = cv2.GaussianBlur(img, (5, 5), 0)ret3, th3 = cv2.threshold(blur, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU) 下面我们用Matplotlib把原图、直方图和阈值图都显示出来： 123456789101112131415161718192021222324images = [img, 0, th1, img, 0, th2, blur, 0, th3]titles = ['Original', 'Histogram', 'Global(v=100)', 'Original', 'Histogram', \"Otsu's\", 'Gaussian filtered Image', 'Histogram', \"Otsu's\"]for i in range(3): # 绘制原图 plt.subplot(3, 3, i * 3 + 1) plt.imshow(images[i * 3], 'gray') plt.title(titles[i * 3], fontsize=8) plt.xticks([]), plt.yticks([]) # 绘制直方图plt.hist，ravel函数将数组降成一维 plt.subplot(3, 3, i * 3 + 2) plt.hist(images[i * 3].ravel(), 256) plt.title(titles[i * 3 + 1], fontsize=8) plt.xticks([]), plt.yticks([]) # 绘制阈值图 plt.subplot(3, 3, i * 3 + 3) plt.imshow(images[i * 3 + 2], 'gray') plt.title(titles[i * 3 + 2], fontsize=8) plt.xticks([]), plt.yticks([])plt.show() 可以看到，Otsu阈值明显由于固定阈值，省去了不断尝试阈值判断效果好坏的过程。其中，绘制直方图时，使用了numpy中的ravel()函数，它会将原矩阵压缩成一维数组，便于画直方图。 引用 本节源码 numpy.ravel Otsu’s Method Image Thresholding","categories":[{"name":"机器视觉","slug":"机器视觉","permalink":"http://ex2tron.coding.me/categories/机器视觉/"}],"tags":[{"name":"OpenCV","slug":"OpenCV","permalink":"http://ex2tron.coding.me/tags/OpenCV/"},{"name":"Python","slug":"Python","permalink":"http://ex2tron.coding.me/tags/Python/"},{"name":"图像处理","slug":"图像处理","permalink":"http://ex2tron.coding.me/tags/图像处理/"},{"name":"阈值","slug":"阈值","permalink":"http://ex2tron.coding.me/tags/阈值/"}]},{"title":"Python+OpenCV教程6：阈值分割","slug":"Python-OpenCV教程6：阈值分割","date":"2017-12-07T13:14:44.000Z","updated":"2018-01-05T04:34:30.800Z","comments":true,"path":"2017/12/07/Python-OpenCV教程6：阈值分割/","link":"","permalink":"http://ex2tron.coding.me/2017/12/07/Python-OpenCV教程6：阈值分割/","excerpt":"学习使用不同的阈值方法”二值化”图像。","text":"学习使用不同的阈值方法”二值化”图像。图片等可到源码处下载。 目标 使用固定阈值、自适应阈值和Otsu阈值法”二值化”图像 OpenCV函数：cv2.threshold(), cv2.adaptiveThreshold() 教程固定阈值分割固定阈值分割很直接，一句话说就是像素点值大于阈值一个值，小于阈值是另外一个值。 12345678910import cv2import matplotlib.pyplot as plt# 灰度图读入img = cv2.imread('gradient.jpg', 0)# 阈值分割ret, th = cv2.threshold(img, 127, 255, cv2.THRESH_BINARY)cv2.imshow('thresh', th)cv2.waitKey(0) cv2.threshold()用来实现阈值分割，ret是return value缩写，代表当前的阈值，暂时不用理会。函数有4个参数： 参数1：要处理的原图，一般是灰度图 参数2：设定的阈值 参数3：最大阈值，一般为255 参数4：阈值的方式，主要有5种，详情：ThresholdTypes 123456789101112131415161718# 应用5种不同的阈值方法ret, th1 = cv2.threshold(img, 127, 255, cv2.THRESH_BINARY)ret, th2 = cv2.threshold(img, 127, 255, cv2.THRESH_BINARY_INV)ret, th3 = cv2.threshold(img, 127, 255, cv2.THRESH_TRUNC)ret, th4 = cv2.threshold(img, 127, 255, cv2.THRESH_TOZERO)ret, th5 = cv2.threshold(img, 127, 255, cv2.THRESH_TOZERO_INV)titles = ['Original', 'BINARY', 'BINARY_INV', 'TRUNC', 'TOZERO', 'TOZERO_INV']images = [img, th1, th2, th3, th4, th5]# 使用Matplotlib显示for i in range(6): plt.subplot(2, 3, i + 1) plt.imshow(images[i], 'gray') plt.title(titles[i], fontsize=8) plt.xticks([]), plt.yticks([]) # 隐藏坐标轴plt.show() 结合下表，就很容易理解这5种方式了： 经验之谈：很多人误以为阈值分割就是二值化。从上图中可以发现，两者并不等同，阈值分割结果是两种值，而不是两个值，所以教程开头我把二值化加了引号 自适应阈值看得出来固定阈值是在整幅图片上应用一个阈值进行分割，它并不适用于明暗分布不均的图片。cv2.adaptiveThreshold()自适应阈值会每次取图片的一小部分计算阈值，这样图片不同区域的阈值就不尽相同。它有5个参数，其实很好理解，先看下效果： 12345678910111213141516171819# 自适应阈值对比固定阈值img = cv2.imread('sudoku.jpg', 0)# 固定阈值ret, th1 = cv2.threshold(img, 127, 255, cv2.THRESH_BINARY)# 自适应阈值th2 = cv2.adaptiveThreshold( img, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 11, 4)th3 = cv2.adaptiveThreshold( img, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 17, 6)titles = ['Original', 'Global(v = 127)', 'Adaptive Mean', 'Adaptive Gaussian']images = [img, th1, th2, th3]for i in range(4): plt.subplot(2, 2, i + 1), plt.imshow(images[i], 'gray') plt.title(titles[i], fontsize=8) plt.xticks([]), plt.yticks([])plt.show() 参数1：要处理的原图 参数2：最大阈值，一般为255 参数3：小区域阈值的计算方式 ADAPTIVE_THRESH_MEAN_C：小区域内取均值 ADAPTIVE_THRESH_GAUSSIAN_C：小区域内加权求和，权重是个高斯核 参数4：阈值方式（跟前面讲的那5种相同） 参数5：小区域的面积，如11就是11*11的小块 参数6：最终阈值等于小区域计算出的阈值再减去此值 如果你没看懂上面的参数也不要紧，暂时会用就行，当然我建议你调整下参数看看不同的结果。 Otsu阈值在前面固定阈值中，我们是随便选了一个阈值如127，那如何知道我们选的这个阈值效果好不好呢？答案是：不断尝试，所以这种方法在很多文献中都被称为经验阈值。Otsu阈值法就提供了一种自动高效的二值化方法，不过我们直方图还没学，这里暂时略过。 好吧，我知道我激起了你的兴趣，~ o(￣▽￣)o，有能力的童鞋可以看下练习题。 小结 cv2.threshold()用来进行固定阈值分割。固定阈值不适用于光线不均匀的图片，所以用cv2.adaptiveThreshold()进行自适应阈值分割 二值化跟阈值分割并不等同。针对不同的图片，可以采用不同的阈值方法 练习 Otsu阈值是一种高效的二值化算法，请尝试阅读番外篇：Otsu阈值法 引用 本节源码 Image Thresholding","categories":[{"name":"机器视觉","slug":"机器视觉","permalink":"http://ex2tron.coding.me/categories/机器视觉/"}],"tags":[{"name":"OpenCV","slug":"OpenCV","permalink":"http://ex2tron.coding.me/tags/OpenCV/"},{"name":"Python","slug":"Python","permalink":"http://ex2tron.coding.me/tags/Python/"},{"name":"图像处理","slug":"图像处理","permalink":"http://ex2tron.coding.me/tags/图像处理/"},{"name":"阈值","slug":"阈值","permalink":"http://ex2tron.coding.me/tags/阈值/"}]},{"title":"Python+OpenCV教程5：颜色空间转换","slug":"Python-OpenCV教程5：颜色空间转换","date":"2017-12-07T07:21:19.000Z","updated":"2017-12-22T03:53:57.741Z","comments":true,"path":"2017/12/07/Python-OpenCV教程5：颜色空间转换/","link":"","permalink":"http://ex2tron.coding.me/2017/12/07/Python-OpenCV教程5：颜色空间转换/","excerpt":"学习如何进行图片的颜色空间转换，视频中追踪特定颜色物体。","text":"学习如何进行图片的颜色空间转换，视频中追踪特定颜色物体。图片等可到源码处下载。 目标 颜色空间转换，如BGR↔Gray，BGR↔HSV等 追踪视频中特定颜色的物体 OpenCV函数：cv2.cvtColor(),cv2.inRange() 教程颜色空间转换12345678import cv2import numpy as npimg = cv2.imread('lena.jpg')# 转换为灰度图img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)cv2.imshow('img', img)cv2.imshow('gray', img_gray), cv2.waitKey(0) cv2.cvtColor()用来进行颜色模型转换，参数1是要转换的图片，参数2是转换模式，COLOR_BGR2GRAY表示BGR→Gray，可用下面的代码显示所有的转换模式： 12flags = [i for i in dir(cv2) if i.startswith('COLOR_')]print(flags) 视频中特定颜色物体追踪HSV是一个常用于颜色识别的模型，相比BGR更易区分颜色，转换模式用COLOR_BGR2HSV表示。 经验之谈：OpenCV中色调H范围为[0,179]，饱和度S是[0,255]，明度V是[0,255]。虽然H的理论数值是0°~360°，但8位图像像素点的最大值是255，所以OpenCV中除以了2，某些软件可能使用不同的尺度表示，所以同其他软件混用时，记得归一化。 现在，我们实现一个使用HSV来只显示视频中蓝色物体的例子，步骤如下： 捕获视频中的一帧 从BGR转换到HSV 提取蓝色范围的物体 只显示蓝色物体 12345678910111213141516171819202122232425capture = cv2.VideoCapture(0)# 蓝色的范围，不同光照条件下不一样，可灵活调整lower_blue = np.array([100, 110, 110])upper_blue = np.array([130, 255, 255])while(True): # 1.捕获视频中的一帧 ret, frame = capture.read() # 2.从BGR转换到HSV hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV) # 3.inRange()：介于lower/upper之间的为白色，其余黑色 mask = cv2.inRange(hsv, lower_blue, upper_blue) # 4.只保留原图中的蓝色部分 res = cv2.bitwise_and(frame, frame, mask=mask) cv2.imshow('frame', frame) cv2.imshow('mask', mask) cv2.imshow('res', res) if cv2.waitKey(1) == ord('q'): break 其中，bitwise_and()函数暂时不用管，后面会讲到。那蓝色的HSV值的lower和upper范围是怎么得到的呢？其实很简单，我们先把标准蓝色的值用cvtColor()转换下： 123blue = np.uint8([[[255, 0, 0]]])hsv_blue = cv2.cvtColor(blue, cv2.COLOR_BGR2HSV)print(hsv_blue) # [[[120 255 255]]] 结果是[120, 255, 255]，所以，我们把蓝色的范围调整成了上面代码那样。 经验之谈：Lab颜色空间也经常用来做颜色识别，有兴趣的同学可以了解下。 小结 cv2.cvtColor()函数用来进行颜色空间转换，常用BGR↔Gray，BGR↔HSV HSV/Lab颜色模型常用于颜色识别。要想知道某种颜色在HSV下的值，可以将它的BGR值用cvtColor()转换得到 练习 尝试在视频中同时提取红色、蓝色、绿色的物体。（效果如下） 引用 本节源码 Changing Colorspaces","categories":[{"name":"机器视觉","slug":"机器视觉","permalink":"http://ex2tron.coding.me/categories/机器视觉/"}],"tags":[{"name":"OpenCV","slug":"OpenCV","permalink":"http://ex2tron.coding.me/tags/OpenCV/"},{"name":"Python","slug":"Python","permalink":"http://ex2tron.coding.me/tags/Python/"},{"name":"图像处理","slug":"图像处理","permalink":"http://ex2tron.coding.me/tags/图像处理/"},{"name":"HSV","slug":"HSV","permalink":"http://ex2tron.coding.me/tags/HSV/"}]},{"title":"Python+OpenCV教程4：图像基本操作","slug":"Python-OpenCV教程4：图像基本操作","date":"2017-12-07T04:13:15.000Z","updated":"2017-12-29T02:59:29.838Z","comments":true,"path":"2017/12/07/Python-OpenCV教程4：图像基本操作/","link":"","permalink":"http://ex2tron.coding.me/2017/12/07/Python-OpenCV教程4：图像基本操作/","excerpt":"学习获取和修改像素点的值，ROI感兴趣区域，通道分离合并等基本操作。","text":"学习获取和修改像素点的值，ROI感兴趣区域，通道分离合并等基本操作。图片等可到源码处下载。 目标 访问和修改图片像素点的值 获取图片的宽、高、通道数等属性 了解感兴趣区域ROI 分离和合并图像通道 教程获取和修改像素点值我们先读入一张图片： 123import cv2img = cv2.imread('lena.jpg') 通过行列的坐标来获取某像素点的值，对于彩色图，这个值是B,G,R三个值的列表，对于灰度图，只有一个值： 123456px = img[100, 100]print(px) # [119 108 201]# 只获取蓝色blue通道的值px_blue = img[100, 100, 0]print(px_blue) # 119 经验之谈：还记得吗？行对应的是y，列对应的是x，所以其实是img[y, x]，需要注意噢(●ˇ∀ˇ●) 修改像素的值也是同样的方式： 12img[100, 100] = [255, 255, 255]print(img[100, 100]) # [255 255 255] 经验之谈：还有一种性能更好的方式，获取：img.item(100,100,0)，修改：img.itemset((100,100,0),255)，但这种方式只能B,G,R逐一进行 图片属性img.shape获取图像的形状，图片是彩色的话，返回一个包含高度、宽度和通道数的元组，灰度图只返回高度和宽度： 1234print(img.shape) # (263, 263, 3)# 形状中包括高度、宽度和通道数height, width, channels = img.shape# img是灰度图的话：height, width = img.shape img.dtype获取图像数据类型： 1print(img.dtype) # uint8 经验之谈：很多错误都是因为数据类型不对导致的，所以健壮的代码需要对这个属性加以判断 img.size获取图像总像素数： 1print(img.size) # 263*263*3=207507 ROIROI：region of interest，感兴趣区域。什么意思呢？比如我们要检测眼睛，因为眼睛肯定在脸上，所以我们感兴趣的只有脸这部分，其他不需要关注，这样就可以大大节省计算量，提高运行速度。 截取ROI非常简单，指定图片的范围即可： 1234# 截取脸部ROIface = img[100:200, 115:188]cv2.imshow('face', face)cv2.waitKey(0) 通道分割与合并彩色图的BGR三个通道是可以分开单独访问的，也可以将单独的三个通道合并成一副图像。分别使用cv2.split()和cv2.merge()： 12b, g, r = cv2.split(img)img = cv2.merge((b, g, r)) split()函数比较耗时，更高效的方式是用numpy的索引，如提取B通道： 123b = img[:, :, 0]cv2.imshow('blue', b)cv2.waitKey(0) 小结 img[y,x]获取/设置像素点值，img.shape：图片的形状（高度、宽度、通道数）,img.dtype：图像的数据类型 img[y1:y2,x1:x2]进行ROI截取，cv2.split()/cv2.merge()通道分割/合并。更推荐的获取单通道方式：b = img[:, :, 0] 练习 打开lena.jpg，将帽子部分（高：25~120，宽：50~220）的红色通道截取出来并显示。 引用 本节源码 Basic Operations on Images","categories":[{"name":"机器视觉","slug":"机器视觉","permalink":"http://ex2tron.coding.me/categories/机器视觉/"}],"tags":[{"name":"OpenCV","slug":"OpenCV","permalink":"http://ex2tron.coding.me/tags/OpenCV/"},{"name":"Python","slug":"Python","permalink":"http://ex2tron.coding.me/tags/Python/"},{"name":"图像处理","slug":"图像处理","permalink":"http://ex2tron.coding.me/tags/图像处理/"},{"name":"ROI","slug":"ROI","permalink":"http://ex2tron.coding.me/tags/ROI/"}]},{"title":"Python+OpenCV教程番外篇3：滑动条","slug":"Python-OpenCV教程番外篇3：滑动条","date":"2017-12-06T14:23:11.000Z","updated":"2018-01-19T06:08:20.571Z","comments":true,"path":"2017/12/06/Python-OpenCV教程番外篇3：滑动条/","link":"","permalink":"http://ex2tron.coding.me/2017/12/06/Python-OpenCV教程番外篇3：滑动条/","excerpt":"学习使用滑动条动态调整参数。","text":"学习使用滑动条动态调整参数。图片等可到源码处下载。 目标 创建和使用滑动条 OpenCV函数：cv2.createTrackbar(), cv2.getTrackbarPos() 教程滑动条的使用首先我们需要创建一个滑动条，如cv2.createTrackbar(&#39;R&#39;,&#39;image&#39;,0,255,call_back)，其中 参数1：滑动条的名称 参数2：所在窗口的名称 参数3：当前的值 参数4：最大值 参数5：回调函数名称，回调函数默认有一个表示当前值的参数 创建好之后，可以在回调函数中获取滑动条的值，也可以用：cv2.getTrackbarPos()得到，其中，参数1是滑动条的名称，参数2是窗口的名称。下面我们实现一个RGB的调色板，理解下函数的使用： 1234567891011121314151617181920212223242526import cv2import numpy as np# 回调函数，x表示滑块的位置，本例暂不使用def nothing(x): passimg = np.zeros((300, 512, 3), np.uint8)cv2.namedWindow('image')# 创建RGB三个滑动条cv2.createTrackbar('R', 'image', 0, 255, nothing)cv2.createTrackbar('G', 'image', 0, 255, nothing)cv2.createTrackbar('B', 'image', 0, 255, nothing)while(True): cv2.imshow('image', img) if cv2.waitKey(1) == 27: break # 获取滑块的值 r = cv2.getTrackbarPos('R', 'image') g = cv2.getTrackbarPos('G', 'image') b = cv2.getTrackbarPos('B', 'image') # 设定img的颜色 img[:] = [b, g, r] 小结 cv2.createTrackbar()用来创建滑动条，可以在回调函数中得到滑块的位置，也可以用cv2.getTrackbarPos() 引用 本节源码 Trackbar as the Color Palette","categories":[{"name":"机器视觉","slug":"机器视觉","permalink":"http://ex2tron.coding.me/categories/机器视觉/"}],"tags":[{"name":"OpenCV","slug":"OpenCV","permalink":"http://ex2tron.coding.me/tags/OpenCV/"},{"name":"Python","slug":"Python","permalink":"http://ex2tron.coding.me/tags/Python/"},{"name":"图像处理","slug":"图像处理","permalink":"http://ex2tron.coding.me/tags/图像处理/"},{"name":"滑动条","slug":"滑动条","permalink":"http://ex2tron.coding.me/tags/滑动条/"}]},{"title":"Python+OpenCV教程3：打开摄像头","slug":"Python-OpenCV教程3：打开摄像头","date":"2017-12-06T08:38:02.000Z","updated":"2018-02-01T13:02:22.625Z","comments":true,"path":"2017/12/06/Python-OpenCV教程3：打开摄像头/","link":"","permalink":"http://ex2tron.coding.me/2017/12/06/Python-OpenCV教程3：打开摄像头/","excerpt":"学习打开摄像头捕获照片、播放本地视频、录制视频等。","text":"学习打开摄像头捕获照片、播放本地视频、录制视频等。视频等可到源码处下载。 目标 打开摄像头并捕获照片 播放本地视频，录制视频 OpenCV函数：cv2.VideoCapture(), cv2.VideoWriter() 教程打开摄像头要使用摄像头，需要使用cv2.VideoCapture(0)创建VideoCapture对象，参数：0指的是摄像头的编号。如果你电脑上有两个摄像头的话，访问第2个摄像头就可以传入1。 1234567891011121314# 打开摄像头并灰度化显示import cv2capture = cv2.VideoCapture(0)while(True): # 获取一帧 ret, frame = capture.read() # 将这帧转换为灰度图 gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY) cv2.imshow('frame', gray) if cv2.waitKey(1) == ord('q'): break capture.read()函数返回的第1个参数ret(return value缩写)是一个布尔值，表示当前这一帧是否获取正确。cv2.cvtColor()用来转换颜色，这里将彩色图转成灰度图。 另外，通过cap.get(propId)可以获取摄像头的一些属性，比如捕获的分辨率，亮度和对比度等。propId是从0~18的数字，代表不同的属性，完整的属性列表可以参考：VideoCaptureProperties。也可以使用cap.set(propId,value)来修改属性值。比如说，我们在while之前添加下面的代码： 12345678# 获取捕获的分辨率# propId可以直接写数字，也可以用OpenCV的符号表示width, height = capture.get(3), capture.get(4)print(width, height)# 以原分辨率的一倍来捕获capture.set(cv2.CAP_PROP_FRAME_WIDTH, width * 2)capture.set(cv2.CAP_PROP_FRAME_HEIGHT, height * 2) 经验之谈：某些摄像头设定分辨率等参数时会无效，因为它有固定的分辨率大小支持，一般可在摄像头的资料页中找到 播放本地视频跟打开摄像头一样，如果把摄像头的编号换成视频的路径就可以播放本地视频了。回想一下cv2.waitKey()，它的参数表示暂停时间，所以这个值越大，视频播放速度越慢，反之，播放速度越快，通常设置为25或30。 12345678910# 播放本地视频capture = cv2.VideoCapture('demo_video.mp4')while(capture.isOpened()): ret, frame = capture.read() gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY) cv2.imshow('frame', gray) if cv2.waitKey(30) == ord('q'): break 录制视频之前我们保存图片用的是cv2.imwrite()，要保存视频，我们需要创建一个VideoWriter的对象，需要给它传入四个参数： 输出的文件名，如’output.avi’ 编码方式FourCC码 帧率FPS 要保存的分辨率大小 FourCC是用来指定视频编码方式的四字节码，所有的编码可参考Video Codecs。如MJPG编码可以这样写：cv2.VideoWriter_fourcc(*&#39;MJPG&#39;)或cv2.VideoWriter_fourcc(&#39;M&#39;,&#39;J&#39;,&#39;P&#39;,&#39;G&#39;) 12345678910111213141516capture = cv2.VideoCapture(0)# 定义编码方式并创建VideoWriter对象fourcc = cv2.VideoWriter_fourcc(*'MJPG')outfile = cv2.VideoWriter('output.avi', fourcc, 25., (640, 480))while(capture.isOpened()): ret, frame = capture.read() if ret: outfile.write(frame) # 写入文件 cv2.imshow('frame', frame) if cv2.waitKey(1) == ord('q'): break else: break 小结 使用cv2.VideoCapture()创建视频对象，然后在循环中一帧帧显示图像。参数传入数字时，代表打开摄像头，传入本地视频路径时，表示播放本地视频 cap.get(propId)获取视频属性，cap.set(propId,value)设置视频属性 cv2.VideoWriter()创建视频写入对象，用来录制/保存视频 练习 请尝试先阅读番外篇：滑动条，然后实现一个可以拖动滑块播放视频的功能。（提示：需要用到cv2.CAP_PROP_FRAME_COUNT和cv2.CAP_PROP_POS_FRAMES两个属性） 引用 本节源码 Video Codecs by FOURCC Getting Started with Videos","categories":[{"name":"机器视觉","slug":"机器视觉","permalink":"http://ex2tron.coding.me/categories/机器视觉/"}],"tags":[{"name":"OpenCV","slug":"OpenCV","permalink":"http://ex2tron.coding.me/tags/OpenCV/"},{"name":"Python","slug":"Python","permalink":"http://ex2tron.coding.me/tags/Python/"},{"name":"图像处理","slug":"图像处理","permalink":"http://ex2tron.coding.me/tags/图像处理/"}]},{"title":"Python+OpenCV教程番外篇2：Matplotlib显示图像","slug":"Python-OpenCV教程番外篇2：Matplotlib显示图像","date":"2017-12-06T07:55:15.000Z","updated":"2018-01-19T06:08:20.571Z","comments":true,"path":"2017/12/06/Python-OpenCV教程番外篇2：Matplotlib显示图像/","link":"","permalink":"http://ex2tron.coding.me/2017/12/06/Python-OpenCV教程番外篇2：Matplotlib显示图像/","excerpt":"学习如何使用Matplotlib显示OpenCV图像。","text":"学习如何使用Matplotlib显示OpenCV图像。 Matplotlib是Python的一个非常重要的绘图库，更多内容可以去官网学习。 显示灰度图1234567import cv2import matplotlib.pyplot as pltimg = cv2.imread('lena.jpg', 0)# 灰度图显示，cmap(color map)设置为grayplt.imshow(img, cmap='gray')plt.show() 结果如下： 显示彩色图OpenCV中的图像是以BGR的通道顺序存储的，但Matplotlib是以RGB模式显示的，所以直接在Matplotlib中显示OpenCV图像会出现问题，因此需要转换一下: 12345678910111213141516import cv2import matplotlib.pyplot as pltimg = cv2.imread('lena.jpg')img2 = img[:, :, ::-1]# 或使用# img2 = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)# 显示不正确的图plt.subplot(121),plt.imshow(img) # 显示正确的图plt.subplot(122)plt.xticks([]), plt.yticks([]) # 隐藏x和y轴plt.imshow(img2)plt.show() 注解：img[:,:,0]表示图片的蓝色通道，熟悉Python的同学应该知道，对一个字符串s进行翻转用的是s[::-1]，同样img[:,:,::-1]就表示BGR通道翻转，变成RGB 结果如下： 引用 本节源码 Matplotlib","categories":[{"name":"机器视觉","slug":"机器视觉","permalink":"http://ex2tron.coding.me/categories/机器视觉/"}],"tags":[{"name":"OpenCV","slug":"OpenCV","permalink":"http://ex2tron.coding.me/tags/OpenCV/"},{"name":"Python","slug":"Python","permalink":"http://ex2tron.coding.me/tags/Python/"},{"name":"图像处理","slug":"图像处理","permalink":"http://ex2tron.coding.me/tags/图像处理/"},{"name":"Matplotlib","slug":"Matplotlib","permalink":"http://ex2tron.coding.me/tags/Matplotlib/"}]},{"title":"Python+OpenCV教程2：基本元素-图片","slug":"Python-OpenCV教程2：基本元素-图片","date":"2017-12-06T07:52:06.000Z","updated":"2017-12-29T02:59:29.862Z","comments":true,"path":"2017/12/06/Python-OpenCV教程2：基本元素-图片/","link":"","permalink":"http://ex2tron.coding.me/2017/12/06/Python-OpenCV教程2：基本元素-图片/","excerpt":"学习如何加载图片，显示并保存图片。","text":"学习如何加载图片，显示并保存图片。图片等可到源码处下载。 目标 加载图片，显示图片，保存图片 OpenCV函数：cv2.imread(), cv2.imshow(), cv2.imwrite() 教程图片 注：本教程不再赘述图像处理的基本理论，只把需要注意的做简单提及噢(⊙o⊙) OpenCV中彩色图是以B-G-R通道存储的，灰度图只有一个通道，图像坐标的起始点是在左上角： 加载图片使用cv2.imread()来读入一张图片： 1234import cv2# 灰度图加载img = cv2.imread('lena.jpg', 0) 参数1：图片的文件名 如果图片放在当前文件夹下，直接写文件名就行了，如’lena.jpg’ 否则，需要给出绝对路径，如’D:\\OpenCVSamples\\lena.jpg’ 参数2：读入方式，省略即采用默认值 cv2.IMREAD_COLOR：彩色图，默认值(1) cv2.IMREAD_GRAYSCALE：灰度图(0) cv2.IMREAD_UNCHANGED：包含透明通道的彩色图(-1) 经验之谈：路径中不能有中文噢，并且没有加载成功的话是不会报错的，而是None，后面处理才会报错，算是个小坑 显示图片使用cv2.imshow()显示图片，窗口会自适应图片的大小： 12cv2.imshow('lena', img)cv2.waitKey(0) 结果应该如下： 参数1是窗口的名字，参数2是要显示的图片。 cv2.waitKey()是让程序暂停的意思，参数是等待时间（毫秒ms）。时间一到，会继续执行接下来的程序，传入0的话表示一直等待。等待期间也可以获取用户的按键输入：k = cv2.waitKey(0)（练习1）。 我们也可以先用cv2.namedWindow()创建一个窗口，之后再显示图片： 1234# 先定义窗口，后显示图片cv2.namedWindow('lena2', cv2.WINDOW_NORMAL)cv2.imshow('lena2', img)cv2.waitKey(0) 参数1依旧是窗口的名字，参数2默认是cv2.WINDOW_AUTOSIZE，表示窗口大小自适应图片，也可以设置为cv2.WINDOW_NORMAL，表示窗口大小可调整。图片比较大的时候，可以考虑用后者。 保存图片使用cv2.imwrite()保存图片： 1cv2.imwrite('lena_gray.jpg', img) Nice，是不是很简单呐，再接再厉噢(●’◡’●) 小结 cv2.imread()读入图片、cv2.imshow()显示图片、cv2.imwrite()保存图片 练习 打开lena.jpg并显示，如果按下’s’，就保存图片为’lena_save.bmp’，否则就结束程序 Matplotlib是Python中很重要的绘图库，请学习番外篇：Matplotlib显示图像 引用 本节源码 Getting Started with Images","categories":[{"name":"机器视觉","slug":"机器视觉","permalink":"http://ex2tron.coding.me/categories/机器视觉/"}],"tags":[{"name":"OpenCV","slug":"OpenCV","permalink":"http://ex2tron.coding.me/tags/OpenCV/"},{"name":"Python","slug":"Python","permalink":"http://ex2tron.coding.me/tags/Python/"},{"name":"图像处理","slug":"图像处理","permalink":"http://ex2tron.coding.me/tags/图像处理/"}]},{"title":"Python+OpenCV教程番外篇1：代码性能优化","slug":"Python-OpenCV教程番外篇1：代码性能优化","date":"2017-12-06T07:51:52.000Z","updated":"2018-01-19T06:08:20.571Z","comments":true,"path":"2017/12/06/Python-OpenCV教程番外篇1：代码性能优化/","link":"","permalink":"http://ex2tron.coding.me/2017/12/06/Python-OpenCV教程番外篇1：代码性能优化/","excerpt":"学习如何评估和优化代码性能。（本节还没更新完…………）","text":"学习如何评估和优化代码性能。（本节还没更新完…………） 完成一项任务很重要，高效地完成更重要。图像处理是对矩阵的操作，数据量巨大。如果代码写的不好，性能差距将很大，所以这节我们来了解下如何评估和提升代码性能。 评估代码运行时间123456import cv2start = cv2.getTickCount()# 这里写测试代码...end = cv2.getTickCount()print((end - start) / cv2.getTickFrequency()) 这段代码就是用来测量程序运行时间的（单位：s），其中cv2.getTickCount()函数得到电脑启动以来的时钟周期数，cv2.getTickFrequency()返回你电脑的主频，前后相减再除以主频就是你代码的运行时间（这样解释并不完全准确，但能理解就行）。另外，也可以用Python中的time模块计时： 123456import timestart = time.clock()# 这里写测试代码...end = time.clock()print(end - start) 经验之谈：如果你使用的是IPython或Jupyter Notebook开发环境，性能分析将会非常方便，详情请参考：Timing and Profiling in IPython 优化原则 数据元素少时用Python语法，数据元素多时用Numpy： 1234567x = 10z = np.uint8([10])# 尝试比较下面三句话各自的运行时间y = x * x * x # (1.6410249677846285e-06)y = x**3 # (2.461537451676943e-06)y = z * z * z # 最慢 (3.1179474387907945e-05) 所以Numpy的运行速度并不一定比Python本身语法快，元素数量较少时，请用Python本身格式。 尽量避免使用循环，尤其嵌套循环，因为极其慢！！！ 优先使用OpenCV/Numpy中封装好的函数 尽量将数据向量化，变成Numpy的数据格式 尽量避免数组的复制操作 引用 本节源码 Python Optimization Techniques Timing and Profiling in IPython Advanced Numpy","categories":[{"name":"机器视觉","slug":"机器视觉","permalink":"http://ex2tron.coding.me/categories/机器视觉/"}],"tags":[{"name":"OpenCV","slug":"OpenCV","permalink":"http://ex2tron.coding.me/tags/OpenCV/"},{"name":"Python","slug":"Python","permalink":"http://ex2tron.coding.me/tags/Python/"},{"name":"图像处理","slug":"图像处理","permalink":"http://ex2tron.coding.me/tags/图像处理/"}]},{"title":"Python+OpenCV教程1：简介与安装","slug":"Python-OpenCV教程1：简介与安装","date":"2017-12-06T07:50:59.000Z","updated":"2018-01-19T06:08:20.571Z","comments":true,"path":"2017/12/06/Python-OpenCV教程1：简介与安装/","link":"","permalink":"http://ex2tron.coding.me/2017/12/06/Python-OpenCV教程1：简介与安装/","excerpt":"本教程绝对浅显易懂，非常easy的辣，大家尽可放心食用！","text":"本教程绝对浅显易懂，非常easy的辣，大家尽可放心食用！ 我相信大部分人对Python进行图像处理的首要疑问是：它快吗？( ╯□╰ )，其次是它的应用平台和拓展性，下面我来为你解答这两个疑惑。 本教程翻译自OpenCV官方英文教程，我按照使用度和难易度翻译和重新编写，将不常用和较难的部分写成番外篇。每小节的源码、图片和练习题答案均可在引用处找到。虽然简单，但本教程依然需要你具备Python和图像处理的简单基础噢(⊙o⊙) Python照样快！众所周知，虽然Python语法简洁，编写高效，但相比C/C++运行慢很多。然而Python还有个重要特性：它是一门胶水语言！Python可以很容易地扩展C/C++。OpenCV-Python就是用Python包装了C++的实现，背后实际就是C++的代码在跑，所以代码的运行速度跟原生C/C++速度一样快，而且更加容易编写。 我举两个简单的例子就一目了然了：一个是读入图片，另一个是调整图片的对比度和亮度： 可以看到某些情况下Python的运行速度甚至好于C++，代码行数也直接少一半多！ 人生苦短，我用Python 如果你搞科研用，果断放弃C++（Matlab？出门左拐） 如果你是快速原型开发，验证方案，果断放弃C++ 如果你懒的配置OpenCV环境，果断放弃C++ 如果你的程序是在支持Python的较高硬件环境下运行，果断放弃C++ 如果你担心Python写不了界面，那是你的问题o_o …. 除非你的程序是MFC或已经用C++编写其他模块或是嵌入式设备，那就用C++吧，不过我仍然建议你进行模块式开发，如上层用其他语言，图像处理仍然用Python外部调用。 另外，图像是矩阵数据，OpenCV-Python原生支持Numpy，相当于Python的Matlab，为矩阵运算、科学计算提供了极大的便利性。“人生苦短，我用Python”，扔掉C/C++，开始OpenCV-Python吧！！！ 安装本教程编写时使用的软件版本是：OpenCV 3.x，Python 3.x。 如果你还没安装Python，强烈推荐安装Anaconda，它包含了大量的科学计算包，不用后期一个个安装。即使你已经装了Python也没有影响，Anaconda相当于虚拟环境，互不干扰。安装好之后，可以在cmd中输入python --version来查看Python的版本信息。 经验之谈：Windows版的Anaconda安装时，记得勾选Add Anaconda to my PATH environment variable，添加到环境变量中 要安装OpenCV，只需cmd下的一条指令： 1pip install opencv-python 要测试是否安装正确，打开Python的开发环境，输入import cv2，运行没有报错说明一切正常。要查看OpenCV的版本，可以： 1print(cv2.__version__) # '3.3.0' Python开发环境我用的是Visual Studio Code，也可以用PyCharm/Jupyter Notebook(Anaconda自带)等，自己习惯就行 常见安装问题： pip识别不了，说明环境变量中没有pip的目录。找到pip目录，添加到用户（或系统）变量的path中 如果下载速度很慢，可以点击此处下载离线版。下载完成后，cmd切换到下载的目录，输入pip install 文件名安装 引用 本节源码 OpenCV-Python Tutorials Numpy Quickstart Tutorial OpenCV Docs OpenCV 中文教程","categories":[{"name":"机器视觉","slug":"机器视觉","permalink":"http://ex2tron.coding.me/categories/机器视觉/"}],"tags":[{"name":"OpenCV","slug":"OpenCV","permalink":"http://ex2tron.coding.me/tags/OpenCV/"},{"name":"Python","slug":"Python","permalink":"http://ex2tron.coding.me/tags/Python/"},{"name":"图像处理","slug":"图像处理","permalink":"http://ex2tron.coding.me/tags/图像处理/"}]},{"title":"【片单】漫威宇宙电影合集","slug":"【片单】漫威宇宙电影合集","date":"2017-12-05T14:44:35.000Z","updated":"2018-03-15T07:43:52.335Z","comments":true,"path":"2017/12/05/【片单】漫威宇宙电影合集/","link":"","permalink":"http://ex2tron.coding.me/2017/12/05/【片单】漫威宇宙电影合集/","excerpt":"十年，17部电影，超过130亿美元的总票房，漫威宇宙电影合集下载！！！","text":"十年，17部电影，超过130亿美元的总票房，漫威宇宙电影合集下载！！！ Excelsior! ——斯坦·李 漫威电影宇宙MCU的成绩有目共睹，在十周年《复仇者联盟3》上映之前，来补一波吧！ 大部分片源来自人人影视字幕组，点击片名即可下载 MCU观影指南： 第一阶段 2008《钢铁侠1》、 2008《无敌浩克》 2010《钢铁侠2》 2011《雷神1》 2011《美国队长1：复仇者先锋》 2012《复仇者联盟1》 第二阶段 2013《钢铁侠3》 2013《雷神2：黑暗世界》 2014《美国队长2：冬日战士》 2014《银河护卫队1》 2015《复仇者联盟2：奥创纪元》 2015《蚁人》 第三阶段 2016《美国队长3：内战》 2016《奇异博士》 2017《银河护卫队2》 2017《蜘蛛侠：英雄归来》 2017《雷神3：诸神黄昏》 2018《复仇者联盟3：无限战争》(即将上映)","categories":[{"name":"谈电影","slug":"谈电影","permalink":"http://ex2tron.coding.me/categories/谈电影/"}],"tags":[{"name":"漫威","slug":"漫威","permalink":"http://ex2tron.coding.me/tags/漫威/"},{"name":"Marvel","slug":"Marvel","permalink":"http://ex2tron.coding.me/tags/Marvel/"},{"name":"复仇者联盟","slug":"复仇者联盟","permalink":"http://ex2tron.coding.me/tags/复仇者联盟/"}]},{"title":"【片单】007电影合集","slug":"【片单】007电影合集","date":"2017-12-05T13:53:37.000Z","updated":"2018-04-07T09:40:49.080Z","comments":true,"path":"2017/12/05/【片单】007电影合集/","link":"","permalink":"http://ex2tron.coding.me/2017/12/05/【片单】007电影合集/","excerpt":"作为风靡全球的一系列谍战电影，007怎能不看呢？007电影合集下载！","text":"作为风靡全球的一系列谍战电影，007怎能不看呢？007电影合集下载！ “My name is Bond, James Bond.” ——詹姆斯·邦德 目前为止，007系列电影已经有24部辣，六任邦德。 大部分片源来自人人影视字幕组，点击片名即可下载 肖恩·康纳利 1. 诺博士 (1962) 2. 来自俄罗斯的爱情 (1963) 3. 金手指 (1964) 4. 霹雳弹 (1965) 5. 雷霆谷 (1967) 7. 金刚钻 (1971) 乔治·拉赞贝 6. 女王密使 (1969) 罗杰·摩尔 8. 生死关头 (1973) 9. 金枪人 (1974) 10. 海底城 (1977) 11. 太空城 (1979) 12. 最高机密 (1981) 13. 八爪女 (1983) 14. 雷霆杀机 (1985) 提摩西·达顿 15. 黎明生机 (1987) 16. 杀人执照 (1989) 皮尔斯·布鲁斯南 17. 黄金眼 (1995) 18. 明日帝国 (1997) 19. 黑日危机 (1999) 20. 择日而亡 (2002) 丹尼尔·克雷格 21. 皇家赌场 (2006) 22. 量子危机 (2008) 23. 天幕杀机 (2012) 24. 幽灵党 (2015)","categories":[{"name":"谈电影","slug":"谈电影","permalink":"http://ex2tron.coding.me/categories/谈电影/"}],"tags":[{"name":"007","slug":"007","permalink":"http://ex2tron.coding.me/tags/007/"},{"name":"邦德","slug":"邦德","permalink":"http://ex2tron.coding.me/tags/邦德/"}]},{"title":"【片单】历届奥斯卡最佳动画长片集","slug":"【片单】历届奥斯卡最佳动画长片集","date":"2017-12-05T06:55:09.000Z","updated":"2018-01-04T14:00:27.944Z","comments":true,"path":"2017/12/05/【片单】历届奥斯卡最佳动画长片集/","link":"","permalink":"http://ex2tron.coding.me/2017/12/05/【片单】历届奥斯卡最佳动画长片集/","excerpt":"历届奥斯卡最佳动画长片合集下载！！！","text":"历届奥斯卡最佳动画长片合集下载！！！ Take her to the moon for me, okay? ——头脑特工队(Inside Out) 奥斯卡最佳动画长片奖设立于2002年，由当时的奥斯卡最佳动画奖细分出来。 天马行空的创意、顶级技术效果、发现生活的美好……都是我喜欢动画的原因。我一直很喜欢国内早期的动画片，三个和尚、小蝌蚪找妈妈和大闹天宫…然而国漫之后一直没啥起色。每次看到喜羊羊，熊出没，我就…同时好莱坞三大动画工作室，迪士尼（皮克斯）、梦工厂、蓝天工作室每年都在制作着世界顶级动画作品。而奥斯卡最佳动画长片更是代表了每年作品中的佼佼者。 大部分片源来自人人影视字幕组，点击片名即可下载 第89届奥斯卡最佳动画长片（2017）：疯狂动物城 第88届奥斯卡最佳动画长片（2016）：头脑特工队 第87届奥斯卡最佳动画长片（2015）：超能陆战队 第86届奥斯卡最佳动画长片（2014）：冰雪奇缘 第85届奥斯卡最佳动画长片（2013）：勇敢传说 第84届奥斯卡最佳动画长片（2012）：兰戈 第83届奥斯卡最佳动画长片（2011）：玩具总动员3 第82届奥斯卡最佳动画长片（2010）：飞屋环游记 第81届奥斯卡最佳动画长片（2009）：机器人总动员 第80届奥斯卡最佳动画长片（2008）：料理鼠王 第79届奥斯卡最佳动画长片（2007）：快乐的大脚 第78届奥斯卡最佳动画长片（2006）：超级无敌掌门狗-人兔的诅咒 第77届奥斯卡最佳动画长片（2005）：超人总动员 第76届奥斯卡最佳动画长片（2004）：海底总动员 第75届奥斯卡最佳动画长片（2003）：千与千寻 第74届奥斯卡最佳动画长片（2002）：怪物史瑞克","categories":[{"name":"谈电影","slug":"谈电影","permalink":"http://ex2tron.coding.me/categories/谈电影/"}],"tags":[{"name":"奥斯卡","slug":"奥斯卡","permalink":"http://ex2tron.coding.me/tags/奥斯卡/"},{"name":"动画","slug":"动画","permalink":"http://ex2tron.coding.me/tags/动画/"}]},{"title":"Brand7 2.0更名\"品牌漆\"正式上架咯！","slug":"Brand7-2-0更名品牌漆正式上架咯！","date":"2017-11-26T11:04:32.000Z","updated":"2017-12-20T09:20:00.144Z","comments":true,"path":"2017/11/26/Brand7-2-0更名品牌漆正式上架咯！/","link":"","permalink":"http://ex2tron.coding.me/2017/11/26/Brand7-2-0更名品牌漆正式上架咯！/","excerpt":"隔了一年更新，良心都有点痛了( ╯□╰ )","text":"隔了一年更新，良心都有点痛了( ╯□╰ ) 示威的人做的不对的话，引起示威的人呢？ ——《辩护人》 当初Brand7写完的时候，一直想写一个关于电影的APP，甚至做出了雏形：MovieBackdrops，可惜，时间不多，事情却很多。前段时间闭关，摸着自己的良心，终于把Brand7更新了一把，来看看更新内容吧： 品牌漆（Brand7）是一款Win10 UWP猜品牌的小游戏，里面涵盖了汽车、娱乐、时尚、生活、餐饮、科技、旅游七个类别的550个品牌。Ver2.0.1更新日志如下： 更名“品牌漆” 全新Logo 全新启动界面 新增50个品牌，现共550个品牌 全面中文版（英文被很多人吐槽看不懂( ╯□╰ )） 界面UI调整 可以在Win10应用商店中搜索“品牌漆”进行下载，或点击此处。","categories":[{"name":"Build篇","slug":"Build篇","permalink":"http://ex2tron.coding.me/categories/Build篇/"}],"tags":[{"name":"Brand7","slug":"Brand7","permalink":"http://ex2tron.coding.me/tags/Brand7/"},{"name":"品牌漆","slug":"品牌漆","permalink":"http://ex2tron.coding.me/tags/品牌漆/"}]},{"title":"软件+影视汁源贴(updating...)","slug":"软件-影视汁源贴-updating","date":"2017-11-15T11:53:46.000Z","updated":"2018-04-11T12:56:41.544Z","comments":true,"path":"2017/11/15/软件-影视汁源贴-updating/","link":"","permalink":"http://ex2tron.coding.me/2017/11/15/软件-影视汁源贴-updating/","excerpt":"经常有人跟我要一些软件和电影的资源，毕竟我是老司机( ╯□╰ )特此整理，有时间会不断更新。","text":"经常有人跟我要一些软件和电影的资源，毕竟我是老司机( ╯□╰ )特此整理，有时间会不断更新。 I’ve always believed with hard work and a little bit of luck, it’s only a matter of time before I’m discovered!我总是相信勤奋与努力外加一点点幸运就能换来成功，我的天分被发现只是时间的问题。——《Ratatouille》(《料理鼠王》) 软件汁源首先列出一些常用网站，后面我只列出常用的软件和官网，请大家优先选择官网进行下载，因为官网版本一般都是最新的，也比较安全。官网进不去，可以点击我给出的版本下载： 常用资源站 网易开源镜像站、淘宝 NPM 镜像站 Windows装机必备、精品绿色便携软件 俺下载、逛电驴、ED2000资源共享、善用佳软 微软官方系统 Windows 7 SP1：64位、32位 Windows 10创意者更新秋季版：64位、32位 激活工具：优先OEM10 密码：c6wz Office办公套件 2016：64位、32位 Visio：64位、32位 2013：64位、32位 Visio：64位、32位 2010：64位、32位 Visio：64位、32位 2016即点即用版：Office、Visio 激活工具：优先OEM10 密码：c6wz Linux系统 树莓派系统：官网、Rasbian 2017 Desktop Ubuntu：官网、桌面版：16.04 64位、17.10 64位 开发工具 Qt：官网、5.8.0 mingw Android Studio：中文社区、3.0、2.3.3 Visual Studio 2017：官网、社区版15.4 Matlab R2017a：x64 dvd1、x64 dvd2、破解工具 Octave：官网、4.2.2_x64、4.2.2_x86 Python：官网、3.6.4 x64、2.7.14 x64 Python包源（如Tensorflow）：源1、源2 Anaconda：官网、5.1.0_cp36_x64、5.1.0_cp36_x86 PyCharm：官网、2018.1 社区版 OpenCV：官网、3.3.1、2.4.13 | OpenCV-Python MySQL：官网、MySQL Installer 5.7.20 Navicat11 for MySQL：11.2 密码：ls2c WampServer：官网、3.1.0 x64、3.1.0 x86 代码编辑器： VS Code：1.21_x64、1.21_x86 | Notepad++：7.5.3 | Sublime Typora(Markdown编写)：官网(需翻墙)、64位、32位 开发组件：串口抓包AccessPort：1.37 | protobuf | ffmpeg 爬虫驱动： Firefox Geckodriver | MicrosoftWebDriver | ChromeDriver、各版本对照表 微软库 Microsoft Visual C++： 2005：x86、x64 2005 SP1：x86、x64 2008：x86、x64 2008 SP1：x86、x64 2010：x86、x64 2010 SP1：x86、x64 2012 Update1：x86、x64 2013：x86、x64 2015：x86、x64 Microsoft .NET Framework： 2.0：x86、x64 3.5：x86 3.5 SP1：x86、完整版 4：x86/x64、完整版 4.5：x86/x64、完整版 4.5.1：x86/x64、完整版 媒体设计 Adobe CC 2017(Photoshop/Audition/Premiere)：精简版 密码：f7yt 实用工具 Lantern蓝灯翻墙：最新版、官网 我平常整理的一些实用工具：密码：806j 影视汁源资源站 6v电影网、电影天堂、80s电影网 字幕组（原人人影视）、ED2000资源共享、飘花电影网 电影榜单 IMDB电影排行榜：TOP250、豆瓣电影排行榜：TOP250 全球电影票房排行榜：中文版、英文版 电影合集 漫威电影合集、007电影合集 诺兰电影合集、历届奥斯卡最佳动画长片合集","categories":[{"name":"谈电影","slug":"谈电影","permalink":"http://ex2tron.coding.me/categories/谈电影/"}],"tags":[{"name":"软件","slug":"软件","permalink":"http://ex2tron.coding.me/tags/软件/"},{"name":"影视","slug":"影视","permalink":"http://ex2tron.coding.me/tags/影视/"}]},{"title":"计量史：时间之旅","slug":"计量史：时间之旅","date":"2017-11-08T13:35:51.000Z","updated":"2017-12-20T09:20:00.129Z","comments":true,"path":"2017/11/08/计量史：时间之旅/","link":"","permalink":"http://ex2tron.coding.me/2017/11/08/计量史：时间之旅/","excerpt":"这篇文章也是我一年前研一《计量史》课上的小论文，感觉不错，也放在博客上，哈哈。","text":"这篇文章也是我一年前研一《计量史》课上的小论文，感觉不错，也放在博客上，哈哈。 Whoever find a friend, find a treasure. ——《Cars2》一个朋友，一个宝。——《汽车总动员2》 宇宙大爆炸的那一刻就注定了这个世界充满着平凡与不平凡，宇宙的变迁、星云的诞生，看似杂乱无章但又井然有序，一切都注入了时间的长河中。而随着一个奇迹：生命的诞生，人类意识、情感的快速升华，人类开始认识到了“时间”，并随着时间的流逝，逐渐认识这个世界。通过自然界的周期现象——日出日落，季节的轮换，潮汐的涨落，来有意识地进行活动。于是，当我们尝试去考量时间的时候，就促使了时间计量产生。作为《时间之谜》的阅读报告，我摘录了一部分原书材料来表述时间计量的科学演变，最后结合自己的经历和见识表达了自己对科学研究和时间计量意义的一些想法。 时间，从来就不是一个很好形容或定义的概念。每当我们想去探讨它时，总会陷入困境，就像有人让你解释你是怎么走路的一样。《时间之谜》 从实用和客观的角度探讨了时间计量的科学演变。通过人们尝试对时间进行测定的手段、时间的使用以及时间对于数学、物理学、天文学的影响等各种客观事实材料，来启发我们对于时间的思考。 I. “时间”的科学演变如今，科学一词早已被大众所认知，并赋予崇高的含义。我想大多数人孩童时候的梦想就是成为一名科学家。而Science一词最早出现在19世纪，像牛顿当时被称为自然哲学家，而非科学家。可以看出，科学溯源于大自然规律的必然性。那么“时间”从哪儿来的呢？ 远古人民往往利用自然界的周期现象——日出日落，季节轮换，甚至潮汐的涨落来进行着人类的日常生活。我小时候在家乡的时候，就是鸡鸣时刻起床，黄昏时刻结束农耕作业。不同于现在城市的生活，那时的我们并不会过分关注具体的“钟表时间”。这种主导人们规律作息生活的自然之力，无疑引起了远古人们对它的神秘、畏惧和崇拜之感。于是，人们内心的欲望和探索心理驱动着我们去开始去关心天文和自然。 然而时间不同于长度、质量或温度，“我们能辨别距离，感受到重量和温度，但人体的任何感官都不能感知时间，我们见不到它，听不到它，嗅不到它，也尝不到它，而只能通过意识，或者通过观测它的效应来理解它。”（《时间之谜》）观测，这就是最开始单纯的“自然界的钟”的产生，也就是通过有意识地观测太阳、月亮和星星的这种大的、显式的运动，来确立时间的原型。之后人们认识到了运动的规律，产生了能否利用以恒定速率运转物体的时间间隔来对时间单位进行计数的问题，于是便有了“钟”。中国古代出现的利用水的推动力造的水钟、十四世纪出现的利用重锤驱动的机械钟以及惠更斯研制的摆钟等等都是探索过程中朝着精密性、易用性的改进。随着人们对自然界的深入了解，特别是对电、磁和物质的原子结构的了解，诸如石英钟、原子钟等一些新的方案得以发展和实现。 现在再去回顾历史，很容易就可以看出时间计量对工业、科学研究和当今世界诸多事务的影响。约翰•哈里逊时钟克服了海洋的颠簸、温度变化和咸水的溅射，大大改善了船只导航。对晶体谐振频率的研究有了如今改变世界的半导体。从“定性上的为什么”到“定量上的多准确”的科学演变，促使了精密测量的需求，进而影响到了数学、物理学、天文学……那么如今的我们需要再去思考“时间”吗？ II. 阿尔法到欧米伽（始与终）太过普世、默会的科学往往会被我们所忽略掉。拿起杯子喝口水，对于人来说，无疑再简单不过，但如果要造一个可以端起杯子喝水的机器人呢？显然，这是一个相对有难度并且复杂的任务，其中所涉及到的运动学、控制学、人体工程学等等科学知识都不是随便说说那么简单。因此，回溯历史能够使我们对那些在日常生活中扮演着最基本角色的事物产生认知，并进一步引领我们去思考。时间，它就扮演着使得人类的一切活动有秩序、有组织地进行着的角色。我想试图去了解时间，可以帮助我们更好的规划工作和生活。 虽然当今社会的物质财富已经相对丰富，但大多数人却丧失了求真求知，我们经常被当下的现实琐碎问题所困。这种局限使得人们疲于现实，而缺少创造和求知的勇气。假设我们可以做一次时间的旅行，“水母、鳄鱼胚胎、星云、犹他州的峡谷和木卫三；第一缕生命的信号、细菌、细胞起源、初恋感觉、意识诞生、人类进化、生与死。”（纪录片《时间之旅》）从宇宙大爆炸的那一刻开始到人类高级智慧的诞生，就注定了人类在漫漫时间长河中探索和认识这个世界的过程。在这个漫长的过程中，时间见证了无数人的探索求真精神，有始有终，从阿尔法到欧米伽，驱动着人类的进步。 我想时间就是一个很好的例子，来溯源支配当今社会行为准则的起源与内涵。正如同天平这种衡器的诞生以及后人对它的不断改进与完善，就是人们对公平与公正追求的一种体现。这种以此来扩充我们见识的过程，有助于锻炼我们的思维，突破一些困扰我们的现实问题，尝试新思路，并最终试图解决我们一直在思考的问题：自我存在。起码这种思维方法对我自己很有帮助：我是工作后考的研究生。考研期间，我没有用智能手机，由于一个人很难坚持下来，于是尝试每天早上7：15到7：45期间用静坐的方式来保持心态的平和。这种方法却意外之外了我的一笔人生财富，因为静坐的时候，我会尝试去想一些平静的事，慢慢地就会回忆起那些很久之前早就遗忘的事情。我想那个时候我就在进行着一趟回溯自己的时间之旅。每件事，好的，坏的都有始有终，总会过去，自己的心态也就变得好起来。静坐之后，洗漱完，8点准时出发，开始一天的学习生活……到现在读研期间，我依旧保持了考研时的一些习惯。 III. 结束语正如同泰伦斯•马力克执导的纪录片《时间之旅》所传达的哲学信息：“如果你在寻找上帝，仔细观察时间的一切就够了。”我想这就是时间对我们个体的意义。","categories":[{"name":"五味杂粮","slug":"五味杂粮","permalink":"http://ex2tron.coding.me/categories/五味杂粮/"}],"tags":[{"name":"计量","slug":"计量","permalink":"http://ex2tron.coding.me/tags/计量/"},{"name":"时间之旅","slug":"时间之旅","permalink":"http://ex2tron.coding.me/tags/时间之旅/"}]},{"title":"摄影之魅：瞬间是一面\"镜子\"","slug":"摄影之魅：瞬间是一面镜子","date":"2017-11-08T12:56:32.000Z","updated":"2017-12-20T09:20:00.144Z","comments":true,"path":"2017/11/08/摄影之魅：瞬间是一面镜子/","link":"","permalink":"http://ex2tron.coding.me/2017/11/08/摄影之魅：瞬间是一面镜子/","excerpt":"这篇文章其实是我一年前研一《摄影艺术》课上的小论文，感觉写的还行，放在博客上。","text":"这篇文章其实是我一年前研一《摄影艺术》课上的小论文，感觉写的还行，放在博客上。 Not everyone can become a great artist, but a great artist can come from anywhere. ——《Ratatouille》并非是谁都能成为伟大的艺术家，不过伟大的艺术家却可能来自任何角落。——《料理鼠王》 19世纪30年代末期，达盖尔发明银版照相法，尼埃普斯拍摄了世界上第一张照片，影像开始可以被记录下来。卢米埃尔兄弟在《火车进站》中开启了24帧的艺术之旅——“电影”。如今，影像无处不在，传递着无穷无尽、千变万化的讯息。这一切都源于定格影像的瞬间——摄影术的独特魅力。 I. 艺术源于生活、艺术高于生活在选修“摄影艺术”这门课程之前，我刚刚入手了一款入门级单反：宾得PENTAX K-50。本着对摄影的爱好，在入手单反之前就经常用手机去拍一些小东西。所以，理所当然，选修这门课程就是希望自己能够拍出“好看”的照片，即追求表意上的拍摄技法。最初，刚接触摄影的我迫切想积累诸如快门、光圈、感光度、景深、构图等等各种专业术语。不可否认的是，这种“量”的层面上的堆积确实有助于提升拍摄认知和水平，但往往会也会束缚我们，缺少创造力、缺少对摄影“质”的理解。自己对摄影的认知也停留在肤浅的“这张照片拍的好，但说不出所以然来”上面。很高兴，这门课程改变了我的很多想法。 人是爱“美”的。如今，拍照是一件及其简单的事。一方面，得益于智能手机的发展，我们只需要按下手机上的拍照按钮，就会捕获一张照片，接近零成本。另一方面，由于拍摄的简便性，对生活中事物的记录变得极其频繁，这某种程度上降低了我们独立思考和赏析的能力。我们往往会赞美一张“好看”的照片，被照片所表现出来的第一观感所牵引，有些人虽然会对拍摄的技法做一些分析，获取经验，但却极少表达对照片的理解。并且，这些赞美和分析通常都只是建立在一张“美”的照片上。之所以强调了多次“美”的照片，是因为摄影不仅仅只是最终呈现出的照片的观感，摄影更多的含义是一个过程，这一过程的目的往往是真实地或艺术地反映出现实，并表现出拍摄者的情感寄托。当然，摄影术发明的目的就是代替画像，它源于生活，更是高于生活，因此，摄影是个庞杂的体系，前面的理解或许只是一种粗浅的认识。对于不同的摄影类别，诸如纪实摄影、风光摄影、商业时尚摄影等等，摄影都有不同的目的和表现方式，但摄影本身又是绝对的自由，它代表这一种艺术、创造力和想象力。 规则是用来打破的，但打破规则之前，我们必需清楚这个规则。得益于课堂之上邱老师介绍的各类摄影大师以及他们的作品，我了解了很多摄影的历史和大师级摄影师的风格。他们能够在摄影史上留下名字，通常都是某种风格的开创者，有着自己个性鲜明的摄影语言并对一个时代产生深远的影响。 II. 以小见大，“决定性瞬间”——布列松 “摄影这一门，你进去时是ABC，出来时是HCB（Henri Cartier-Bresson：亨利·卡蒂埃·布列松）”——《日本摄影》杂志。 其实，对于一位被冠以“他的摄影定义了20世纪”、“新闻摄影之父”称号的大师级摄影师来说，无需多言。然而布列松提出的“决定性瞬间”的摄影艺术确确实实让我略微滤清了以往杂乱无章的“瞬间”摄影认知。在此之前，我一直很崇尚抓拍。可能是因为最初自己并不是特别了解一些摄影技法，在拍摄一些故事性很强的场景时，拍出的照片通常描述或还原不了那一时刻的故事。很多时候，摆拍的人物表情很不自然，一般也表现不出很强的故事性。“决定性瞬间”：“在一秒钟的很小一部分中，以一种精确的形式呈现出某一事件的重要性，使它成为这一事件的最恰当的描述。”布列松的作品总是恰到好处地抓住了事件最微妙的一瞬间。这或许与他自身的经历大大相关。 布列松曾前往法国的非洲殖民地科特迪瓦并以打猎为主。在打猎的过程中，他形成了贯穿他一生的摄影技巧——准备，等待，等待，等待…，最后扣动扳机（按下快门）。这一过程，造就了布列松面对巨大压力之下的沉着和冷静。他的作品就仿佛一直等在主体那里拍摄这一场景一般，这均得益于布列松的耐心、完美的拍摄时刻和一种无人可以匹敌的直觉。 《布列松习作》(上图)作为布列松的一幅名作，一方面以其娴熟的抓拍功底丰富而自然地表现出拍摄瞬间的故事性：小男孩情绪十分自然，踌躇满志的抱着两个大酒瓶回家，身后的小女孩也投来羡慕的目光…另一方面，这幅作品也很好的体现了布列松的摄影理念：“不论一幅作品技术多么到位，画面多么“好看”，如果它远离了爱，远离了对人类的理解，远离了对人类命运的认知，那么它一定不是一件成功的作品。”布列松的镜头虽然对准的是现实小场景，但他的立意高远，致力于以小见大，“最小的事物可以成为伟大的主题”。 III. 瞬间是一面“镜子” 摄影大师的作品中往往呈现出非常鲜明的个性特征，赋予了其作品与众不同的表现力和故事性。摄影师在按下快门的那一刻，CCD/CMOS上接收的那些信号就变成了一张转瞬即逝一瞬间的记录。通常，摄影师抓拍的那一刻场景，很难再去复现，再加之摄影师独特的拍摄手法和艺术风格，使得每一张照片都变得独一无二，这也是瞬间反映的价值所在。因此，当我们去鉴赏这些作品、这些瞬间时，我们会被其表现出的感染力所吸引，《饥饿的苏丹》带给我们巨大的震撼，《时代广场的胜利》让我们体验到二战胜利的狂喜……。当然很多作品所表现出来的往往并不是“好看”的第一观感，它就如同一面可以窥视我们人类、社会、自然各种善恶丑美的镜子。直面这样的一面镜子，我们不免会产生强烈的情感冲击，因为这样的作品并不是单纯的、好看的、无意义的，而是承载着某些人文情怀和哲学思考。当我们深刻去理解它的时候，理所当然就会被其所揭示的内在所折服。 不过，摄影终归是自由的表现力、创造力的象征，这也是摄影术的魅力所在。我们需要不断学习和模仿经典作品的拍摄，但却不能有所束缚，当深刻地了解了这些规则后，就可以尝试打破这些规则，形成自己的风格！ “Not everyone can become a great artist, but a great artist can come from anywhere.”, “Everyone Can Cook！”（《料理鼠王》电影台词） “摄影艺术”这门课程改变了我很多的认识和想法，或许最大的感受便是：“Everyone Can Shoot！”每个人都有对其生活环境、人生观、世界观、价值观的独特理解，每个人也都可以拿起手中的设备拍出自己独特的风格。对大师作品的品鉴和艺术赏析都有助于提升自身的艺术品位，但关键在于去拍、去学习、去发现、去创造。我想这门课程给了我信心可以站在巨人的肩膀上努力拍出自己的作品，毕竟摄影是自由的，这才是摄影术之魅力！","categories":[{"name":"五味杂粮","slug":"五味杂粮","permalink":"http://ex2tron.coding.me/categories/五味杂粮/"}],"tags":[{"name":"摄影","slug":"摄影","permalink":"http://ex2tron.coding.me/tags/摄影/"},{"name":"布列松","slug":"布列松","permalink":"http://ex2tron.coding.me/tags/布列松/"}]},{"title":"小白深度学习笔记3：浅层神经网络","slug":"小白深度学习笔记3：浅层神经网络","date":"2017-10-13T07:15:18.000Z","updated":"2017-12-20T09:20:00.144Z","comments":true,"path":"2017/10/13/小白深度学习笔记3：浅层神经网络/","link":"","permalink":"http://ex2tron.coding.me/2017/10/13/小白深度学习笔记3：浅层神经网络/","excerpt":"logistic回归可以看作是只有1层1个神经元的神经网络，那么一般的神经网络是怎么样的呢？","text":"logistic回归可以看作是只有1层1个神经元的神经网络，那么一般的神经网络是怎么样的呢？ 因为国民不富裕就不能受法律保护，就不能享受民主，这种说法我是无法接受的。 ——《辩护人》 本文是我在观看吴恩达老师的《神经网络和深度学习》视频课程时，相关的笔记整理，大佬勿喷！ 神经网络前面学习了logistic回归，可以把logistic看作只有1层1个神经元的神经网络，如下图： 这个神经元做两个操作： 计算\\(z=w^Tx+b\\) 计算\\(\\hat{y}=a=\\sigma(z)\\) 而一般的神经网路包括输入层、隐藏层和输出层。如下图所示，是一个两层神经网络。层数从隐藏层(Hidden Layer)开始算，也就是这个图中，第1层是隐藏层，第2层是输出层(Output Layer)。可以把输入层(Input Layer)称为第0层。 浅层神经网络是相较于深层神经网络而言的，深层神经网络中，隐藏层的个数&gt;=2，层数越多，也就越深。 激活函数如果把2层的神经网络看作是logistic回归的堆叠的话，那么这个神经网络的正向传播应该是下面这样的公式： $$z^{[1]}=W^{[1]}x+b^{[1]}\\tag{1}$$$$a^{[1]}=\\sigma(z^{[1]})\\tag{2}$$$$z^{[2]}=W^{[2]}x+b^{[2]}\\tag{3}$$$$a^{[2]}=\\sigma(z^{[2]})\\tag{4}$$ 其中，sigmoid函数就是激活函数(Activation Function)。激活函数不一定是sigmoid函数，有的非线性函数要比sigmoid函数更好，这里介绍两种：tanh和ReLU。 tanhtanh(Hyperbolic Tangent Function)双曲正切函数，\\(a=tanh(z)=\\frac{e^z-e^{-z}}{e^z+e^{-z}}\\)。tanh往往比sigmoid表现更好，从上图中可以看出，这个激活函数的平均值更接近于0。但是输出层如果是二类分类的话，结果要么是0要么是1，那么我们预测值应该介于0~1之间，所以这种情况下，输出层的激活函数依然用sigmoid函数。 ReLU如果仔细观察sigmoid和tanh函数曲线的话，就会发现，自变量z比较大或比较小时，这个函数的斜率就会很小，接近于0，这样会拖慢梯度下降法的速度。所以，另外一个经常使用到的激活函数是ReLU(Rectified Linear Unit)。\\(a=max(0,z)\\)，z为正时，导数为1，z为负时，导数为0。 所以，总结三种激活函数， 一般不使用sigmoid做激活函数，除非是二类分类，可用在输出层 tanh普遍效果要比sigmoid更好 最常用的默认激活函数是ReLU 正向传播如果我们选择tanh作为激活函数的话，开头那个2层神经网络的正向传播就是： $$Z^{[1]}=W^{[1]}X+b^{[1]}\\tag{1}$$$$A^{[1]}=tanh(Z^{[1]})\\tag{2}$$$$Z^{[2]}=W^{[2]}X+b^{[2]}\\tag{3}$$$$A^{[2]}=tanh(Z^{[2]})\\tag{4}$$ 反向传播反向传播的推导跟logistic回归一样，只不过进行两次： $$dZ^{[2]}=A^{[2]}-Y\\tag{1}$$$$dW^{[2]}=\\frac{1}{m}dZ^{[2]}A^{[1]^T}\\tag{2}$$$$db^{[2]}=\\frac{1}{m}np.sum(dZ^{[2]},axis=1,keepdims=True)\\tag{3}$$$$dZ^{[1]}=W^{[2]^T}dZ^{[2]}*tanh^{’[1]}(Z^{[1]})\\tag{4}$$$$dW^{[1]}=\\frac{1}{m}dZ^{[1]}X^T\\tag{5}$$$$db^{[1]}=\\frac{1}{m}np.sum(dZ^{[1]},axis=1,keepdims=True)\\tag{6}$$ 随机初始化之前在logistic回归中，我们可以将权重W初始化为0，但是对于神经网络而言，W都初始化为0的话，是无效的。 举例来说，对于上图中的神经网络，隐藏层神经元个数是2，如果W全部初始化为0的话，那么： $$ W^{[1]}= \\begin{bmatrix} 0 &amp; 0 \\newline 0 &amp; 0 \\end{bmatrix}$$ 因为\\(z^{[1]}=W^{[1]}x+b\\)，这样的话\\(z_1^{[1]}=z_2^{[1]}\\)，\\(a_1^{[1]}=a_2^{[1]}\\)，也就是说，两个神经元的功能完全一样，计算相同的值，这样1个神经元和n个神经元对神经网络的作用是一样的，其他n-1个是多余的。 所以，在神经网络的参数初始化中，权重W是不能全部初始化为0的，b的话无所谓，都可以。","categories":[{"name":"深度学习","slug":"深度学习","permalink":"http://ex2tron.coding.me/categories/深度学习/"}],"tags":[{"name":"神经网络","slug":"神经网络","permalink":"http://ex2tron.coding.me/tags/神经网络/"}]},{"title":"numpy中几种矩阵的乘法","slug":"numpy中几种矩阵的乘法","date":"2017-10-11T02:26:09.000Z","updated":"2017-12-20T09:20:00.129Z","comments":true,"path":"2017/10/11/numpy中几种矩阵的乘法/","link":"","permalink":"http://ex2tron.coding.me/2017/10/11/numpy中几种矩阵的乘法/","excerpt":"最近在手动实现神经网络模型的时候，老是混淆numpy中几种矩阵乘法区别，所以特此记录一下。","text":"最近在手动实现神经网络模型的时候，老是混淆numpy中几种矩阵乘法区别，所以特此记录一下。 With great power comes great responsibility ——《Spider-Man》能力越大，责任越大。——《蜘蛛侠》 首先，这里规定一下，我们用numpy定义矩阵时全部采用标准的形式，举例如下： 12345678import numpy as np# 不推荐的方式a = np.array([1,2,3])print(a.shape)# 推荐的方式b = np.array([[1,2,3]])print(b.shape) 上面代码a的形状是(3,)，b的形状(1,3)，即1行3列的一个矩阵。 np.dotnp.dot(A,B)就是实现同线性代数里面的矩阵乘法，也就是说，A的列数要等于B的行数才可以相乘： 12345import numpy as npa = np.array([[1,2,3],[4,5,6]])b = np.array([[1],[2],[3]])print(np.dot(a,b)) a是(2,3)，b是(3,1)，所以输出结果是：[[14], [32]]。 np.multiplynp.multiply(A,B)和A*B效果一样，实现对应位置元素相乘。 12345678910111213import numpy as np# 示例一a = np.array([[1,2,3]])b = np.array([[4,5,6]])print(a*b)print(np.multiply(a,b))# 示例二c = np.array([[1,2,3],[4,5,6]])d = np.array([[1],[2]])print(c*d)print(np.multiply(c,d)) 示例一输出结果是[[4 10 18]]，即[[1*4 2*5 3*6]]。示例二输出结果是[[1 2 3], [8 10 12]]，这里涉及到一个numpy中广播的概念：因为c是(2,3)，而d是(2,1)，为了实现对应元素相乘，numpy会把d的列复制扩展成(2,3)，于是就有了上面的结果。 np.innernp.inner(A,B) 实现A,B的内积，要求A,B矩阵最后一维是相同的，如果是2维矩阵，即A,B矩阵的列数要相同。 12345import numpy as npa = np.array([[1,2,3]])b = np.array([[4,5,6]])print(np.inner(a,b)) 结果为[[32]]，即1*4 + 2*10 + 3*6。 np.outernp.outer(A,B)即A,B的外积： 12345import numpy as npa = np.array([[1,2,3]])b = np.array([[4,5,6]])print(np.outer(a,b)) 结果为[[4 5 6], [8 10 12], [12 15 18]]，即[[1*4 1*5 1*6], [2*4 2*5 2*6], [3*4 3*5 3*6]]。","categories":[{"name":"Build篇","slug":"Build篇","permalink":"http://ex2tron.coding.me/categories/Build篇/"}],"tags":[{"name":"Python","slug":"Python","permalink":"http://ex2tron.coding.me/tags/Python/"},{"name":"numpy","slug":"numpy","permalink":"http://ex2tron.coding.me/tags/numpy/"},{"name":"矩阵","slug":"矩阵","permalink":"http://ex2tron.coding.me/tags/矩阵/"}]},{"title":"Python+OpenCV教程（目录）","slug":"Python-OpenCV教程（目录）","date":"2017-10-10T14:22:13.000Z","updated":"2018-01-19T06:08:20.571Z","comments":true,"path":"2017/10/10/Python-OpenCV教程（目录）/","link":"","permalink":"http://ex2tron.coding.me/2017/10/10/Python-OpenCV教程（目录）/","excerpt":"","text":"图文版 | 简洁版 入门篇 简介与安装（了解安装OpenCV-Python） | 番外篇1：代码性能优化 基本元素-图片（图片载入/显示/保存） | 番外篇2：Matplotlib显示图像 打开摄像头（打开摄像头捕获图片/播放保存视频） | 番外篇3：滑动条 图像基本操作（访问像素点/ROI/通道分离合并） 颜色空间转换（颜色空间转换/追踪特定颜色物体） 阈值分割（阈值分割/二值化） | 番外篇4：Otsu阈值法 图像几何变换（旋转/平移/缩放/仿射变换/透视变换） 绘图功能（画线/画圆/画矩形/添加文字） | 番外篇5：鼠标绘图 基础篇 图像混合（算数运算/混合/按位运算） | 番外篇6：亮度与对比度 平滑图像（卷积/滤波/模糊/降噪） | 番外篇7：卷积基础(图片边框) 边缘检测（Canny/Sobel） | 番外篇8：图像梯度 腐蚀与膨胀（形态学操作/腐蚀/膨胀/开运算/闭运算） 轮廓 （寻找/绘制轮廓） | 番外篇9：轮廓层级 轮廓特征 （面积/周长/最小外接矩(圆)/形状匹配） | 番外篇10：凸包及更多轮廓特征 直方图（计算绘制直方图/均衡化） 模板匹配（大图中找小图） 霍夫变换（提取直线/圆）","categories":[{"name":"机器视觉","slug":"机器视觉","permalink":"http://ex2tron.coding.me/categories/机器视觉/"}],"tags":[{"name":"OpenCV","slug":"OpenCV","permalink":"http://ex2tron.coding.me/tags/OpenCV/"},{"name":"Python","slug":"Python","permalink":"http://ex2tron.coding.me/tags/Python/"},{"name":"图像处理","slug":"图像处理","permalink":"http://ex2tron.coding.me/tags/图像处理/"}]},{"title":"小白深度学习笔记2：Python实现logistic回归","slug":"小白深度学习笔记2：Python实现logistic回归","date":"2017-10-09T01:52:11.000Z","updated":"2017-12-20T09:20:00.144Z","comments":true,"path":"2017/10/09/小白深度学习笔记2：Python实现logistic回归/","link":"","permalink":"http://ex2tron.coding.me/2017/10/09/小白深度学习笔记2：Python实现logistic回归/","excerpt":"上一篇了解了一些logistic回归的原理，现在我们用Python实现一个用于鉴别是否是一张猫的图片的分类器！","text":"上一篇了解了一些logistic回归的原理，现在我们用Python实现一个用于鉴别是否是一张猫的图片的分类器！ 本文是我在观看吴恩达老师的《神经网络和深度学习》视频课程时，相关的笔记整理，大佬勿喷！ You’re not worried？ Would it help？ ——《Bridge of Spies》你不担心吗？有用吗？——《间谍之桥》 首先，回顾一下，logistic回归其实就相当于只有一层的最简单的神经网络，如下图，正向传播计算出预测值和成本函数，而反向传播计算出的dw和db： p.s.本文其实是吴恩达老师第二周教程的作业，没答案，这里提供我写的，仅供参考！ 导入包首先import我们要使用的包，其中lr_utils和数据样本点此处下载： 1234567import numpy as npimport matplotlib.pyplot as pltimport h5pyimport scipyfrom PIL import Imagefrom scipy import ndimagefrom lr_utils import load_dataset 得到样本集我们的训练样本和测试样本都在前面下载的文件中： 12# 加载样本train_set_x_orig,train_set_y,test_set_x_orig,test_set_y,classes = load_dataset() 因为我们直接加载的样本集还需要进行处理，所以变量名上加了_orig。此时，train_set_x_orig中的每一个元素就是一副图片，可以用下面的方式让它显示出来： 1234# 显示第11张图片plt.figure()plt.imshow(train_set_x_orig[10])plt.show() 如果打印出train_set_x_orig的形状，结果为：(209,64,64,3)。可知训练样本的个数m_train=209，图片的宽和高都是num_px=64。 1print(train_set_x_orig.shape) 还记得上一篇中提到如果把图片量化吗？如果图片的维数是(num_px,num_px,3)，我们要变成(num_px*num_px*3,1)的形状。也就是说要把形状为(a,b,c,d)的矩阵变成形状数组为(b*c*d,a)的矩阵数组，这里可以用下面的一个小技巧： 1X_flatten = X.reshape(X.shape[0], -1).T 12train_set_x_flatten = train_set_x_orig.reshape(train_set_x_orig.shape[0],-1).Ttest_set_x_flatten = test_set_x_orig.reshape(test_set_x_orig.shape[0],-1).T 编写神经网络的代码中经常出现的错误便是把矩阵的维数搞错，所以随时可以通过shape属性进行检查，经过上面的语句后，train_set_x_flatten的形状应该是(12288,209)，test_set_x_flatten的形状应该是(12288,50)。 因为像素值最大是255，为了避免数据过大，可以将数据归一化得到最终的训练/测试集样本： 12train_set_x = train_set_x_flatten/255test_set_x = test_set_x_flatten/255 编写各个模块sigmoid函数这里注意python自带math模块中的exp函数和numpy中的exp函数的区别，math.exp是没有广播功能的，不适合此处的矩阵运算。123def sigmoid(x): s = 1/(1+np.exp(-x)) return s 测试：1print(sigmoid(np.array([0,2]))) 结果应为[0.5 0.88079708] 初始化w和b因为logistic回归相当于只有一个输出层的神经网络，根据上一篇的分析，w的形状是(nx,1)，b的形状是(1,1)，这里我们统一初始化为0：1234def initialize_with_zeros(dim): w = np.zeros([dim,1]) b = 0. return w, b 正/反向传播这里的函数就是本文开头那张图上显示的正向传播和反向传播：1234567891011121314def propagate(w, b, X, Y): m = X.shape[1] # 正向传播 A = sigmoid(np.dot(w.T,X)+b) # 成本函数 cost = -np.sum(Y*np.log(A)+(1-Y)*np.log(1-A),axis=1)/m cost = np.squeeze(cost) # 反向传播 dw = np.dot(X,(A-Y).T)/m db = np.sum(A-Y,axis=1)/m grads = &#123;\"dw\":dw,\"db\":db&#125; return cost,grads 测试：123w,b,X,Y = np.array([[1],[2]]),2,np.array([[1,2],[3,4]]),np.array([[1,0]])cost,grads = propagate(w,b,X,Y)print(cost,grads) 结果应为：6.000064773192205 {&#39;dw&#39;: array([[0.99993216], [ 1.99980262]]), &#39;db&#39;: array([0.49993523])} 优化器反向传播完，我们需要更新w，b的值，即应用梯度下降法进行优化： 12345678910111213141516171819def optimize(w,b,X,Y,num_iterations,learning_rate,print_cost=False): costs = [] for i in range(num_iterations): cost,grads = propagate(w,b,X,Y) dw = grads['dw'] db = grads['db'] # 更新w和b的值 w = w-learning_rate*dw b = b-learning_rate*db # 每隔100次，记录下成本函数的值 if(i%100 == 0): costs.append(cost) if(print_cost): print(\"cost after iteration %i:%f\"%(i,cost)) params=&#123;'w':w,'b':b&#125; grads=&#123;'dw':dw,'db':db&#125; return params,grads,costs 测试：12params, grads, costs = optimize(w, b, X, Y, num_iterations= 100, learning_rate = 0.009, print_cost = False)print(params,grads,costs) 结果应为{&#39;w&#39;: array([[0.1124579 ],[0.23106775]]), &#39;b&#39;: array([ 1.55930492])} {&#39;dw&#39;: array([[ 0.90158428],[1.76250842]]), &#39;db&#39;: array([ 0.43046207])} [array(6.000064773192205)] 预测函数通过优化器得到w和b参数之后，就可以用这两个参数预测X了，如果预测值&gt;=0.5，那结果就为1，即是一张有猫的图片，反之，结果为0，是一张没有猫的图片： 123456789def predict(w,b,X): m = X.shape[1] Y_predictions = np.zeros([1,m]) A = sigmoid(np.dot(w.T,X)+b) for i in range(A.shape[1]): Y_predictions[0,i] = 1 if A[0,i]&gt;=0.5 else 0 return Y_predictions 分类模型这样我们就编写好了所有的模块了，最后，把它们整合在一起，就是logistic回归的二类分类模型了：12345678910111213141516171819202122def model(X_train,Y_train,X_test,Y_test,num_iterations=2000,learning_rate=0.5,print_cost=False): w,b = initialize_with_zeros(X_train.shape[0]) params,grads,costs = optimize(w,b,X_train,Y_train,num_iterations,learning_rate,print_cost) w = params['w'] b = params['b'] Y_prediction_test = predict(w,b,X_test) Y_prediction_train = predict(w,b,X_train) print(\"train accuracy:&#123;&#125; %\".format(100-np.mean(np.abs(Y_prediction_train-Y_train))*100)) print(\"test accuracy:&#123;&#125; %\".format(100-np.mean(np.abs(Y_prediction_test-Y_test))*100)) d = &#123;\"costs\": costs, \"Y_prediction_test\": Y_prediction_test, \"Y_prediction_train\" : Y_prediction_train, \"w\" : w, \"b\" : b, \"learning_rate\" : learning_rate, \"num_iterations\": num_iterations&#125; return d 现在，可以把我们真正的样本数据传入这个模型，看它最后训练的结果：1d = model(train_set_x, train_set_y, test_set_x, test_set_y, num_iterations = 2000, learning_rate = 0.005, print_cost = True) 如果一切正常，会打印出最后模型在训练集和测试集上的准确率：12train accuracy:99.04306220095694 %test accuracy:70.0 % 验证和分析结果可以看到当前的训练结果其实是过拟合的，测试集上的准确率并不高，但暂时足够了。我们可以显示和打印出真实的图片结果进行对比。比如说这里我们打开测试集上的第5张图片，并将学习率曲线画出来：123456789index = 4plt.imshow(test_set_x[:,index].reshape([num_px,num_px,3]))print(\"real result = \"+str(test_set_y[0,index])+\" and your predict = \"+str(d['Y_prediction_test'][0,index]))plt.figure()plt.plot(np.squeeze(d['costs']))plt.ylabel('cost')plt.xlabel('iterations(per hundreds)')plt.title(\"learning rate = \"+str(d['learning_rate']))plt.show() 最后，源代码中包含了一段针对不同的学习率得到不同的训练结果的代码，大家可以参考下噢！~ o(￣▽￣)o 本文源代码：python_implement_logistic_regression.py","categories":[{"name":"深度学习","slug":"深度学习","permalink":"http://ex2tron.coding.me/categories/深度学习/"}],"tags":[{"name":"神经网络","slug":"神经网络","permalink":"http://ex2tron.coding.me/tags/神经网络/"},{"name":"logistic","slug":"logistic","permalink":"http://ex2tron.coding.me/tags/logistic/"}]},{"title":"【利器篇】GitKraken：顶级酷炫Git图像化客户端","slug":"【利器篇】GitKraken：顶级酷炫Git图像化工具","date":"2017-10-05T09:33:20.000Z","updated":"2017-12-20T09:20:00.144Z","comments":true,"path":"2017/10/05/【利器篇】GitKraken：顶级酷炫Git图像化工具/","link":"","permalink":"http://ex2tron.coding.me/2017/10/05/【利器篇】GitKraken：顶级酷炫Git图像化工具/","excerpt":"不喜欢敲命令？那么这款酷炫的Git客户端让你逼格满满！","text":"不喜欢敲命令？那么这款酷炫的Git客户端让你逼格满满！ 真正的忘记是不需要努力的。——《大鱼海棠》 首先废话一段：以前我上班的时候，公司里的SCM用的是perforce，你应该、可能没听过( ╯□╰ )。总之，就是集中式版本管理系统，相比于git的分布式有很多缺陷，具体可以看廖雪峰的这篇文章：“集中式vs分布式”。但作为一款商业软件，perforce提供的优秀客户端体验还是相当不错的。使用git后，一直都是敲命令的，一是因为习惯，毕竟码代码逼格高嘛，二是因为git的GUI客户端要不很丑，要不功能捉急，总之不想用。之后，在微博上看到这款软件，又同类似的SourceTree相比体验了一下，无奈，我，还是喜欢颜值高的~ o(￣▽￣)o另外，以前外教老师提问说《加勒比海盗2》中的那个怪物叫啥，阅片无数的我，那天竟然没回答上，装逼失败，所以对这只“挪威海怪kraken”影响特别深刻。好了，开始正题吧，扯远了~ 官网/下载：GitKraken GitKraken对Windows/Linux/Mac三大主流平台都支持，其方便之处在于，它不需要安装配置，双击打开就可以了。打开之后，可以选择用Github账号登陆，需要Github授权： 打开/克隆/初始化GitKranken支持打开本地仓库，从指定的URL或Github、Gitlab、Bitbucket等上面直接克隆。前面我们已经用Github直接登陆了，所以，从Github克隆时，会直接列出你当前的所有仓库项目，非常方便。当然，也可以连接到Gitlab/Bitbucket平台： 初始化/新建项目也非常方便，在Init选项中，可以选择初始化一个本地仓库或类似Github之类的远程仓库。GitKraken初始化时还提供了.gitignore的文件的相关模板： 界面/功能打开一个仓库后，主界面如下图，酷炫简洁，顶部提供了常用的Git功能，就不细说了。我主要提及一下，如何进行版本差分： 在提交日志的主界面，如果要比较任意两个版本之间的差分，按住Ctrl键，选择要比较的版本，右边会自动列出两个版本之间所修改的文件，点击文件就可以看到diff了： 当然，最新版本（本文使用的是3.1版本）的GitKraken提供了Merge和Diff工具的自定义（File-Preferences-General中设置），比如说我最常用的Merge工具是WinMerge，就可以在这里配置。 抛砖引玉，大致介绍了一下，其实熟悉Git的话，这个工具使用起来还是蛮简单的~ o(￣▽￣)o","categories":[{"name":"利器篇","slug":"利器篇","permalink":"http://ex2tron.coding.me/categories/利器篇/"}],"tags":[{"name":"Git","slug":"Git","permalink":"http://ex2tron.coding.me/tags/Git/"},{"name":"GitKraken","slug":"GitKraken","permalink":"http://ex2tron.coding.me/tags/GitKraken/"}]},{"title":"小白深度学习笔记1：logistic回归","slug":"小白深度学习笔记1：logistic回归","date":"2017-10-02T13:06:32.000Z","updated":"2017-12-20T09:20:00.144Z","comments":true,"path":"2017/10/02/小白深度学习笔记1：logistic回归/","link":"","permalink":"http://ex2tron.coding.me/2017/10/02/小白深度学习笔记1：logistic回归/","excerpt":"开启神经网络与深度学习之坑！","text":"开启神经网络与深度学习之坑！本篇内容包含部分数学公式，需要用MathJax脚本渲染，所以页面需等待加载完成后，才可完整显示公式。 When life ends up breathtakingly fucked, you can generally trace it back to one big, bad decision.——《DeadPool》当你的生活变成一坨屎的时候，通常都是因为你当时做的傻逼决定。——《死侍》 本文是我在观看吴恩达老师的《神经网络和深度学习》视频课程时，相关的笔记整理，大佬勿喷！ 二类分类比如说分析一张图片中有猫还是没猫，这就是一个二类分类（Binary Classification）问题。这里，我们用输出y=1表示有猫，y=0表示没有猫。输入是一张图片，做过图像处理的同学应该知道图片是以RGB三个矩阵存储的，把RGB三分量的值提取出来，作为X，如下图： 那么当有m个样本时，X就是一个(nx,m)，即nx行、m列的矩阵，而输出Y的形状（形状就是指矩阵的行数和列数）是(1,m)。 logistic回归logistic回归（Logistic Regression）就是一个用于二类分类的学习算法：假定给出输入的特征向量\\(x_1\\)（如一张图片），我们希望程序给出一个预测值\\(\\hat{y}\\)，它指出这张图片中有猫还是没猫的概率，即：$$\\hat{y}=P(y=1\\ or\\ 0\\mid x)$$ 既然\\(\\hat{y}\\)是一个概率，那么\\(\\hat{y}\\in[0,1]\\)。如果按照线性回归，输出值应该是：\\(\\hat{y}=w^Tx+b\\)，w形状是(nx,1)，b形状是(1,1)，但是这个值可能远比1大或者出现负数，所以，需要用一个sigmoid函数做限定，最终输出为：$$\\hat{y}=\\sigma(w^Tx+b)$$ 观察sigmoid函数\\(\\sigma(z)=\\frac{1}{1+e^{-z}}\\)的曲线图： \\(z\\rightarrow\\infty,\\sigma(z)\\rightarrow1;z\\rightarrow-\\infty,\\sigma(z)\\rightarrow0;z=0,\\sigma(z)=0.5\\) 损失函数既然我们的目标就是训练得到logistic回归函数中的w和b参数，那么怎么衡量算法的运行情况呢？我们可以用损失函数（Loss Function）L表示预测值与真值的接近程度。最简单的损失函数可以定义成\\(L(\\hat{y},y)=\\hat{y}-y\\)。但是不会这样用，因为要考虑到优化算法的运算速度和效率，排除多个局部最优解。一般，损失函数定义为：$$L(\\hat{y},y)=-[y\\log\\hat{y}+(1-y)\\log(1-\\hat{y})]$$ 显然，损失函数越小，结果越好。那么这个损失函数如何起作用的呢？ 假设真值y=1，那么上式就会变成：\\(L(\\hat{y},1)=-\\log\\hat{y}\\)，要让损失函数尽量小，那么\\(\\log\\hat{y}\\)尽量大，也就是说\\(\\hat{y}\\)尽量大，由于\\(\\hat{y}\\in[0,1]\\)，所以，这个损失函数会使预测值\\(\\hat{y}\\)尽量接近1，即真值。同样，大家可以推一下真值y=0的情况。 成本函数前面所说的损失函数是针对单个训练样本定义的，我们可以用成本函数（Cost Function）来定义全体训练样本上的算法运行情况，定义如下：$$J(w,b)=\\frac{1}{m}\\sum_{i=1}^mL(\\hat{y^i},y^i)$$ 梯度下降法好，到这里，先总结一下： logistic回归模型是用于二类分类的一种学习算法 损失函数衡量参数w和b在单个训练样本的效果 成本函数衡量参数w和b在全体训练样本的效果 训练目标：找到使成本函数J尽可能小的参数w和b 那么w和b参数是怎么调整的呢？为了说明梯度下降法（Gradient Descent），吴恩达老师假定w和b都是实数，那么J(w,b)的函数图形类似下图： 一般，先随机初始化w和b，然后朝着最快下降的方向不断按下面的公式调整w和b参数，最后得到最优解（:=表示更新w的值）： $$w:=w-\\alpha\\frac{dJ(w,b)}{dw}$$$$b:=b-\\alpha\\frac{dJ(w,b)}{db}$$ \\(\\alpha\\)成为学习率（Learning Rate），表示梯度下降法的步长。 好了，这就是相关的logistic回归的简单理论笔记。","categories":[{"name":"深度学习","slug":"深度学习","permalink":"http://ex2tron.coding.me/categories/深度学习/"}],"tags":[{"name":"神经网络","slug":"神经网络","permalink":"http://ex2tron.coding.me/tags/神经网络/"},{"name":"logistic","slug":"logistic","permalink":"http://ex2tron.coding.me/tags/logistic/"}]},{"title":"【算法贴】三点定位算法","slug":"【算法贴】三点定位算法","date":"2017-09-29T10:58:31.000Z","updated":"2017-12-20T09:20:00.144Z","comments":true,"path":"2017/09/29/【算法贴】三点定位算法/","link":"","permalink":"http://ex2tron.coding.me/2017/09/29/【算法贴】三点定位算法/","excerpt":"已知三个点的坐标和未知点到这三个点的距离，求未知点？","text":"已知三个点的坐标和未知点到这三个点的距离，求未知点？ 过去的如果就这么过去了，以后只会越来越糟。——《驴得水》 p.s.本文引用了mathjax脚本用来显示数学公式，所以需等待加载完成才能显示正常。 算法解析如下图所示，以三个已知点为圆心，d1,d2,d3为半径作圆，交点便是要求解的未知点： 刚开始百度了一下，各种稀奇的算法，包括将三角形平移、旋转啥的，其实不用这么麻烦，直接通过勾股定理死算就可以了。 $$(x_1-x_0)^2+(y_1-y_0)^2=d_1^2$$ $$(x_2-x_0)^2+(y_2-y_0)^2=d_2^2$$ $$(x_3-x_0)^2+(y_3-y_0)^2=d_3^2$$ 将上面三个式子展开： $$x_1^2+x_0^2-2x_0x_1+y_1^2+y_0^2-2y_0y_1=d_1^2 ①$$$$x_2^2+x_0^2-2x_0x_2+y_2^2+y_0^2-2y_0y_2=d_2^2 ②$$$$x_3^2+x_0^2-2x_0x_3+y_3^2+y_0^2-2y_0y_3=d_3^2 ③$$ 显然通过三个式子中的任意两个相减，比如①-③和②-③就可以得到两个未知数的两个式子： $$x_1^2-x_3^2-2x_0(x_1-x_3)+y_1^2-y_3^2-2y_0(y_1-y_3)=d_1^2-d_3^2$$$$x_2^2-x_3^2-2x_0(x_2-x_3)+y_2^2-y_3^2-2y_0(y_2-y_3)=d_2^2-d_3^2$$ 接下来就不用说了，其实这都是初中数学的问题( ╯□╰ ) 算法实现CSharp根据上面的推导，我们的算法就很好写了。先定义一个Point的结构体或类，然后编写一个函数，将已知的三个点和三个距离传入： 12345678910111213141516171819202122232425262728293031/// &lt;summary&gt;/// 定义Point结构体/// &lt;/summary&gt;public struct Point&#123; public double X; public double Y;&#125;static Point GetMobilePoint(Point p1, Point p2, Point p3, double d1, double d2, double d3)&#123; //相当于①式-③式 double A = p1.X - p3.X; double B = p1.Y - p3.Y; double C = Math.Pow(p1.X, 2) - Math.Pow(p3.X, 2) + Math.Pow(p1.Y, 2) - Math.Pow(p3.Y, 2) + Math.Pow(d3, 2) - Math.Pow(d1, 2); //相当于②式-③式 double D = p2.X - p3.X; double E = p2.Y - p3.Y; double F = Math.Pow(p2.X, 2) - Math.Pow(p3.X, 2) + Math.Pow(p2.Y, 2) - Math.Pow(p3.Y, 2) + Math.Pow(d3, 2) - Math.Pow(d2, 2); //计算结果 double x0 = (B * F - E * C) / (2 * B * D - 2 * A * E); double y0 = (A * F - D * C) / (2 * A * E - 2 * B * D); Point resultPoint; resultPoint.X = x0; resultPoint.Y = y0; return resultPoint;&#125;","categories":[{"name":"Build篇","slug":"Build篇","permalink":"http://ex2tron.coding.me/categories/Build篇/"}],"tags":[{"name":"三角定位","slug":"三角定位","permalink":"http://ex2tron.coding.me/tags/三角定位/"}]},{"title":"构建：变量","slug":"构建：杀死变量","date":"2017-09-28T13:23:45.000Z","updated":"2018-04-09T08:36:37.427Z","comments":true,"path":"2017/09/28/构建：杀死变量/","link":"","permalink":"http://ex2tron.coding.me/2017/09/28/构建：杀死变量/","excerpt":"如果你仔细回想一下，平日阅读代码的时候，是什么占用了你大量的时间和精力？毫无疑问：变量。","text":"如果你仔细回想一下，平日阅读代码的时候，是什么占用了你大量的时间和精力？毫无疑问：变量。 Why do we fall, Bruce? So we can learn to pick ourselves up. ——《Batman Begins》我们为何会跌倒？这样我们才可以学会自己爬起来。——《蝙蝠侠：侠影之谜》 如果一个变量在代码中很分散，阅读者在同一时间内考虑的代码行数势必会增加，编写者引入Bug的概率也会增大。那么，该如何从减少变量的作用域角度提高代码质量呢？ 本文内容是我阅读《代码大全：表驱动法p411》时的笔记，加入了自己的案例和总结。 变量跨度与存活时间建议一：把对变量的引用尽可能集中在一起，使变量局部化12345a = 0; b = 0;c = 0;a = b + c;b += 1; 跨度（span）是衡量变量不同引用点靠近程度的一种方法。比如说上面的代码，对a的第一次引用和第二次引用之间有2行代码，那么变量a的跨度就是2。引用多次的话，可以取平均跨度。如b的第一次和第二次引用之间行数为1，第二次和第三次引用之间行数为0，所以平均跨度span(b)=(1+0)/2=0.5。 另外一个概念是：存活时间（live time）。跟跨度类似，不过存活时间只跟变量第一次和最后一次引用有关。比如对于上面代码中的b变量，跨度是0.5，但是存活时间是4条语句。 显然，我们的目标就是缩短变量的跨度和存活时间。如果用这两个概念考察全局变量，就会发现全局变量的跨度和存活时间都很长，这也是为什么避免使用全局变量的原因之一。 减小作用域的建议建议二：把相关语句放在一起把变量的引用点集中在一起，使代码易于自上而下的阅读，举例来说： 12345678910111213141516//跳来跳去的糟糕代码MarketingData marketingData;SalesData salesData;TravelData travelData;travelData.ComputeWeekly();salesData.ComputeWeekly();marketingData.ComputeWeekly();salesData.ComputeAnnually();travelData.ComputeAnnually();marketingData.ComputeAnnually();salesData.print();travelData.print();marketingData.print(); 显然，如果你要想知道marketingData的计算流程，就必须在这段代码的不同行数跳跃。所以，这样组织代码会更好： 123456789101112131415//组织良好，从上而下阅读MarketingData marketingData;marketingData.ComputeWeekly();marketingData.ComputeAnnually();marketingData.print();SalesData salesData;salesData.ComputeWeekly();salesData.ComputeAnnually();salesData.print();TravelData travelData;travelData.ComputeWeekly();travelData.ComputeAnnually();travelData.print(); 《代码大全》中介绍了一种简便的检查相关语句是否组成得当的方法，把你的代码片段打印出来，然后把相关的语句画上框，组织得当的话， 这些框是不会重叠的： 建议三：把相关语句提取成单独的子程序更短的子程序相比长的子程序，变量的跨度和存活时间更小。比如，可以尝试这样重构上面的代码： 123456//重构，提取子程序ComputeMarketingData();ComputeSalesData();ComputeTravelData(); 建议四：开始使用最小的作用域，然后根据需求再扩展一句话解释就是：把全局变量转换为成员局部变量要比局部变量转换为全局变量难的多。因此，在设计程序时，如果对变量的作用域犹豫不决时，优先倾向于最小的作用域。 建议五：循环开始之前再去初始化循环变量一个不好的编程习惯就是在程序开头初始化好循环所使用的变量，如int i = 0,j = 0;。而在很后面才使用到循环。这样做的坏处一是查看循环时需要跳到开头才知道循环变量的值，另外，如果要修改这个循环，往往会忘记同时修改循环变量。 往期【构建法】系列回顾： 构建法、单点控制 构建法、表驱动法","categories":[{"name":"Build篇","slug":"Build篇","permalink":"http://ex2tron.coding.me/categories/Build篇/"}],"tags":[{"name":"构建法","slug":"构建法","permalink":"http://ex2tron.coding.me/tags/构建法/"},{"name":"变量","slug":"变量","permalink":"http://ex2tron.coding.me/tags/变量/"},{"name":"作用域","slug":"作用域","permalink":"http://ex2tron.coding.me/tags/作用域/"}]},{"title":"【片单】诺兰神作集","slug":"【片单】诺兰神作集","date":"2017-09-24T12:37:41.000Z","updated":"2017-12-20T09:07:45.763Z","comments":true,"path":"2017/09/24/【片单】诺兰神作集/","link":"","permalink":"http://ex2tron.coding.me/2017/09/24/【片单】诺兰神作集/","excerpt":"有的导演，虽然没拿过奥斯卡，作品不多，但每部却都被影迷奉为神作，没错，说的就是诺神。","text":"有的导演，虽然没拿过奥斯卡，作品不多，但每部却都被影迷奉为神作，没错，说的就是诺神。：克里斯托弗·诺兰 克里斯托弗·诺兰今天周末，回顾了下诺神的蝙蝠侠和盗梦空间，加上前段时间刚看完敦刻尔克，按耐不住，就分享下诺兰的神作电影下载链接吧。 大部分片源来自人人影视字幕组，作品按时间倒序，点击片名即可下载。 敦刻尔克 | Dunkirk 星际穿越 | Interstellar 蝙蝠侠：黑暗骑士崛起 | The Dark Knight Rises 盗梦空间 | Inception 蝙蝠侠：黑暗骑士 | The Dark Knight 致命魔术 | The Prestige 蝙蝠侠.侠影之谜 | Batman Begins 记忆碎片 | Memento p.s.本文所有的图片均来自TMDB，如果你觉得很酷炫的话，我会在后期开发一款专门下载影视壁纸的APP，敬请期待！","categories":[{"name":"谈电影","slug":"谈电影","permalink":"http://ex2tron.coding.me/categories/谈电影/"}],"tags":[{"name":"诺兰","slug":"诺兰","permalink":"http://ex2tron.coding.me/tags/诺兰/"}]},{"title":"【利器篇】七牛云——用做每月免费10G的图床","slug":"【利器篇】七牛云：用做每月免费10G的图床","date":"2017-09-18T11:55:38.000Z","updated":"2017-12-20T09:20:00.144Z","comments":true,"path":"2017/09/18/【利器篇】七牛云：用做每月免费10G的图床/","link":"","permalink":"http://ex2tron.coding.me/2017/09/18/【利器篇】七牛云：用做每月免费10G的图床/","excerpt":"随着越来越多的人开始使用Markdown写自己的独立博客，一个好用稳定的图床是必不可少的了。","text":"随着越来越多的人开始使用Markdown写自己的独立博客，一个好用稳定的图床是必不可少的了。 对比在七牛云之前，我使用过国外的Cloud App和阿里云的oss对象存储。 首先，国外的东西在国内稳定性和速度都是相对较差的，我试着在阿里云和Cloud App上上传同一张图片并生成外链，Cloud App要比阿里的加载速度延迟1-2s，阿里基本秒开。 阿里的oss对象存储虽然很稳定，但是并不提供免费的空间。相对来说，七牛云提供的每月10G免费流量，对于博客来说，绰绰有余了。 另外，七牛云提供了诸多的图片处理接口，如水印、格式转换、缩放等，很实用，很强大。 使用注册并登陆七牛云，在七牛云的产品列表中，添加一个对象存储，如这里取名为picblog： 创建好之后，七牛云会自动生成一个测试域名： 这个域名就是你文件的前缀了。比如，我们点击内容管理，点击上传文件，选择一幅图片上传。上传完成后，复制该文件的外链地址： 这个地址就是你的图片地址辣，你可以在浏览器中访问该地址，比如你可以访问我的这个：mysql_demo 绑定域名添加二级域名如同前面那张图上所说，七牛云默认的测试域名有很多限制。所以，你如果已经购买了域名的话，可以在这里绑定自己的二级域名，这样既好记又方便管理。 比如，这里我已经在万网上购买了ex2tron.xin的域名，这里我演示如何将七牛云的存储空间绑定pic.ex2tron.xin这个域名。 在七牛云的存储空间页面，点击绑定域名，只需要在加速域名处填写要绑定的域名，其他项保持默认即可：1加速域名： pic.ex2tron.xin 创建后，系统会配置一段时间，等待处理完成，会显示一个诸如xxx.qiniudns.com的CNAME记录值，记下此值，后面要用到。 添加域名解析打开万网的域名控制台，添加一条CNAME的解析：1234记录类型：CNAME主机记录：pic记录值：xxx.qiniudns.com# 其他选型保持默认 这样，你上传的图片外链就是：http://pic.ex2tron.xin/filename.png之类的了。 添加图片样式利用七牛云做图床的另外一个强大之处在于丰富的图片样式。点击图片样式-新建图片样式，七牛云提供了如下很多种场景： 比如，这里我们选择指定宽高，强行缩放+打图片水印，然后添加一个文字水印，可以调整文字的字体样式，位置等等： 调整好之后，为样式取个名称，如webpic，这样，只要在原来外链的后面添加-webpic就可以了： 1http://pic.ex2tron.xin/filename.png-webpic 其中-这个连接符可以通过存储空间控制面板的样式分隔符设置中进行修改。 图床工具对于七牛云，每张图片都在网页端上传还是比较麻烦的，所以用一些图床客户端工具会更加快速。 这里推荐使用MPic图床神器。打开软件后，设置好自己的AK和SK（可在七牛云的个人中心-密钥管理中看到）。MPic支持文件拖拽上传，点击复制就可以复制外链，非常方便：","categories":[{"name":"利器篇","slug":"利器篇","permalink":"http://ex2tron.coding.me/categories/利器篇/"}],"tags":[{"name":"七牛","slug":"七牛","permalink":"http://ex2tron.coding.me/tags/七牛/"},{"name":"图床","slug":"图床","permalink":"http://ex2tron.coding.me/tags/图床/"}]},{"title":"Hexo+Github Pages轻松搭博客(2)：在Github上部署","slug":"Hexo-Github-Pages轻松搭博客-2：在Github上部署","date":"2017-09-13T12:15:47.000Z","updated":"2017-12-20T09:20:00.144Z","comments":true,"path":"2017/09/13/Hexo-Github-Pages轻松搭博客-2：在Github上部署/","link":"","permalink":"http://ex2tron.coding.me/2017/09/13/Hexo-Github-Pages轻松搭博客-2：在Github上部署/","excerpt":"使用免费的Github Pages服务或者部署在自己服务器上，别人就可以访问你的博客啦！","text":"使用免费的Github Pages服务或者部署在自己服务器上，别人就可以访问你的博客啦！ 如果你已经有配置好的云服务器，直接可以将Hexo博客生成的public目录文件放在服务器上就好了。比如我购买的是阿里云服务器（apache），只需要将public下的文件放在/var/www/html/下面就可以用你服务器地址访问博客了。很容易，不过，考虑到云服务器的价格，这里我们还是用免费的Github吧。 关联Github首先登陆Github，没有账号的话，先注册一个。新建一个名为username.github.io的仓库，username必须与你的账户名相同，比如我的就是ex2tron.github.io，这就是你博客的域名地址了（绑定独立域名之后再说）。新建时注意勾选”Initialize this repository with a README“，因为这个仓库必须不能为空。 如果你是git新用户的话，推荐看：廖雪峰的Git教程-远程仓库 接下来打开博客目录下的_config.yml配置文件，定位到最后的deploy选项，修改如下：1234deploy: type: git repository: git@github.com:ex2tron/ex2tron.github.io.git branch: master 注意冒号后面有个空格，不然会出错滴~~~配置好之后，使用下面的命令就可以部署到Github上了：123$ hexo clean$ hexo g$ hexo d 这样通过Github提供的域名地址（如我的：https://ex2tron.github.io）就可以访问你的博客了，简单快速高效！ 发布新博客博客搭建起来之后，就可以用Markdown写博客辣，使用下面的命令，创建新博客（如名为：我的第一篇博客）：1$ hexo new '我的第一篇博客' 此命令会在博客目录\\source_posts\\h下生成“我的第一篇博客.md”文件，这就是你的博客源文件啦，文件开头如下，记得冒号后面有空格噢，不然会出错：12345---title: 我的第一篇博客date: 2017-09-13 20:15:47tags: #文章标签，格式：[1,2,3]--- 不熟悉Markdown语法的可以看：Markdown 语法说明。写完之后依然使用之前的三条命令发布：123$ hexo clean$ hexo g$ hexo d 后面两条指令也可以简化为一条：1$ hexo g -d 常出现的问题 在hexo d进行部署时，如果出现ERROR Deployer not found: git的问题，可以先用下面的命令修复： 1$ npm install hexo-deployer-git --save 如果你没配置过ssh导致部署失败（可以通过ssh -T username@example.com来测试ssh有无配置成功），可以参考这篇文章：针对github权限导致hexo部署失败的解决方案","categories":[{"name":"Build篇","slug":"Build篇","permalink":"http://ex2tron.coding.me/categories/Build篇/"}],"tags":[{"name":"Hexo","slug":"Hexo","permalink":"http://ex2tron.coding.me/tags/Hexo/"},{"name":"Github","slug":"Github","permalink":"http://ex2tron.coding.me/tags/Github/"}]},{"title":"Hexo+Github Pages轻松搭博客(1)","slug":"Hexo-Github-Pages轻松搭博客-1","date":"2017-09-13T08:07:06.000Z","updated":"2017-12-20T09:20:00.144Z","comments":true,"path":"2017/09/13/Hexo-Github-Pages轻松搭博客-1/","link":"","permalink":"http://ex2tron.coding.me/2017/09/13/Hexo-Github-Pages轻松搭博客-1/","excerpt":"想用Github Pages轻松搭建自己的博客，用Hexo，10分钟！","text":"想用Github Pages轻松搭建自己的博客，用Hexo，10分钟！ 废话区域：我在接触Hexo（可以读作Hack So）之前，绝对没少尝试建立一个完全自由、自己说了算的独立博客：WordPress定位重量级，功能强大，生成的是动态网站，依赖数据库……太繁琐了，放弃~而Jekyll和Hexo都是静态建站工具，但Jekyll的依赖项也很多，也不简约，不想用~最后才是名气相对不高的Hexo，相信我，熟练的情况下，10分钟就可以搭出来： 简介Hexo是一个免费的静态Blog生成工具。简单来说，就是把你写的Markdown博客文件生成静态网页，把这个网页放在Github或者你自己的服务器上就可以快速访问了。软件界，从来不缺自动化工具(ง •_•)ง 安装官网文档：Hexo Docs Hexo安装前，你的电脑上需要先有下面这两个东西： Node.js Git 如果已经安装了的话，命令行下一句话就好啦： 1$ npm install -g hexo-cli 初始化博客目录在你的本地新建一个存放博客的目录，比如”D:\\MyHexoBlog“，然后在这个目录右键，选择”Git Bash Here“，输入下面两条命令进行初始化： 12$ hexo init$ npm install 初始化完成之后，你的目录结构应该是这样的： 12345678.├── _config.yml├── package.json├── scaffolds├── source| ├── _drafts| └── _posts└── themes 如果没有出错的话，继续执行下面的指令启动服务： 12$ hexo g $ hexo s 启动之后，在浏览器中访问：http://localhost:4000/，是不是看到了漂亮的Hexo博客页面了。不过目前这个博客还是运行在你本机上的，下篇我们看一下怎么样让别人也能访问这个博客。 引用 Hexo Docs Hexo+Github搭建个人博客(一)——开始搭建","categories":[{"name":"Build篇","slug":"Build篇","permalink":"http://ex2tron.coding.me/categories/Build篇/"}],"tags":[{"name":"Hexo","slug":"Hexo","permalink":"http://ex2tron.coding.me/tags/Hexo/"},{"name":"Github","slug":"Github","permalink":"http://ex2tron.coding.me/tags/Github/"}]},{"title":"【利器篇】用VS Code写Markdown","slug":"【利器篇】用VSCode写Markdown","date":"2017-09-11T07:11:22.000Z","updated":"2017-12-20T09:20:00.144Z","comments":true,"path":"2017/09/11/【利器篇】用VSCode写Markdown/","link":"","permalink":"http://ex2tron.coding.me/2017/09/11/【利器篇】用VSCode写Markdown/","excerpt":"Markdown以其简洁、优雅整齐的风格，成为目前非常流行的博客文件格式。甚至有人说：每个人都应该用Markdown写博客","text":"Markdown以其简洁、优雅整齐的风格，成为目前非常流行的博客文件格式。甚至有人说：每个人都应该用Markdown写博客。关于Markdown相较富文本的优势，我就不细说了。 Markdown编辑器支持Markdown的工具有很多，大家可以参考网上，如这篇文章：码字必备：18 款优秀的 Markdown 写作工具 | 2015 年度盘点。就我自己目前在Windows上使用的而言有：简书、有道云笔记、Typora、VSCode 简书本身就是一个博客平台，有道云笔记是类似OneNote和印象笔迹的应用。如果你已经在使用这两个平台的话，就不用多说了。但如果只是想用一个单纯的Markdown编辑器的话，推荐极致简洁的Typora。虽说界面简洁，但功能强大，不仅内置了常见的一些Markdown样式，还支持PDF/HTML等多种格式导出： 你是一枚文青的话，千万不要错过这款编辑器。不过，对于程序猿来说，VSCode才显得更有味道。 用VSCode写MarkdownVSCode就不过多介绍了，我之前也写过关于它的介绍： Visual Studio Code Preview初体验 Visual Studio Code Preview深度体验、使用技巧 现在版本的VSCode默认已经支持Markdown预览，不需要下载插件。用VSCode打开md文件或将当前文件更改为Markdown格式就可以开始书写了： VSCode支持两种预览方式： 按下Ctrl+K V，像上图一样左右同步实时预览 按下Ctrl+Shift+V，只预览最终渲染结果 如上图，编写和预览界面是实时同步的，不需要的话，可以按下Ctrl+,组合键，添加如下两条设置： 12\"markdown.preview.scrollEditorWithPreview\": false,\"markdown.preview.scrollPreviewWithEditorSelection\": false 另外，目前VSCode预览样式中，中文的显示很别扭，这里推荐下载Github风格的CSS 下载完成后，配置css文件的设置如下即可： 123\"markdown.styles\": [ \"file:///D:/markdown-github.css\"] 另外，VSCode中有很多Markdown相关的插件，如”Markdown All in One”和”Markdown Theme Kit”等，大家可以下载下来尝试一下哈！ 引用Markdown editing with Visual Studio Code","categories":[{"name":"利器篇","slug":"利器篇","permalink":"http://ex2tron.coding.me/categories/利器篇/"}],"tags":[{"name":"Markdown","slug":"Markdown","permalink":"http://ex2tron.coding.me/tags/Markdown/"},{"name":"VSCode","slug":"VSCode","permalink":"http://ex2tron.coding.me/tags/VSCode/"}]},{"title":"【利器篇】MyCLI：自动补全和语法高亮的MySQL命令行工具","slug":"【利器篇】MyCLI：自动补全和语法高亮的MySQL命令行工具","date":"2017-09-11T06:32:14.000Z","updated":"2017-12-25T15:17:44.463Z","comments":true,"path":"2017/09/11/【利器篇】MyCLI：自动补全和语法高亮的MySQL命令行工具/","link":"","permalink":"http://ex2tron.coding.me/2017/09/11/【利器篇】MyCLI：自动补全和语法高亮的MySQL命令行工具/","excerpt":"mycli是MySQL命令行工具，支持关键字语法高亮和自动补全，看上面的动图你就知道了。","text":"mycli是MySQL命令行工具，支持关键字语法高亮和自动补全，看上面的动图你就知道了。 mycli不仅会提示MySQL的关键字，更牛掰的是数据库名、表名、字段名都可以提示，非常方便。如果你经常在命令行里码MySQL命令，相信这款工具一定会让你满意。 官网：MyCLI 安装其实mycli是一个Python的包，所以你已经安装了Python(pip)的话，用下面一条指令就好了： 1pip install mycli 如果出现问题，可以参考官网，有详细的说明。 使用安装好之后，在cmd下，将以往登陆MySQL用的mysql换成mycli就可以了： 好了，大家觉得好用的话，欢迎扩散噢！ Never give up. Never stop fighting. Excelsior!","categories":[{"name":"利器篇","slug":"利器篇","permalink":"http://ex2tron.coding.me/categories/利器篇/"}],"tags":[{"name":"MyCLI","slug":"MyCLI","permalink":"http://ex2tron.coding.me/tags/MyCLI/"},{"name":"MySQL","slug":"MySQL","permalink":"http://ex2tron.coding.me/tags/MySQL/"}]},{"title":"博客新篇章！Brave New World","slug":"博客新篇章！","date":"2017-08-23T12:56:32.000Z","updated":"2017-11-16T14:33:08.434Z","comments":true,"path":"2017/08/23/博客新篇章！/","link":"","permalink":"http://ex2tron.coding.me/2017/08/23/博客新篇章！/","excerpt":"从2014/08/23在lofter上写我的第一篇博客开始，已经过去了整整三年……","text":"从2014/08/23在lofter上写我的第一篇博客开始，已经过去了整整三年…… 再见，lofterlofter是一个非常不错的轻博客平台，我喜欢它的设计和定位。但lofter终究不适合程序猿，长久以来不支持markdown也让我很头痛。现在，终于还是要说再见了! http://ex2tron.lofter.com 旧的66篇博客【Code/编程/开发】构建法、单点控制 构建法、表驱动法 【云端漫步】一起上“阿里云”（1）、购买学生党套餐 【云端漫步】一起上“阿里云”（2）、远程登陆服务器 【云端漫步】一起上“阿里云”（3）、LAMP环境搭建 【云端漫步】一起上“阿里云”（4）、搭建Git服务器 【云端漫步】一起上“阿里云”（5）、域名购买和解析 Python多字节二进制文件读取 C#中集合List的深浅拷贝 C#中常用的集合List去重方法 C#多字节二进制文件读取 深入理解C#（01）：堆栈、值类型和引用类型、值传递和引用传递 宽字符 编程命名法 编程字体推荐 Json序列化与反序列化（1）-JavaScriptSerializer Json序列化与反序列化（2）-Json.Net Json序列化与反序列化（3）-DataContractJsonSerializer CR与LF（操作系统“下一行”的不同） Visual Studio Code Preview初体验 Visual Studio Code Preview深度体验、使用技巧 Brand7-品牌漆上架商店啦！ UWP应用Brand7开发小记（1）、判断App是否是第一次启动 UWP应用Brand7开发小记（2）、用Excel和Json初始化本地数据源Part1 UWP应用Brand7开发小记（2）、用Excel和Json初始化本地数据源Part2 UWP 应用Brand7开发小记（3）、判断GridView的滚动方向 UWP应用Brand7开发小记（4）、集合控件的虚拟化问题 UWP 应用Brand7开发小记（5）、控件嵌入标题栏 MySQL学习小记（1）-不能启动MySQL服务 MySQL学习小记（2）-添加远程访问权限详解 MySQL学习小记（3）-外键的使用 MySQL学习小记（4）-最大连接数 MySQL学习小记（5）-主从服务器同步 VS至强插件ReSharper指南01、安装入门 【视觉与图像】【视觉与图像】摄像头篇（1）、CCD靶面尺寸 【视觉与图像】摄像头篇（2）、焦距和视角 CMake编译OpenCV3.2（Qt平台） Qt+OpenCV环境搭建 【Design/演示/设计】玩转PPT放映第一篇、演示者视图 玩转PPT放映第二篇、快捷键 玩转PPT放映第三篇、自定义放映 【PPT动画】钟摆效果 【PPT动画】模糊渐变切换效果 【PPT动画】制作左、右浮入效果 PPT制作画中画效果 PPT绘制长阴影图标 PPT三维立体图形绘制 PPT巧用矩形等分区域（黄金分割线） 【Lens/摄影/影视】家乡 | 黑白 | PENTAX K-50 | 看见不一样 看见，时光（延时摄影短片） 我那时的“计量”（一），黑白质感 我那时的“计量”（二），迎新色彩 Lumia 1520 by iPhone6s 历届奥斯卡最佳动画长片下载（1） 历届奥斯卡最佳动画长片下载（2） 「精品」皮克斯15部动画长片下载 【Other/科普/发现】PPI与DPI USB接口类型（2.0概述） Type-C和USB3.0（3.1） 发现Win10 Bug两枚（均得微软官方确认，一枚已解决） 再战之后，这场旅途，只属于我 Win8以上系统安装PL2303驱动 硬盘容量计算的差别 硬盘整数分区原理及计算（附工具下载） 详解Windows运行组件第一篇、原理篇 详解Windows运行组件第二篇、自定义运行指令 Windows 10技术预览版体验视频 Never give up. Never stop fighting. Excelsior!","categories":[],"tags":[]},{"title":"CMake编译OpenCV3.2（QT平台）","slug":"CMake编译OpenCV3-2（Qt平台）","date":"2017-07-26T14:25:29.000Z","updated":"2018-04-16T14:38:17.856Z","comments":true,"path":"2017/07/26/CMake编译OpenCV3-2（Qt平台）/","link":"","permalink":"http://ex2tron.coding.me/2017/07/26/CMake编译OpenCV3-2（Qt平台）/","excerpt":"最近，需要在Windows下搭建一个QT和OpenCV的环境，可惜官方OpenCV3.2的build里面并不是针对QT平台的。所以，需要用CMake编译OpenCV的源码。","text":"最近，需要在Windows下搭建一个QT和OpenCV的环境，可惜官方OpenCV3.2的build里面并不是针对QT平台的。所以，需要用CMake编译OpenCV的源码。 CMake V3.9.0 OpenCV V3.2.0 编译步骤安装完CMake后，打开cmake-gui，如下图所示： 选择OpenCV3.2源码所在位置，我的是在：D:\\ProgramFiles\\OpenCV3\\sources 选择编译生成的目录 最后点击”Configure”，如下图所示： 选择“MinGW Makefiles”并勾选“Specify native compilers”，点击“Next”： 这里分别选择QT安装目录下gcc和g++的路径，点击“Finish”，等待配置完成。 配置完成后，勾选“WITH_OPENGL”和“WITH_QT”，点击“Generate”就可以了。如果发生错误： 将QT的相关路径配置如下： 先点击“Configure”，再次点击“Generate”就可以生成了。然后在cmd下切换到生成的目录，我的是D:\\OpenCVBuild，执行命令：mingw32-make开始编译（25分钟左右）： 编译好之后，再执行mingw32-make install就完成了。","categories":[{"name":"Build篇","slug":"Build篇","permalink":"http://ex2tron.coding.me/categories/Build篇/"}],"tags":[{"name":"CMake","slug":"CMake","permalink":"http://ex2tron.coding.me/tags/CMake/"},{"name":"OpenCV","slug":"OpenCV","permalink":"http://ex2tron.coding.me/tags/OpenCV/"}]},{"title":"【视觉与图像】摄像头篇2：焦距和视角","slug":"【视觉与图像】摄像头篇2：焦距和视角","date":"2017-05-16T12:41:16.000Z","updated":"2018-04-16T14:19:43.200Z","comments":true,"path":"2017/05/16/【视觉与图像】摄像头篇2：焦距和视角/","link":"","permalink":"http://ex2tron.coding.me/2017/05/16/【视觉与图像】摄像头篇2：焦距和视角/","excerpt":"焦距镜头是由一组光学凹凸透镜组成的：光透过透镜后，聚焦在CCD上形成影像（小孔成像）。","text":"焦距镜头是由一组光学凹凸透镜组成的：光透过透镜后，聚焦在CCD上形成影像（小孔成像）。如上图中所示，焦距就是透镜中心点到CCD焦平面的距离。按照焦距可否调节，镜头可分为定焦镜头和变焦镜头。 当你不能够再拥有，你唯一可以做的，就是令自己不要忘记。——《东邪西毒》 玩过单反摄影的人都知道相机上有个焦平面标记，这就是胶片时代为了精准对焦用的，有相机的童鞋可以拿出来看看： 可视角显然，焦距的大小决定了视场角的大小（也称视野范围FOV：Field of View）。同样的CCD尺寸下，焦距越大，视角越小。同理，相同的焦距下，CCD尺寸越大，可视角越大。 举例来说，一张4:3比例（CCD比例假设也为4:3）的照片中，要把身高为1.75m的人拍到，那么对角线距离是2.19m左右： 把上图中的黑线部分提取出来，摄像头跟拍摄人物间的距离计算如下： 购买摄像头时，如果没有说明镜头的可视角，但知道CCD尺寸和焦距，可按照上图简单计算。 比如1/2.7inch的CCD（4:3），焦距为3.6mm，那么根据上篇博客，w=6.592/2=3.296mm，d=3.6mm，所以可视角=2*α=84.95°。 当然，焦距越大，视角越小，摄像头也能看得更远。比如下图是某款1/3inch CCD监控摄像头的可视角和监控范围图： 引用监控摄像头镜头焦距与可视角度换算表","categories":[{"name":"机器视觉","slug":"机器视觉","permalink":"http://ex2tron.coding.me/categories/机器视觉/"}],"tags":[{"name":"焦距","slug":"焦距","permalink":"http://ex2tron.coding.me/tags/焦距/"},{"name":"视角","slug":"视角","permalink":"http://ex2tron.coding.me/tags/视角/"}]},{"title":"【视觉与图像】摄像头篇1：CCD靶面尺寸","slug":"【视觉与图像】摄像头篇1：CCD靶面尺寸","date":"2017-05-15T02:29:52.000Z","updated":"2018-04-16T14:14:06.806Z","comments":true,"path":"2017/05/15/【视觉与图像】摄像头篇1：CCD靶面尺寸/","link":"","permalink":"http://ex2tron.coding.me/2017/05/15/【视觉与图像】摄像头篇1：CCD靶面尺寸/","excerpt":"对于机器视觉和图像处理的任务，通常都从选择一款好的摄像头开始的。","text":"对于机器视觉和图像处理的任务，通常都从选择一款好的摄像头开始的。如果摄像头选的恰当，就能获取到一幅“好”的图像，这点很重要。 如果你不出去走走，你就会以为这就是全世界。——《天堂电影院》 所以我们就摄像头的几个重要参数来深入说明一下，首先看下CCD尺寸，开始入坑吧： CCD尺寸CCD靶面尺寸就是相机中CCD图像传感器芯片的大小： 玩过摄影的人应该都知道135相机和全画幅相机，全画幅相机指的就是CCD/CMOS长宽为36×24mm的数码相机。胶片时代，135胶卷（柯达生产）的画幅就是36×24mm，算上胶卷的开孔，高度是35mm，所以135相机也叫35mm相机。 显然，CCD尺寸越大，感光面积就越大，能捕获的光也就越多。另外，相同分辨率大小下，CCD面积越大，单个像素感光点之间的间隔也就越大，信噪比越低。 常见尺寸这里列举几种典型的CCD尺寸： 规格 长宽比 尺寸mm 对角线mm 全画幅 3:2 36×24 43.3 APS-C 3:2 24.9×16.6 29.3 4/3英寸 4:3 18×13.5 22.5 1英寸 4:3 12.8×9.6 16 2/3英寸 4:3 8.8×6.6 11 1/2英寸 4:3 6.4×4.8 8 1/2.7英寸 4:3 5.27×3.96 6.592 1/3英寸 4:3 4.8×3.6 6 1/4英寸 4:3 3.2×2.4 4 要注意的是，这里的1英寸并不等于实际中的25.4毫米。其实最初是为了避免圆形图像裁剪成矩形显示时四个角发暗，才搞出了对角线16mm为1英寸的说法： 宽高比另外，CCD靶面除了尺寸之外，还需要注意它的宽高比/长宽比。目前主流的CCD大多是4:3和3:2比例，还有16:9等比例的CCD。如果一个CCD的宽高比为4:3，那么只有分辨率宽高比也是4:3的情况下（如：640*480），才能全像素输出，拍摄16：9的图像时，像素会有损失。 引用 CCD尺寸对应表 科普：CCD/CMOS靶面尺寸型号标准 【CCD尺寸】各尺寸CCD大小比对图 全幅、半幅、M4/3、2/3、1/2.3、1/2.7","categories":[{"name":"机器视觉","slug":"机器视觉","permalink":"http://ex2tron.coding.me/categories/机器视觉/"}],"tags":[{"name":"CCD","slug":"CCD","permalink":"http://ex2tron.coding.me/tags/CCD/"}]}]}