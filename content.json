[{"title":"Python+OpenCV教程7：图像几何变换","date":"2017-12-08T06:36:53.000Z","path":"2017/12/08/Python-OpenCV教程7：图像几何变换/","text":"学习如何旋转、平移和缩放图片，了解仿射/透视变换。图片等可到源码处下载。 目标 实现旋转、平移和缩放图片 了解仿射变换和透视变换 OpenCV函数：cv2.resize(), cv2.warpAffine(), cv2.warpPerspective() 教程缩放图片缩放就是调整图片的大小，使用cv2.resize()函数实现缩放。可以按照比例缩放，也可以按照指定的大小缩放： 12345678910111213import cv2import numpy as npimport matplotlib.pyplot as pltimg = cv2.imread('drawing.jpg')# 按照指定的宽度、高度缩放图片res = cv2.resize(img, (132, 150))# 按照比例缩放，如x,y轴均放大一倍res2 = cv2.resize(img, None, fx=2, fy=2, interpolation=cv2.INTER_LINEAR)cv2.imshow('shrink', res), cv2.imshow('zoom', res2)cv2.waitKey(0) 我们也可以指定缩放方法interpolation，更专业点叫插值方法，默认是INTER_LINEAR，全部可以参考：InterpolationFlags 平移图片这里涉及到仿射变换的概念，大家不用知道它的意思，只需要了解下面三点： 仿射变换后，原图中平行的线依然平行 用cv2.warpAffine()实现仿射变换 仿射变换需要定义一个2*3维的变换矩阵 要平移图片，我们需要定义下面这样一个矩阵，tx,ty是向x和y方向平移的距离： $$ M = \\left[ \\begin{matrix} 1 &amp; 0 &amp; tx \\newline 0 &amp; 1 &amp; ty \\end{matrix} \\right] \\tag{3}$$ 1234567891011# 平移图片rows, cols = img.shape[:2]# 定义平移矩阵，需要是numpy的float32类型# x轴平移100，y轴平移50M = np.float32([[1, 0, 100], [0, 1, 50]])# 用仿射变换实现平移dst = cv2.warpAffine(img, M, (cols, rows))cv2.imshow('shift', dst)cv2.waitKey(0) 再次强调一下：图片的高度（y方向）是rows，宽度（x方向）是cols，请勿混淆。 平移图片 旋转图片旋转同平移一样，也需要定义一个变换矩阵。OpenCV直接提供了cv2.getRotationMatrix2D()函数用来生成这个矩阵，对这个矩阵的形式感兴趣的童鞋可以去引用查看： 123456# 45°旋转图片并缩小一半M = cv2.getRotationMatrix2D((cols / 2, rows / 2), 45, 0.5)dst = cv2.warpAffine(img, M, (cols, rows))cv2.imshow('rotation', dst)cv2.waitKey(0) cv2.getRotationMatrix2D()函数有三个参数： 参数1：图片的旋转中心 参数2：旋转角度 参数3：缩放比例，该例中0.5表示我们缩小一半 旋转45°并缩放 仿射变换除了平移和旋转，如何实现任意的图像变换呢？同样的道理，我们需要一个变换矩阵。 要生成这个变换矩阵，需要定义变换前后的三个点，比如说： 123456789101112# 变换前的三个点pts1 = np.float32([[50, 65], [150, 65], [210, 210]])# 变换后的三个点pts2 = np.float32([[50, 100], [150, 65], [100, 250]])# 生成变换矩阵M = cv2.getAffineTransform(pts1, pts2)dst = cv2.warpAffine(img, M, (cols, rows))plt.subplot(121), plt.imshow(img), plt.title('input')plt.subplot(122), plt.imshow(dst), plt.title('output')plt.show() 变换前后的三个点我已经标记出来了。用cv2.getAffineTransform()生成变换矩阵，接下来再用cv2.warpAffine()实现变换。大家可以修改下变换后的三个点坐标看看效果： 仿射变换前后对比图 透视变换透视变换绝对是一项很酷的功能。我们经常会用手机去拍身份证和文件，无论你怎么拍，貌似都拍不正或者有边框。如果你使用过手机上面一些扫描类软件，比如”扫描全能王“，”Office Lens“，它们能很好地矫正图片。这些软件就是应用透视变换实现的，跟仿射变换一样，我们不用知道它的具体原理。 透视变换后，原图中的直线依旧是直线。如下图，我们实现这个功能： 矫正一鸣的卡片 1234567891011121314151617181920import cv2import numpy as npimport matplotlib.pyplot as pltimg = cv2.imread('card.jpg')rows, cols = img.shape[:2]# 原图中卡片的四个角点pts1 = np.float32([[148, 80], [437, 114], [94, 247], [423, 288]])# 变换后分别在左上、右上、左下、右下四个点pts2 = np.float32([[0, 0], [320, 0], [0, 178], [320, 178]])# 生成透视变换矩阵M = cv2.getPerspectiveTransform(pts1, pts2)# 进行透视变换dst = cv2.warpPerspective(img, M, (320, 178))plt.subplot(121), plt.imshow(img[:, :, ::-1]), plt.title('input')plt.subplot(122), plt.imshow(dst[:, :, ::-1]), plt.title('output')plt.show() 透视变换需要前后四个点来生成3*3的变换矩阵，用cv2.getPerspectiveTransform()实现。然后再用cv2.warpPerspective()进行变换。代码中有个img[:, :, ::-1]还记得吗？忘记的话，请看练习。 是不是很简单？当然，我们后面学习了特征提取之后，就可以自动识别角点了。 小结cv2.resize()缩放图片，可以按指定大小缩放，亦可以按比例缩放。 平移和旋转是靠cv2.warpAffine()仿射变换实现的，也可以自己定义变换前后的点，实现任意变换。 透视变换常用于矫正图片，是一个很酷的功能。 练习 透视变换代码中有个img[:, :, ::-1]，还记得吗？请复习：Matplotlib显示图像 引用本节源码 Geometric Transformations of Images","tags":[{"name":"Code","slug":"Code","permalink":"https://ex2tron.github.io/tags/Code/"},{"name":"Python","slug":"Python","permalink":"https://ex2tron.github.io/tags/Python/"},{"name":"OpenCV","slug":"OpenCV","permalink":"https://ex2tron.github.io/tags/OpenCV/"},{"name":"图像处理","slug":"图像处理","permalink":"https://ex2tron.github.io/tags/图像处理/"},{"name":"几何变换","slug":"几何变换","permalink":"https://ex2tron.github.io/tags/几何变换/"}]},{"title":"Python+OpenCV教程番外篇2：Otsu阈值法","date":"2017-12-08T04:48:05.000Z","path":"2017/12/08/Python-OpenCV教程番外篇2：Otsu阈值法/","text":"大部分图像处理任务都需要先二值化操作，所以阈值的选取很关键，Otsu阈值法会自动计算阈值。 Otsu阈值法（日本人提出的，也可以叫大津算法）会自动计算阈值，它适用于双峰图片，啥意思呢？ 什么是双峰图片？双峰图片就是指图片的灰度直方图上有两个峰值： Otsu算法假设这副图片由前景色和背景色组成，通过统计学方法（最大类间方差）选取一个阈值，将前景和背景尽可能分开，算法详解：Otsu’s Method(wikipedia) 代码示例下面这段代码对比了使用固定阈值和Otsu阈值后的不同结果： 另外，对含噪点的图像，先进行滤波操作效果会更好。 1234567891011121314151617181920212223242526272829303132333435363738394041import cv2from matplotlib import pyplot as pltimg = cv2.imread('noisy.jpg', 0)# 固定阈值法ret1, th1 = cv2.threshold(img, 100, 255, cv2.THRESH_BINARY)# Otsu阈值法ret2, th2 = cv2.threshold(img, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)# 先进行高斯滤波，再使用Otsu阈值法blur = cv2.GaussianBlur(img, (5, 5), 0)ret3, th3 = cv2.threshold(blur, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)images = [img, 0, th1, img, 0, th2, blur, 0, th3]titles = ['Original', 'Histogram', 'Global(v=100)', 'Original', 'Histogram', \"Otsu's\", 'Gaussian filtered Image', 'Histogram', \"Otsu's\"]for i in range(3): # 绘制原图 plt.subplot(3, 3, i * 3 + 1) plt.imshow(images[i * 3], 'gray') plt.title(titles[i * 3], fontsize=8) plt.xticks([]), plt.yticks([]) # 绘制直方图plt.hist，ravel函数将数组降成一维 plt.subplot(3, 3, i * 3 + 2) plt.hist(images[i * 3].ravel(), 256) plt.title(titles[i * 3 + 1], fontsize=8) plt.xticks([]), plt.yticks([]) # 绘制阈值图 plt.subplot(3, 3, i * 3 + 3) plt.imshow(images[i * 3 + 2], 'gray') plt.title(titles[i * 3 + 2], fontsize=8) plt.xticks([]), plt.yticks([])plt.show() 固定阈值 vs Otsu阈值 可以看到，Otsu阈值明显由于固定阈值，省去了不断尝试阈值判断效果好坏的过程。其中，绘制直方图时，使用了numpy中的ravel()函数，它会将原矩阵压缩成一维数组，便于画直方图。 引用本节源码 numpy.ravel Otsu’s Method Image Thresholding","tags":[{"name":"Code","slug":"Code","permalink":"https://ex2tron.github.io/tags/Code/"},{"name":"Python","slug":"Python","permalink":"https://ex2tron.github.io/tags/Python/"},{"name":"OpenCV","slug":"OpenCV","permalink":"https://ex2tron.github.io/tags/OpenCV/"},{"name":"图像处理","slug":"图像处理","permalink":"https://ex2tron.github.io/tags/图像处理/"},{"name":"阈值","slug":"阈值","permalink":"https://ex2tron.github.io/tags/阈值/"}]},{"title":"Python+OpenCV教程6：阈值分割","date":"2017-12-07T13:14:44.000Z","path":"2017/12/07/Python-OpenCV教程6：阈值分割/","text":"学习使用不同的阈值方法”二值化”图像。图片等可到源码处下载。 目标 使用固定阈值、自适应阈值和Otsu阈值法”二值化”图像 OpenCV函数：cv2.threshold(), cv2.adaptiveThreshold() 教程固定阈值分割固定阈值分割很直接，一句话说就是像素点值大于阈值一个值，小于阈值是另外一个值。 12345678910import cv2import matplotlib.pyplot as plt# 灰度图读入img = cv2.imread('gradient.jpg', 0)# 阈值分割ret, th = cv2.threshold(img, 127, 255, cv2.THRESH_BINARY)cv2.imshow('thresh', th)cv2.waitKey(0) cv2.threshold()用来实现阈值分割，ret是return value缩写，代表当前的阈值，暂时无用，不用管它。函数有4个参数： 参数1：要处理的原图，一般是灰度图 参数2：设定的阈值 参数3：最大阈值，一般为255 参数4：阈值的方式，主要有5种，详情：ThresholdTypes 123456789101112131415161718# 应用5种不同的阈值方法ret, th1 = cv2.threshold(img, 127, 255, cv2.THRESH_BINARY)ret, th2 = cv2.threshold(img, 127, 255, cv2.THRESH_BINARY_INV)ret, th3 = cv2.threshold(img, 127, 255, cv2.THRESH_TRUNC)ret, th4 = cv2.threshold(img, 127, 255, cv2.THRESH_TOZERO)ret, th5 = cv2.threshold(img, 127, 255, cv2.THRESH_TOZERO_INV)titles = ['Original', 'BINARY', 'BINARY_INV', 'TRUNC', 'TOZERO', 'TOZERO_INV']images = [img, th1, th2, th3, th4, th5]# 使用Matplotlib显示for i in range(6): plt.subplot(2, 3, i + 1) plt.imshow(images[i], 'gray') plt.title(titles[i], fontsize=8) plt.xticks([]), plt.yticks([]) # 隐藏坐标轴plt.show() 5种不同的阈值方式结果 结合下表，就很容易理解这5种方式了： 经验之谈：很多人误以为阈值分割就是二值化。从上图中可以发现，两者并不等同，阈值分割结果是两种值，而不是两个值，所以教程开头我把二值化加了引号。 自适应阈值看得出来固定阈值是在整幅图片上应用一个阈值进行分割，它并不适用于明暗分布不均的图片。cv2.adaptiveThreshold()自适应阈值会每次取图片的一小部分计算阈值，这样图片不同区域的阈值就不尽相同。它有5个参数，其实很好理解，先看下效果： 12345678910111213141516171819# 自适应阈值对比固定阈值img = cv2.imread('sudoku.jpg', 0)# 固定阈值ret, th1 = cv2.threshold(img, 127, 255, cv2.THRESH_BINARY)# 自适应阈值th2 = cv2.adaptiveThreshold( img, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 11, 4)th3 = cv2.adaptiveThreshold( img, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 17, 6)titles = ['Original', 'Global(v = 127)', 'Adaptive Mean', 'Adaptive Gaussian']images = [img, th1, th2, th3]for i in range(4): plt.subplot(2, 2, i + 1), plt.imshow(images[i], 'gray') plt.title(titles[i], fontsize=8) plt.xticks([]), plt.yticks([])plt.show() 自适应阈值对比固定阈值 参数1：要处理的原图 参数2：最大阈值，一般为255 参数3：小区域阈值的计算方式 ADAPTIVE_THRESH_MEAN_C：小区域内取均值 ADAPTIVE_THRESH_GAUSSIAN_C：小区域内加权求和，权重是个高斯核 参数4：阈值方式（跟前面讲的那5种相同） 参数5：小区域的面积，如11就是11*11的小块 参数6：最终阈值等于小区域计算出的阈值再减去此值 如果你没看懂上面的参数也不要紧，暂时会用就行，当然我建议你调整下参数看看不同的结果。 Otsu阈值在前面固定阈值中，我们是随便选了一个阈值如127，那如何知道我们选的这个阈值效果好不好呢？答案是：不断尝试，所以这种方法在很多文献中都被称为经验阈值。Otsu阈值法就提供了一种自动高效的二值化方法，不过我们直方图还没学，这里暂时略过。 好吧，我知道我激起了你的兴趣，~ o(￣▽￣)o，有能力的童鞋可以看下练习题。 小结cv2.threshold()用来进行固定阈值分割。固定阈值不适用于光线不均匀的图片，所以用cv2.adaptiveThreshold()进行自适应阈值分割。 二值化跟阈值分割并不等同。针对不同的图片，可以采用不同的阈值方法。 练习 Otsu阈值是一种高效的二值化算法，请尝试阅读番外篇2：Otsu阈值法。 引用本节源码 Image Thresholding","tags":[{"name":"Code","slug":"Code","permalink":"https://ex2tron.github.io/tags/Code/"},{"name":"Python","slug":"Python","permalink":"https://ex2tron.github.io/tags/Python/"},{"name":"OpenCV","slug":"OpenCV","permalink":"https://ex2tron.github.io/tags/OpenCV/"},{"name":"图像处理","slug":"图像处理","permalink":"https://ex2tron.github.io/tags/图像处理/"},{"name":"阈值","slug":"阈值","permalink":"https://ex2tron.github.io/tags/阈值/"}]},{"title":"Python+OpenCV教程5：颜色空间转换","date":"2017-12-07T07:21:19.000Z","path":"2017/12/07/Python-OpenCV教程5：颜色空间转换/","text":"学习如何进行图片的颜色空间转换，视频中追踪特定颜色物体。图片等可到源码处下载。 目标 颜色空间转换，如BGR↔Gray，BGR↔HSV等 追踪视频中特定颜色的物体 OpenCV函数：cv2.cvtColor(),cv2.inRange() 教程颜色空间转换12345678import cv2import numpy as npimg = cv2.imread('lena.jpg')# 转换为灰度图img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)cv2.imshow('img', img)cv2.imshow('gray', img_gray), cv2.waitKey(0) cv2.cvtColor()用来进行颜色模型转换，参数1是要转换的图片，参数2是转换模式，COLOR_BGR2GRAY表示BGR→Gray，可用下面的代码显示所有的转换模式： 12flags = [i for i in dir(cv2) if i.startswith('COLOR_')]print(flags) 视频中特定颜色物体追踪HSV是一个常用于颜色识别的模型，相比BGR更易区分颜色，转换模式用COLOR_BGR2HSV表示。 经验之谈：OpenCV中色调H范围为[0,179]，饱和度S是[0,255]，明度V是[0,255]。其他软件可能使用不同的尺度表示，所以同其他软件使用时，记得归一化。 现在，我们实现一个使用HSV来只显示视频中蓝色物体的例子，步骤如下： 捕获视频中的一帧 从BGR转换到HSV 提取蓝色范围的物体 只显示蓝色物体 跟踪视频中的蓝色物体 12345678910111213141516171819202122232425capture = cv2.VideoCapture(0)# 蓝色的范围，不同光照条件下不一样，可灵活调整lower_blue = np.array([100, 110, 110])upper_blue = np.array([130, 255, 255])while(True): # 1.捕获视频中的一帧 ret, frame = capture.read() # 2.从BGR转换到HSV hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV) # 3.inRange()：介于lower/upper之间的为白色，其余黑色 mask = cv2.inRange(hsv, lower_blue, upper_blue) # 4.只保留原图中的蓝色部分 res = cv2.bitwise_and(frame, frame, mask=mask) cv2.imshow('frame', frame) cv2.imshow('mask', mask) cv2.imshow('res', res) if cv2.waitKey(1) == ord('q'): break 其中，bitwise_and()函数暂时不用管，后面会讲到。那蓝色的HSV值的lower和upper范围是怎么得到的呢？其实很简单，我们先把标准蓝色的值用cvtColor()转换下： 123blue = np.uint8([[[255, 0, 0]]])hsv_blue = cv2.cvtColor(blue, cv2.COLOR_BGR2HSV)print(hsv_blue) # [[[120 255 255]]] 结果是[120, 255, 255]，所以，我们把蓝色的范围调整成了上面代码那样。 经验之谈：Lab颜色空间也经常用来做颜色识别，有兴趣的同学可以了解下。 小结cv2.cvtColor()函数用来进行颜色空间转换，常用BGR↔Gray，BGR↔HSV。 HSV/Lab颜色模型常用于颜色识别。要想知道某种颜色在HSV下的值，可以将它的BGR值用cvtColor()转换得到。 练习 尝试在视频中同时提取红色、蓝色、绿色的物体。（效果如下） 同时追踪3种颜色 引用本节源码 Changing Colorspaces","tags":[{"name":"Code","slug":"Code","permalink":"https://ex2tron.github.io/tags/Code/"},{"name":"Python","slug":"Python","permalink":"https://ex2tron.github.io/tags/Python/"},{"name":"OpenCV","slug":"OpenCV","permalink":"https://ex2tron.github.io/tags/OpenCV/"},{"name":"图像处理","slug":"图像处理","permalink":"https://ex2tron.github.io/tags/图像处理/"},{"name":"HSV","slug":"HSV","permalink":"https://ex2tron.github.io/tags/HSV/"}]},{"title":"Python+OpenCV教程4：图像基本操作","date":"2017-12-07T04:13:15.000Z","path":"2017/12/07/Python-OpenCV教程4：图像基本操作/","text":"学习获取和修改像素点的值，ROI感兴趣区域，通道分离合并等基本操作。图片等可到源码处下载。 目标 访问和修改图片像素点的值 获取图片的宽、高、通道数等属性 了解感兴趣区域ROI 分离和合并图像通道 教程获取和修改像素点值我们先读入一张图片： 123import cv2img = cv2.imread('lena.jpg') 通过行列的坐标来获取某像素点的值，对于彩色图，这个值是B,G,R三个值的列表，对于灰度图，只有一个值： 123456px = img[100, 100]print(px) # [119 108 201]# 只获取蓝色blue通道的值px_blue = img[100, 100, 0]print(px_blue) # 119 注意，行列坐标是img[y,x]，如下图，本教程不再赘述图像处理的基本理论，只做简单提及。 图像坐标和通道 修改像素的值也是同样的方式： 12img[100, 100] = [255, 255, 255]print(img[100, 100]) # [255 255 255] 经验之谈：还记得之前说过OpenCV-Python原生支持numpy吗？numpy是针对矩阵运算优化的，所以像上面的操作性能较差，更推荐的方式是：获取：img.item(100,100,0)，修改：img.itemset((100,100,0),255)，但这种方式只能B,G,R逐一进行。 图片属性img.shape获取图像的形状，图片是彩色的话，返回一个包含高度、宽度和通道数的元组，灰度图只返回高度和宽度： 1234print(img.shape) # (263, 263, 3)# 形状中包括高度、宽度和通道数height, width, channels = img.shape# img是灰度图的话：height, width = img.shape img.dtype获取图像数据类型： 1print(img.dtype) # uint8 经验之谈：很多错误都是因为数据类型不对导致的，所以健壮的代码需要对这个属性加以判断。 img.size获取图像总像素数： 1print(img.size) # 263*263*3=207507 ROIROI：region of interest，感兴趣区域。什么意思呢？比如我们要检测眼睛，因为眼睛肯定在脸上，所以我们感兴趣的只有脸这部分，其他不需要关注，这样就可以大大节省计算量，提高运行速度。 只关注脸( ╯□╰ ) 截取ROI非常简单，指定图片的范围即可： 1234# 截取脸部ROIface = img[100:200, 115:188]cv2.imshow('face', face)cv2.waitKey(0) 通道分割与合并彩色图的BGR三个通道是可以分开单独访问的，也可以将单独的三个通道合并成一副图像。分别使用cv2.split()和cv2.merge()： 12b, g, r = cv2.split(img)img = cv2.merge((b, g, r)) split()函数比较耗时，更高效的方式是用numpy的索引，如提取B通道： 123b = img[:, :, 0]cv2.imshow('blue', b)cv2.waitKey(0) 小结img[y,x]获取/设置像素点值，img.shape：图片的形状（高度、宽度、通道数）,img.dtype：图像的数据类型。 img[y1:y2,x1:x2]进行ROI截取，cv2.split()/cv2.merge()通道分割/合并。更推荐的获取单通道方式：b = img[:, :, 0]。 练习 打开lena.jpg，将帽子部分（高：25~120，宽：50~220）的红色通道截取出来并显示。 引用本节源码 Basic Operations on Images","tags":[{"name":"Code","slug":"Code","permalink":"https://ex2tron.github.io/tags/Code/"},{"name":"Python","slug":"Python","permalink":"https://ex2tron.github.io/tags/Python/"},{"name":"OpenCV","slug":"OpenCV","permalink":"https://ex2tron.github.io/tags/OpenCV/"},{"name":"图像处理","slug":"图像处理","permalink":"https://ex2tron.github.io/tags/图像处理/"},{"name":"ROI","slug":"ROI","permalink":"https://ex2tron.github.io/tags/ROI/"}]},{"title":"Python+OpenCV教程3：打开摄像头","date":"2017-12-06T08:38:02.000Z","path":"2017/12/06/Python-OpenCV教程3：打开摄像头/","text":"学习打开摄像头捕获照片、播放本地视频、录制视频等。视频等可到源码处下载。 目标 打开摄像头并捕获照片 播放本地视频，录制视频 OpenCV函数：cv2.VideoCapture(), cv2.VideoWriter() 教程打开摄像头要使用摄像头，需要使用cv2.VideoCapture(0)创建VideoCapture对象，参数0指的是摄像头的编号。如果你电脑上有两个摄像头的话，访问第2个摄像头就可以传入1。 1234567891011121314# 打开摄像头并灰度化显示import cv2capture = cv2.VideoCapture(0)while(True): # 获取一帧 ret, frame = capture.read() # 将这帧转换为灰度图 gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY) cv2.imshow('frame', gray) if cv2.waitKey(1) == ord('q'): break capture.read()函数返回的第一个参数是一个布尔值，frame获取正确的话，ret=True。cv2.cvtColor()是颜色空间转换函数，OpenCV默认以BGR通道顺序存储图像，这里转成灰度图。 另外，通过cap.get(propId)可以获取摄像头的一些信息，比如捕获的分辨率，亮度和对比度等。propId是从0~18的数字，代表不同的属性，完整的属性列表可以参考：Property Identifier。也可以使用cap.set(propId,value)来修改属性值。比如说，我们在while之前添加如下代码： 12345678# 获取捕获的分辨率width, height = capture.get(3), capture.get(4)print(width, height)# 以原分辨率的一倍来捕获，# 参数1可以直接写数字，或者OpenCV符号表示capture.set(cv2.CAP_PROP_FRAME_WIDTH, width * 2)capture.set(cv2.CAP_PROP_FRAME_HEIGHT, height * 2) 经验之谈：某些摄像头设定分辨率等参数时会无效，因为它有固定的分辨率大小支持，一般可在摄像头的资料页中找到。 播放本地视频跟打开摄像头一样，如果把摄像头的编号换成本地视频的路径就可以播放了。回想一下cv2.waitKey()，它的参数表示暂停时间，所以这个值越大，视频播放速度越慢，反之，播放速度越快，通常设置为25或30。 123456789101112import cv2# 播放本地视频capture = cv2.VideoCapture('demo_video.mp4')while(capture.isOpened()): ret, frame = capture.read() gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY) cv2.imshow('frame', gray) if cv2.waitKey(30) == ord('q'): break 录制视频之前我们保存图片用的是cv2.imwrite()，要保存视频，我们需要创建一个VideoWriter对象，可以给它传入四个参数： 输出的文件名，如’output.avi’ 编码方式FourCC码 帧率FPS 要保存的分辨率大小 FourCC是用来指定视频编码方式的四字节码，所有的编码可参考Video Codecs。如MJPG编码可以这样写：cv2.VideoWriter_fourcc(*&#39;MJPG&#39;)或cv2.VideoWriter_fourcc(&#39;M&#39;,&#39;J&#39;,&#39;P&#39;,&#39;G&#39;) 1234567891011121314151617181920import cv2capture = cv2.VideoCapture(0)# 定义编码方式并创建VideoWriter对象fourcc = cv2.VideoWriter_fourcc(*'MJPG')outfile = cv2.VideoWriter('output.avi', fourcc, 25., (640, 480))while(capture.isOpened()): ret, frame = capture.read() if ret: # 写入文件 outfile.write(frame) cv2.imshow('frame', frame) if cv2.waitKey(1) == ord('q'): break else: break 小结使用cv2.VideoCapture()创建视频对象，然后在循环中一帧帧显示图像。参数传入数字时，代表打开摄像头，传入本地视频地址时，代表播放本地视频。 cap.get(propId)获取视频属性，cap.set(propId,value)设置视频属性。 cv2.VideoWriter()创建视频写入对象，用来录制/保存视频，四位FOURCC码表示视频编码方式。 引用本节源码 Video Codecs by FOURCC Getting Started with Videos","tags":[{"name":"Code","slug":"Code","permalink":"https://ex2tron.github.io/tags/Code/"},{"name":"Python","slug":"Python","permalink":"https://ex2tron.github.io/tags/Python/"},{"name":"OpenCV","slug":"OpenCV","permalink":"https://ex2tron.github.io/tags/OpenCV/"},{"name":"图像处理","slug":"图像处理","permalink":"https://ex2tron.github.io/tags/图像处理/"}]},{"title":"Python+OpenCV教程番外篇1：Matplotlib显示图像","date":"2017-12-06T07:55:15.000Z","path":"2017/12/06/Python-OpenCV教程番外篇1：Matplotlib显示图像/","text":"学习如何使用Matplotlib显示OpenCV图像。 Matplotlib是Python的一个非常重要的绘图库，更多内容可以去官网学习。 显示灰度图1234567import cv2import matplotlib.pyplot as pltimg = cv2.imread('lena.jpg', 0)# 灰度图显示，cmap(color map)设置为grayplt.imshow(img, cmap='gray')plt.show() 结果如下： 显示彩色图OpenCV中的图像是以BGR的通道顺序存储的，但Matplotlib是以RGB模式显示的，所以直接在Matplotlib中显示OpenCV图像会出现问题，因此需要转换一下: 12345678910111213141516import cv2import matplotlib.pyplot as pltimg = cv2.imread('lena.jpg')img2 = img[:, :, ::-1]# 或使用# img2 = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)# 显示不正确的图plt.subplot(121),plt.imshow(img) # 显示正确的图plt.subplot(122)plt.xticks([]), plt.yticks([]) # 隐藏x和y轴plt.imshow(img2)plt.show() 注解：img[:,:,0]代表拷贝图片的蓝色通道，熟悉Python的同学应该知道，对一个字符串s进行翻转用的是s[::-1]，同样img[:,:,::-1]就表示BGR通道翻转，变成RGB。 结果如下： 引用本节源码","tags":[{"name":"Code","slug":"Code","permalink":"https://ex2tron.github.io/tags/Code/"},{"name":"Python","slug":"Python","permalink":"https://ex2tron.github.io/tags/Python/"},{"name":"OpenCV","slug":"OpenCV","permalink":"https://ex2tron.github.io/tags/OpenCV/"},{"name":"图像处理","slug":"图像处理","permalink":"https://ex2tron.github.io/tags/图像处理/"},{"name":"Matplotlib","slug":"Matplotlib","permalink":"https://ex2tron.github.io/tags/Matplotlib/"}]},{"title":"Python+OpenCV教程2：基本元素——图片","date":"2017-12-06T07:52:06.000Z","path":"2017/12/06/Python-OpenCV教程2：基本元素——图片/","text":"学习如何加载图片，显示并保存图片。图片等可到源码处下载。 目标 加载图片，显示图片，保存图片 OpenCV函数：cv2.imread(), cv2.imshow(), cv2.imwrite() 教程加载图片使用cv2.imread()来读入一张图片： 1234import cv2# 灰度图加载img = cv2.imread('lena.jpg', 0) 参数1是图片的文件名： 如果图片放在当前文件夹下，直接写文件名就行了，如’lena.jpg’ 否则，需要给出绝对路径，如’D:\\OpenCVSamples\\lena.jpg’ 参数2是图片的读入方式，省略即采用默认值： cv2.IMREAD_COLOR：忽略透明通道的彩色图，默认值(1) cv2.IMREAD_GRAYSCALE：灰度图加载(0) cv2.IMREAD_UNCHANGED：包含透明通道的彩色图(-1) 经验之谈：图片如果没有加载成功的话是不会报错的，而是img=None，后面处理才会报错，算是个小坑。 显示图片使用cv2.imshow()显示图片，窗口会自适应图片的大小： 12cv2.imshow('lena', img)cv2.waitKey(0) 结果应该如下： lena灰度图显示 参数1是窗口的名字，参数2是要显示的图片。 cv2.waitKey()是让程序暂停等待按键的函数。参数是等待时间（单位：毫秒ms），时间一到，会继续执行接下来的程序，传入0的话代表一直等待。按键可通过k = cv2.waitKey(0)获取（练习1）。 我们也可以先用cv2.namedWindow()创建一个窗口，之后再显示图片。参数1依旧是窗口的名字，参数2默认是cv2.WINDOW_AUTOSIZE，代表窗口大小自适应图片，也可以设置为cv2.WINDOW_NORMAL，来调整窗口大小： 1234# 先定义窗口，后显示图片cv2.namedWindow('lena2', cv2.WINDOW_NORMAL)cv2.imshow('lena2', img)cv2.waitKey(0) 保存图片使用cv2.imwrite()保存图片： 1cv2.imwrite('lena_gray.jpg', img) 小结cv2.imread()读入图片、cv2.imshow()显示图片、cv2.imwrite()保存图片 练习 打开lena.jpg并显示，显示时如果按下’s’，就保存图片为’lena_save.bmp’，否则就结束程序。 Matplotlib是Python中很重要的绘图库，请学习这篇内容：Matplotlib显示图像 引用本节源码 Getting Started with Images","tags":[{"name":"Code","slug":"Code","permalink":"https://ex2tron.github.io/tags/Code/"},{"name":"Python","slug":"Python","permalink":"https://ex2tron.github.io/tags/Python/"},{"name":"OpenCV","slug":"OpenCV","permalink":"https://ex2tron.github.io/tags/OpenCV/"},{"name":"图像处理","slug":"图像处理","permalink":"https://ex2tron.github.io/tags/图像处理/"}]},{"title":"Python+OpenCV教程1：简介","date":"2017-12-06T07:50:59.000Z","path":"2017/12/06/Python-OpenCV教程1：简介/","text":"Python+OpenCV搞图像处理与C/C++一样快！ 首先本教程绝对浅显易懂，非常easy的辣，大家尽可放心食用！其次，我相信大多数人的疑问在Python调用OpenCV进行图像处理的性能上面，所以这里我们主要说下这个。 其实，你英文Ok的话，推荐你看官方教程。我写的大部分也是照搬，但官方是按照OpenCV中的组件顺序讲的，大部分功能并不常用，所以我按照使用度和难易程度重写了一遍。 Python照样快众所周知，虽然Python语法简洁，编写高效，但相比C/C++慢很多。然而Python还有个重要的特性：它是一个胶水语言！Python可以很容易地扩展C/C++。 OpenCV-Python就是用Python包装了C++的实现，背后实际就是C++的代码在跑，所以，代码的运行速度跟原生C/C++速度一样快，而且更加容易编写。 另外，OpenCV-Python原生支持numpy，为矩阵操作、科学计算提供了极大的便利性。所以，扔掉你的C/C++，开始OpenCV-Python吧！！！ 安装本教程使用的软件版本是：OpenCV 3.x，Python 3.x。 如果你还没安装Python，我强烈推荐你安装Anaconda，它包含了大量的科学计算包，后期不用我们一个个安装。即使你已经装了Python也没有影响，Anaconda中自带Python，互不干扰。 Anaconda装好之后，打开cmd，输入：pip install opencv-python，等待安装完成即可。 如果识别不了pip，说明没有将pip的目录添加到环境变量。找到pip的安装目录，添加到用户变量（或系统变量）的path中。 如果下载速度很慢，可以点击此处下载离线版。下载完成后，cmd切换到下载的目录，输入pip install 文件名安装。 引用OpenCV-Python Tutorials Numpy Quickstart Tutorial OpenCV Docs","tags":[{"name":"Code","slug":"Code","permalink":"https://ex2tron.github.io/tags/Code/"},{"name":"Python","slug":"Python","permalink":"https://ex2tron.github.io/tags/Python/"},{"name":"OpenCV","slug":"OpenCV","permalink":"https://ex2tron.github.io/tags/OpenCV/"},{"name":"图像处理","slug":"图像处理","permalink":"https://ex2tron.github.io/tags/图像处理/"}]},{"title":"【片单】漫威宇宙电影合集","date":"2017-12-05T14:44:35.000Z","path":"2017/12/05/【片单】漫威宇宙电影合集/","text":"十年，17部电影，超过130亿美元的总票房，漫威宇宙电影合集下载！！！ Excelsior! ——斯坦·李 漫威电影宇宙MCU的成绩有目共睹，在十周年《复仇者联盟3》上映之前，来补一波漫威宇宙的电影吧（点击片名即可下载）！ MCU观影指南： 第一阶段： 2008《钢铁侠1》、 2008《无敌浩克》 2010《钢铁侠2》 2011《雷神1》 2011《美国队长1：复仇者先锋》 2012《复仇者联盟1》 第二阶段： 2013《钢铁侠3》 2013《雷神2：黑暗世界》 2014《美国队长2：冬日战士》 2014《银河护卫队1》 2015《复仇者联盟2：奥创纪元》 2015《蚁人》 第三阶段： 2016《美国队长3：内战》 2016《奇异博士》 2017《银河护卫队2》 2017《蜘蛛侠：英雄归来》 2017《雷神3：诸神黄昏》(上映中) 2018《复仇者联盟3：无限战争》(即将上映) 无限战争！！！","tags":[{"name":"Lens","slug":"Lens","permalink":"https://ex2tron.github.io/tags/Lens/"},{"name":"片单","slug":"片单","permalink":"https://ex2tron.github.io/tags/片单/"},{"name":"漫威","slug":"漫威","permalink":"https://ex2tron.github.io/tags/漫威/"},{"name":"Marvel","slug":"Marvel","permalink":"https://ex2tron.github.io/tags/Marvel/"},{"name":"复仇者联盟","slug":"复仇者联盟","permalink":"https://ex2tron.github.io/tags/复仇者联盟/"}]},{"title":"Brand7 2.0更名\"品牌漆\"正式上架咯！","date":"2017-11-26T11:04:32.000Z","path":"2017/11/26/Brand7-2-0更名品牌漆正式上架咯！/","text":"隔了一年更新，良心都有点痛了( ╯□╰ ) 示威的人做的不对的话，引起示威的人呢？ ——《辩护人》 当初Brand7写完的时候，一直想写一个关于电影的APP，甚至做出了雏形：MovieBackdrops，可惜，时间不多，事情却很多。前段时间闭关，摸着自己的良心，终于把Brand7更新了一把，来看看更新内容吧： 品牌漆（Brand7）是一款Win10 UWP猜品牌的小游戏，里面涵盖了汽车、娱乐、时尚、生活、餐饮、科技、旅游七个类别的550个品牌。Ver2.0.1更新日志如下： 更名“品牌漆” 全新Logo 全新启动界面 新增50个品牌，现共550个品牌 全面中文版（英文被很多人吐槽看不懂( ╯□╰ )） 界面UI调整 新旧版对比：中文版 完成界面 新的启动界面 分享界面 可以在Win10应用商店中搜索“品牌漆”进行下载，或点击此处。","tags":[{"name":"Code","slug":"Code","permalink":"https://ex2tron.github.io/tags/Code/"},{"name":"Brand7","slug":"Brand7","permalink":"https://ex2tron.github.io/tags/Brand7/"},{"name":"品牌漆","slug":"品牌漆","permalink":"https://ex2tron.github.io/tags/品牌漆/"}]},{"title":"软件+影视汁源贴(updating...)","date":"2017-11-15T11:53:46.000Z","path":"2017/11/15/软件-影视汁源贴-updating/","text":"经常有人跟我要一些软件和电影的资源，毕竟我是老司机( ╯□╰ )特此整理，有时间会不断更新。 I’ve always believed with hard work and a little bit of luck, it’s only a matter of time before I’m discovered! ——《Ratatouille》我总是相信勤奋与努力外加一点点幸运就能换来成功，我的天分被发现只是时间的问题。——《料理鼠王》 软件汁源首先列出一些常用网站，后面我只列出常用的软件和官网，请大家优先选择官网进行下载，因为官网版本一般都是最新的，也比较安全。官网进不去，可以点击我给出的版本下载： 常用资源站 Windows装机必备、网易开源镜像站 善用佳软、精品绿色便携软件 俺下载、逛电驴、ED2000资源共享 微软官方系统 Windows 10创意者更新秋季版：64位(4.42 GB)、32位(3.31 GB) Windows 7 With SP1 简体中文旗舰版：64位(3.19 GB)、32位(2.47 GB) 激活工具：优先OEM10，密码：c6wz Office办公套件 Office Pro Plus 2016批量授权版：64位、32位 Visio Pro 2016 批量授权版：64位、32位 Office Pro Plus 2016 即点即用版 Visio Pro 2016 即点即用版 激活工具：优先OEM10，密码：c6wz 开发工具 Visual Studio 2017 Community 15.4：官网 Android Studio：3.0、2.3.3 Qt 5.8.0 mingw：官网 Matlab：R2017a x64 dvd1、R2017a x64 dvd2、破解工具 Python相关： 官网、Python相关包（如tensorflow）：源1、源2 Anaconda：官网、5.0.1 Python 3.6 x86_x64、5.0.1 Python 3.6 x86 MySQL：官网、MySQL Installer 5.7.20 WampServer：官网、3.1.0 x64、3.1.0 x86 开发组件： 串口抓包工具AccessPort：官网、1.37 protobuf：官网(需翻墙) ffmpeg：官网 媒体 Adobe CC 2017：精简版 密码：f7yt 实用工具我平常整理的一些各类有用的工具：密码：806j 影视汁源资源站 6v电影网 字幕组（原人人影视） ED2000资源共享 电影天堂 飘花电影网 电影榜单 IMDB电影排行榜：TOP250 豆瓣电影排行榜：TOP250 全球电影票房排行榜：中文版、英文版 电影合集 诺兰电影合集 漫威电影合集","tags":[{"name":"Lens","slug":"Lens","permalink":"https://ex2tron.github.io/tags/Lens/"},{"name":"软件","slug":"软件","permalink":"https://ex2tron.github.io/tags/软件/"},{"name":"影视","slug":"影视","permalink":"https://ex2tron.github.io/tags/影视/"}]},{"title":"计量史：时间之旅","date":"2017-11-08T13:35:51.000Z","path":"2017/11/08/计量史：时间之旅/","text":"这篇文章也是我一年前研一《计量史》课上的小论文，感觉不错，也放在博客上，哈哈。 Whoever find a friend, find a treasure. ——《Cars2》一个朋友，一个宝。——《汽车总动员2》 宇宙大爆炸的那一刻就注定了这个世界充满着平凡与不平凡，宇宙的变迁、星云的诞生，看似杂乱无章但又井然有序，一切都注入了时间的长河中。而随着一个奇迹：生命的诞生，人类意识、情感的快速升华，人类开始认识到了“时间”，并随着时间的流逝，逐渐认识这个世界。通过自然界的周期现象——日出日落，季节的轮换，潮汐的涨落，来有意识地进行活动。于是，当我们尝试去考量时间的时候，就促使了时间计量产生。作为《时间之谜》的阅读报告，我摘录了一部分原书材料来表述时间计量的科学演变，最后结合自己的经历和见识表达了自己对科学研究和时间计量意义的一些想法。 时间，从来就不是一个很好形容或定义的概念。每当我们想去探讨它时，总会陷入困境，就像有人让你解释你是怎么走路的一样。《时间之谜》 从实用和客观的角度探讨了时间计量的科学演变。通过人们尝试对时间进行测定的手段、时间的使用以及时间对于数学、物理学、天文学的影响等各种客观事实材料，来启发我们对于时间的思考。 I. “时间”的科学演变如今，科学一词早已被大众所认知，并赋予崇高的含义。我想大多数人孩童时候的梦想就是成为一名科学家。而Science一词最早出现在19世纪，像牛顿当时被称为自然哲学家，而非科学家。可以看出，科学溯源于大自然规律的必然性。那么“时间”从哪儿来的呢？ 远古人民往往利用自然界的周期现象——日出日落，季节轮换，甚至潮汐的涨落来进行着人类的日常生活。我小时候在家乡的时候，就是鸡鸣时刻起床，黄昏时刻结束农耕作业。不同于现在城市的生活，那时的我们并不会过分关注具体的“钟表时间”。这种主导人们规律作息生活的自然之力，无疑引起了远古人们对它的神秘、畏惧和崇拜之感。于是，人们内心的欲望和探索心理驱动着我们去开始去关心天文和自然。 然而时间不同于长度、质量或温度，“我们能辨别距离，感受到重量和温度，但人体的任何感官都不能感知时间，我们见不到它，听不到它，嗅不到它，也尝不到它，而只能通过意识，或者通过观测它的效应来理解它。”（《时间之谜》）观测，这就是最开始单纯的“自然界的钟”的产生，也就是通过有意识地观测太阳、月亮和星星的这种大的、显式的运动，来确立时间的原型。之后人们认识到了运动的规律，产生了能否利用以恒定速率运转物体的时间间隔来对时间单位进行计数的问题，于是便有了“钟”。中国古代出现的利用水的推动力造的水钟、十四世纪出现的利用重锤驱动的机械钟以及惠更斯研制的摆钟等等都是探索过程中朝着精密性、易用性的改进。随着人们对自然界的深入了解，特别是对电、磁和物质的原子结构的了解，诸如石英钟、原子钟等一些新的方案得以发展和实现。 现在再去回顾历史，很容易就可以看出时间计量对工业、科学研究和当今世界诸多事务的影响。约翰•哈里逊时钟克服了海洋的颠簸、温度变化和咸水的溅射，大大改善了船只导航。对晶体谐振频率的研究有了如今改变世界的半导体。从“定性上的为什么”到“定量上的多准确”的科学演变，促使了精密测量的需求，进而影响到了数学、物理学、天文学……那么如今的我们需要再去思考“时间”吗？ II. 阿尔法到欧米伽（始与终）太过普世、默会的科学往往会被我们所忽略掉。拿起杯子喝口水，对于人来说，无疑再简单不过，但如果要造一个可以端起杯子喝水的机器人呢？显然，这是一个相对有难度并且复杂的任务，其中所涉及到的运动学、控制学、人体工程学等等科学知识都不是随便说说那么简单。因此，回溯历史能够使我们对那些在日常生活中扮演着最基本角色的事物产生认知，并进一步引领我们去思考。时间，它就扮演着使得人类的一切活动有秩序、有组织地进行着的角色。我想试图去了解时间，可以帮助我们更好的规划工作和生活。 虽然当今社会的物质财富已经相对丰富，但大多数人却丧失了求真求知，我们经常被当下的现实琐碎问题所困。这种局限使得人们疲于现实，而缺少创造和求知的勇气。假设我们可以做一次时间的旅行，“水母、鳄鱼胚胎、星云、犹他州的峡谷和木卫三；第一缕生命的信号、细菌、细胞起源、初恋感觉、意识诞生、人类进化、生与死。”（纪录片《时间之旅》）从宇宙大爆炸的那一刻开始到人类高级智慧的诞生，就注定了人类在漫漫时间长河中探索和认识这个世界的过程。在这个漫长的过程中，时间见证了无数人的探索求真精神，有始有终，从阿尔法到欧米伽，驱动着人类的进步。 我想时间就是一个很好的例子，来溯源支配当今社会行为准则的起源与内涵。正如同天平这种衡器的诞生以及后人对它的不断改进与完善，就是人们对公平与公正追求的一种体现。这种以此来扩充我们见识的过程，有助于锻炼我们的思维，突破一些困扰我们的现实问题，尝试新思路，并最终试图解决我们一直在思考的问题：自我存在。起码这种思维方法对我自己很有帮助：我是工作后考的研究生。考研期间，我没有用智能手机，由于一个人很难坚持下来，于是尝试每天早上7：15到7：45期间用静坐的方式来保持心态的平和。这种方法却意外之外了我的一笔人生财富，因为静坐的时候，我会尝试去想一些平静的事，慢慢地就会回忆起那些很久之前早就遗忘的事情。我想那个时候我就在进行着一趟回溯自己的时间之旅。每件事，好的，坏的都有始有终，总会过去，自己的心态也就变得好起来。静坐之后，洗漱完，8点准时出发，开始一天的学习生活……到现在读研期间，我依旧保持了考研时的一些习惯。 III. 结束语正如同泰伦斯•马力克执导的纪录片《时间之旅》所传达的哲学信息：“如果你在寻找上帝，仔细观察时间的一切就够了。”我想这就是时间对我们个体的意义。","tags":[{"name":"Lens","slug":"Lens","permalink":"https://ex2tron.github.io/tags/Lens/"},{"name":"计量","slug":"计量","permalink":"https://ex2tron.github.io/tags/计量/"},{"name":"时间之旅","slug":"时间之旅","permalink":"https://ex2tron.github.io/tags/时间之旅/"}]},{"title":"摄影之魅：瞬间是一面\"镜子\"","date":"2017-11-08T12:56:32.000Z","path":"2017/11/08/摄影之魅：瞬间是一面镜子/","text":"这篇文章其实是我一年前研一《摄影艺术》课上的小论文，感觉写的还行，放在博客上。 Not everyone can become a great artist, but a great artist can come from anywhere. ——《Ratatouille》并非是谁都能成为伟大的艺术家，不过伟大的艺术家却可能来自任何角落。——《料理鼠王》 19世纪30年代末期，达盖尔发明银版照相法，尼埃普斯拍摄了世界上第一张照片，影像开始可以被记录下来。卢米埃尔兄弟在《火车进站》中开启了24帧的艺术之旅——“电影”。如今，影像无处不在，传递着无穷无尽、千变万化的讯息。这一切都源于定格影像的瞬间——摄影术的独特魅力。 I. 艺术源于生活、艺术高于生活在选修“摄影艺术”这门课程之前，我刚刚入手了一款入门级单反：宾得PENTAX K-50。本着对摄影的爱好，在入手单反之前就经常用手机去拍一些小东西。所以，理所当然，选修这门课程就是希望自己能够拍出“好看”的照片，即追求表意上的拍摄技法。最初，刚接触摄影的我迫切想积累诸如快门、光圈、感光度、景深、构图等等各种专业术语。不可否认的是，这种“量”的层面上的堆积确实有助于提升拍摄认知和水平，但往往会也会束缚我们，缺少创造力、缺少对摄影“质”的理解。自己对摄影的认知也停留在肤浅的“这张照片拍的好，但说不出所以然来”上面。很高兴，这门课程改变了我的很多想法。 人是爱“美”的。如今，拍照是一件及其简单的事。一方面，得益于智能手机的发展，我们只需要按下手机上的拍照按钮，就会捕获一张照片，接近零成本。另一方面，由于拍摄的简便性，对生活中事物的记录变得极其频繁，这某种程度上降低了我们独立思考和赏析的能力。我们往往会赞美一张“好看”的照片，被照片所表现出来的第一观感所牵引，有些人虽然会对拍摄的技法做一些分析，获取经验，但却极少表达对照片的理解。并且，这些赞美和分析通常都只是建立在一张“美”的照片上。之所以强调了多次“美”的照片，是因为摄影不仅仅只是最终呈现出的照片的观感，摄影更多的含义是一个过程，这一过程的目的往往是真实地或艺术地反映出现实，并表现出拍摄者的情感寄托。当然，摄影术发明的目的就是代替画像，它源于生活，更是高于生活，因此，摄影是个庞杂的体系，前面的理解或许只是一种粗浅的认识。对于不同的摄影类别，诸如纪实摄影、风光摄影、商业时尚摄影等等，摄影都有不同的目的和表现方式，但摄影本身又是绝对的自由，它代表这一种艺术、创造力和想象力。 规则是用来打破的，但打破规则之前，我们必需清楚这个规则。得益于课堂之上邱老师介绍的各类摄影大师以及他们的作品，我了解了很多摄影的历史和大师级摄影师的风格。他们能够在摄影史上留下名字，通常都是某种风格的开创者，有着自己个性鲜明的摄影语言并对一个时代产生深远的影响。 II. 以小见大，“决定性瞬间”——布列松 “摄影这一门，你进去时是ABC，出来时是HCB（Henri Cartier-Bresson：亨利·卡蒂埃·布列松）”——《日本摄影》杂志。 图1 布列松本人及其作品 其实，对于一位被冠以“他的摄影定义了20世纪”、“新闻摄影之父”称号的大师级摄影师来说，无需多言。然而布列松提出的“决定性瞬间”的摄影艺术确确实实让我略微滤清了以往杂乱无章的“瞬间”摄影认知。在此之前，我一直很崇尚抓拍。可能是因为最初自己并不是特别了解一些摄影技法，在拍摄一些故事性很强的场景时，拍出的照片通常描述或还原不了那一时刻的故事。很多时候，摆拍的人物表情很不自然，一般也表现不出很强的故事性。“决定性瞬间”：“在一秒钟的很小一部分中，以一种精确的形式呈现出某一事件的重要性，使它成为这一事件的最恰当的描述。”布列松的作品总是恰到好处地抓住了事件最微妙的一瞬间。这或许与他自身的经历大大相关。 布列松曾前往法国的非洲殖民地科特迪瓦并以打猎为主。在打猎的过程中，他形成了贯穿他一生的摄影技巧——准备，等待，等待，等待…，最后扣动扳机（按下快门）。这一过程，造就了布列松面对巨大压力之下的沉着和冷静。他的作品就仿佛一直等在主体那里拍摄这一场景一般，这均得益于布列松的耐心、完美的拍摄时刻和一种无人可以匹敌的直觉。 图2 布列松作品:< 布列松习作>（左）、（右，前景中跳跃的男子与背后的跳跃女郎互相呼应） 《布列松习作》(上图)作为布列松的一幅名作，一方面以其娴熟的抓拍功底丰富而自然地表现出拍摄瞬间的故事性：小男孩情绪十分自然，踌躇满志的抱着两个大酒瓶回家，身后的小女孩也投来羡慕的目光…另一方面，这幅作品也很好的体现了布列松的摄影理念：“不论一幅作品技术多么到位，画面多么“好看”，如果它远离了爱，远离了对人类的理解，远离了对人类命运的认知，那么它一定不是一件成功的作品。”布列松的镜头虽然对准的是现实小场景，但他的立意高远，致力于以小见大，“最小的事物可以成为伟大的主题”。 III. 瞬间是一面“镜子” 图3 (上)、(下) 摄影大师的作品中往往呈现出非常鲜明的个性特征，赋予了其作品与众不同的表现力和故事性。摄影师在按下快门的那一刻，CCD/CMOS上接收的那些信号就变成了一张转瞬即逝一瞬间的记录。通常，摄影师抓拍的那一刻场景，很难再去复现，再加之摄影师独特的拍摄手法和艺术风格，使得每一张照片都变得独一无二，这也是瞬间反映的价值所在。因此，当我们去鉴赏这些作品、这些瞬间时，我们会被其表现出的感染力所吸引，《饥饿的苏丹》带给我们巨大的震撼，《时代广场的胜利》让我们体验到二战胜利的狂喜……。当然很多作品所表现出来的往往并不是“好看”的第一观感，它就如同一面可以窥视我们人类、社会、自然各种善恶丑美的镜子。直面这样的一面镜子，我们不免会产生强烈的情感冲击，因为这样的作品并不是单纯的、好看的、无意义的，而是承载着某些人文情怀和哲学思考。当我们深刻去理解它的时候，理所当然就会被其所揭示的内在所折服。 不过，摄影终归是自由的表现力、创造力的象征，这也是摄影术的魅力所在。我们需要不断学习和模仿经典作品的拍摄，但却不能有所束缚，当深刻地了解了这些规则后，就可以尝试打破这些规则，形成自己的风格！ “Not everyone can become a great artist, but a great artist can come from anywhere.”, “Everyone Can Cook！”（《料理鼠王》电影台词） “摄影艺术”这门课程改变了我很多的认识和想法，或许最大的感受便是：“Everyone Can Shoot！”每个人都有对其生活环境、人生观、世界观、价值观的独特理解，每个人也都可以拿起手中的设备拍出自己独特的风格。对大师作品的品鉴和艺术赏析都有助于提升自身的艺术品位，但关键在于去拍、去学习、去发现、去创造。我想这门课程给了我信心可以站在巨人的肩膀上努力拍出自己的作品，毕竟摄影是自由的，这才是摄影术之魅力！","tags":[{"name":"Lens","slug":"Lens","permalink":"https://ex2tron.github.io/tags/Lens/"},{"name":"摄影","slug":"摄影","permalink":"https://ex2tron.github.io/tags/摄影/"},{"name":"布列松","slug":"布列松","permalink":"https://ex2tron.github.io/tags/布列松/"}]},{"title":"小白深度学习笔记3：浅层神经网络","date":"2017-10-13T07:15:18.000Z","path":"2017/10/13/小白深度学习笔记3：浅层神经网络/","text":"logistic回归可以看作是只有1层1个神经元的神经网络，那么一般的神经网络是怎么样的呢？ 因为国民不富裕就不能受法律保护，就不能享受民主，这种说法我是无法接受的。 ——《辩护人》 本文是我在观看吴恩达老师的《神经网络和深度学习》视频课程时，相关的笔记整理，大佬勿喷！ 神经网络前面学习了logistic回归，可以把logistic看作只有1层1个神经元的神经网络，如下图： logistic_regression_singal_neural_network_sample 这个神经元做两个操作： 计算\\(z=w^Tx+b\\) 计算\\(\\hat{y}=a=\\sigma(z)\\) 而一般的神经网路包括输入层、隐藏层和输出层。如下图所示，是一个两层神经网络。层数从隐藏层(Hidden Layer)开始算，也就是这个图中，第1层是隐藏层，第2层是输出层(Output Layer)。可以把输入层(Input Layer)称为第0层。 two_layers_neural_network_samples 浅层神经网络是相较于深层神经网络而言的，深层神经网络中，隐藏层的个数&gt;=2，层数越多，也就越深。 激活函数如果把2层的神经网络看作是logistic回归的堆叠的话，那么这个神经网络的正向传播应该是下面这样的公式： $$z^{[1]}=W^{[1]}x+b^{[1]}\\tag{1}$$$$a^{[1]}=\\sigma(z^{[1]})\\tag{2}$$$$z^{[2]}=W^{[2]}x+b^{[2]}\\tag{3}$$$$a^{[2]}=\\sigma(z^{[2]})\\tag{4}$$ 其中，sigmoid函数就是激活函数(Activation Function)。激活函数不一定是sigmoid函数，有的非线性函数要比sigmoid函数更好，这里介绍两种：tanh和ReLU。 common_activation_functions tanhtanh(Hyperbolic Tangent Function)双曲正切函数，\\(a=tanh(z)=\\frac{e^z-e^{-z}}{e^z+e^{-z}}\\)。tanh往往比sigmoid表现更好，从上图中可以看出，这个激活函数的平均值更接近于0。但是输出层如果是二类分类的话，结果要么是0要么是1，那么我们预测值应该介于0~1之间，所以这种情况下，输出层的激活函数依然用sigmoid函数。 ReLU如果仔细观察sigmoid和tanh函数曲线的话，就会发现，自变量z比较大或比较小时，这个函数的斜率就会很小，接近于0，这样会拖慢梯度下降法的速度。所以，另外一个经常使用到的激活函数是ReLU(Rectified Linear Unit)。\\(a=max(0,z)\\)，z为正时，导数为1，z为负时，导数为0。 所以，总结三种激活函数， 一般不使用sigmoid做激活函数，除非是二类分类，可用在输出层 tanh普遍效果要比sigmoid更好 最常用的默认激活函数是ReLU 正向传播如果我们选择tanh作为激活函数的话，开头那个2层神经网络的正向传播就是： $$Z^{[1]}=W^{[1]}X+b^{[1]}\\tag{1}$$$$A^{[1]}=tanh(Z^{[1]})\\tag{2}$$$$Z^{[2]}=W^{[2]}X+b^{[2]}\\tag{3}$$$$A^{[2]}=tanh(Z^{[2]})\\tag{4}$$ 反向传播反向传播的推导跟logistic回归一样，只不过进行两次： $$dZ^{[2]}=A^{[2]}-Y\\tag{1}$$$$dW^{[2]}=\\frac{1}{m}dZ^{[2]}A^{[1]^T}\\tag{2}$$$$db^{[2]}=\\frac{1}{m}np.sum(dZ^{[2]},axis=1,keepdims=True)\\tag{3}$$$$dZ^{[1]}=W^{[2]^T}dZ^{[2]}*tanh^{’[1]}(Z^{[1]})\\tag{4}$$$$dW^{[1]}=\\frac{1}{m}dZ^{[1]}X^T\\tag{5}$$$$db^{[1]}=\\frac{1}{m}np.sum(dZ^{[1]},axis=1,keepdims=True)\\tag{6}$$ 随机初始化之前在logistic回归中，我们可以将权重W初始化为0，但是对于神经网络而言，W都初始化为0的话，是无效的。 no_zero_initialized_sample 举例来说，对于上图中的神经网络，隐藏层神经元个数是2，如果W全部初始化为0的话，那么： $$ W^{[1]}= \\begin{bmatrix} 0 &amp; 0 \\newline 0 &amp; 0 \\end{bmatrix}$$ 因为\\(z^{[1]}=W^{[1]}x+b\\)，这样的话\\(z_1^{[1]}=z_2^{[1]}\\)，\\(a_1^{[1]}=a_2^{[1]}\\)，也就是说，两个神经元的功能完全一样，计算相同的值，这样1个神经元和n个神经元对神经网络的作用是一样的，其他n-1个是多余的。 所以，在神经网络的参数初始化中，权重W是不能全部初始化为0的，b的话无所谓，都可以。","tags":[{"name":"Code","slug":"Code","permalink":"https://ex2tron.github.io/tags/Code/"},{"name":"神经网络","slug":"神经网络","permalink":"https://ex2tron.github.io/tags/神经网络/"},{"name":"深度学习","slug":"深度学习","permalink":"https://ex2tron.github.io/tags/深度学习/"}]},{"title":"numpy中几种矩阵的乘法","date":"2017-10-11T02:26:09.000Z","path":"2017/10/11/numpy中几种矩阵的乘法/","text":"最近在手动实现神经网络模型的时候，老是混淆numpy中几种矩阵乘法区别，所以特此记录一下。 With great power comes great responsibility ——《Spider-Man》能力越大，责任越大。——《蜘蛛侠》 首先，这里规定一下，我们用numpy定义矩阵时全部采用标准的形式，举例如下： 12345678import numpy as np# 不推荐的方式a = np.array([1,2,3])print(a.shape)# 推荐的方式b = np.array([[1,2,3]])print(b.shape) 上面代码a的形状是(3,)，b的形状(1,3)，即1行3列的一个矩阵。 np.dotnp.dot(A,B)就是实现同线性代数里面的矩阵乘法，也就是说，A的列数要等于B的行数才可以相乘： 12345import numpy as npa = np.array([[1,2,3],[4,5,6]])b = np.array([[1],[2],[3]])print(np.dot(a,b)) a是(2,3)，b是(3,1)，所以输出结果是：[[14], [32]]。 np.multiplynp.multiply(A,B)和A*B效果一样，实现对应位置元素相乘。 12345678910111213import numpy as np# 示例一a = np.array([[1,2,3]])b = np.array([[4,5,6]])print(a*b)print(np.multiply(a,b))# 示例二c = np.array([[1,2,3],[4,5,6]])d = np.array([[1],[2]])print(c*d)print(np.multiply(c,d)) 示例一输出结果是[[4 10 18]]，即[[1*4 2*5 3*6]]。示例二输出结果是[[1 2 3], [8 10 12]]，这里涉及到一个numpy中广播的概念：因为c是(2,3)，而d是(2,1)，为了实现对应元素相乘，numpy会把d的列复制扩展成(2,3)，于是就有了上面的结果。 np.innernp.inner(A,B) 实现A,B的内积，要求A,B矩阵最后一维是相同的，如果是2维矩阵，即A,B矩阵的列数要相同。 12345import numpy as npa = np.array([[1,2,3]])b = np.array([[4,5,6]])print(np.inner(a,b)) 结果为[[32]]，即1*4 + 2*10 + 3*6。 np.outernp.outer(A,B)即A,B的外积： 12345import numpy as npa = np.array([[1,2,3]])b = np.array([[4,5,6]])print(np.outer(a,b)) 结果为[[4 5 6], [8 10 12], [12 15 18]]，即[[1*4 1*5 1*6], [2*4 2*5 2*6], [3*4 3*5 3*6]]。","tags":[{"name":"Code","slug":"Code","permalink":"https://ex2tron.github.io/tags/Code/"},{"name":"Python","slug":"Python","permalink":"https://ex2tron.github.io/tags/Python/"},{"name":"numpy","slug":"numpy","permalink":"https://ex2tron.github.io/tags/numpy/"},{"name":"矩阵","slug":"矩阵","permalink":"https://ex2tron.github.io/tags/矩阵/"}]},{"title":"小白深度学习笔记2：Python实现logistic回归","date":"2017-10-09T01:52:11.000Z","path":"2017/10/09/小白深度学习笔记2：Python实现logistic回归/","text":"上一篇了解了一些logistic回归的原理，现在我们用Python实现一个用于鉴别是否是一张猫的图片的分类器！ 本文是我在观看吴恩达老师的《神经网络和深度学习》视频课程时，相关的笔记整理，大佬勿喷！ You’re not worried？ Would it help？ ——《Bridge of Spies》你不担心吗？有用吗？——《间谍之桥》 首先，回顾一下，logistic回归其实就相当于只有一层的最简单的神经网络，如下图，正向传播计算出预测值和成本函数，而反向传播计算出的dw和db： logistic_forward_backword_propagation p.s.本文其实是吴恩达老师第二周教程的作业，没答案，这里提供我写的，仅供参考！ 导入包首先import我们要使用的包，其中lr_utils和数据样本点此处下载： 1234567import numpy as npimport matplotlib.pyplot as pltimport h5pyimport scipyfrom PIL import Imagefrom scipy import ndimagefrom lr_utils import load_dataset 得到样本集我们的训练样本和测试样本都在前面下载的文件中： 12# 加载样本train_set_x_orig,train_set_y,test_set_x_orig,test_set_y,classes = load_dataset() 因为我们直接加载的样本集还需要进行处理，所以变量名上加了_orig。此时，train_set_x_orig中的每一个元素就是一副图片，可以用下面的方式让它显示出来： 1234# 显示第11张图片plt.figure()plt.imshow(train_set_x_orig[10])plt.show() 如果打印出train_set_x_orig的形状，结果为：(209,64,64,3)。可知训练样本的个数m_train=209，图片的宽和高都是num_px=64。 1print(train_set_x_orig.shape) 还记得上一篇中提到如果把图片量化吗？如果图片的维数是(num_px,num_px,3)，我们要变成(num_px*num_px*3,1)的形状。也就是说要把形状为(a,b,c,d)的矩阵变成形状数组为(b*c*d,a)的矩阵数组，这里可以用下面的一个小技巧： 1X_flatten = X.reshape(X.shape[0], -1).T 12train_set_x_flatten = train_set_x_orig.reshape(train_set_x_orig.shape[0],-1).Ttest_set_x_flatten = test_set_x_orig.reshape(test_set_x_orig.shape[0],-1).T 编写神经网络的代码中经常出现的错误便是把矩阵的维数搞错，所以随时可以通过shape属性进行检查，经过上面的语句后，train_set_x_flatten的形状应该是(12288,209)，test_set_x_flatten的形状应该是(12288,50)。 因为像素值最大是255，为了避免数据过大，可以将数据归一化得到最终的训练/测试集样本： 12train_set_x = train_set_x_flatten/255test_set_x = test_set_x_flatten/255 编写各个模块sigmoid函数这里注意python自带math模块中的exp函数和numpy中的exp函数的区别，math.exp是没有广播功能的，不适合此处的矩阵运算。123def sigmoid(x): s = 1/(1+np.exp(-x)) return s 测试：1print(sigmoid(np.array([0,2]))) 结果应为[0.5 0.88079708] 初始化w和b因为logistic回归相当于只有一个输出层的神经网络，根据上一篇的分析，w的形状是(nx,1)，b的形状是(1,1)，这里我们统一初始化为0：1234def initialize_with_zeros(dim): w = np.zeros([dim,1]) b = 0. return w, b 正/反向传播这里的函数就是本文开头那张图上显示的正向传播和反向传播：1234567891011121314def propagate(w, b, X, Y): m = X.shape[1] # 正向传播 A = sigmoid(np.dot(w.T,X)+b) # 成本函数 cost = -np.sum(Y*np.log(A)+(1-Y)*np.log(1-A),axis=1)/m cost = np.squeeze(cost) # 反向传播 dw = np.dot(X,(A-Y).T)/m db = np.sum(A-Y,axis=1)/m grads = &#123;\"dw\":dw,\"db\":db&#125; return cost,grads 测试：123w,b,X,Y = np.array([[1],[2]]),2,np.array([[1,2],[3,4]]),np.array([[1,0]])cost,grads = propagate(w,b,X,Y)print(cost,grads) 结果应为：6.000064773192205 {&#39;dw&#39;: array([[0.99993216], [ 1.99980262]]), &#39;db&#39;: array([0.49993523])} 优化器反向传播完，我们需要更新w，b的值，即应用梯度下降法进行优化： 12345678910111213141516171819def optimize(w,b,X,Y,num_iterations,learning_rate,print_cost=False): costs = [] for i in range(num_iterations): cost,grads = propagate(w,b,X,Y) dw = grads['dw'] db = grads['db'] # 更新w和b的值 w = w-learning_rate*dw b = b-learning_rate*db # 每隔100次，记录下成本函数的值 if(i%100 == 0): costs.append(cost) if(print_cost): print(\"cost after iteration %i:%f\"%(i,cost)) params=&#123;'w':w,'b':b&#125; grads=&#123;'dw':dw,'db':db&#125; return params,grads,costs 测试：12params, grads, costs = optimize(w, b, X, Y, num_iterations= 100, learning_rate = 0.009, print_cost = False)print(params,grads,costs) 结果应为{&#39;w&#39;: array([[0.1124579 ],[0.23106775]]), &#39;b&#39;: array([ 1.55930492])} {&#39;dw&#39;: array([[ 0.90158428],[1.76250842]]), &#39;db&#39;: array([ 0.43046207])} [array(6.000064773192205)] 预测函数通过优化器得到w和b参数之后，就可以用这两个参数预测X了，如果预测值&gt;=0.5，那结果就为1，即是一张有猫的图片，反之，结果为0，是一张没有猫的图片： 123456789def predict(w,b,X): m = X.shape[1] Y_predictions = np.zeros([1,m]) A = sigmoid(np.dot(w.T,X)+b) for i in range(A.shape[1]): Y_predictions[0,i] = 1 if A[0,i]&gt;=0.5 else 0 return Y_predictions 分类模型这样我们就编写好了所有的模块了，最后，把它们整合在一起，就是logistic回归的二类分类模型了：12345678910111213141516171819202122def model(X_train,Y_train,X_test,Y_test,num_iterations=2000,learning_rate=0.5,print_cost=False): w,b = initialize_with_zeros(X_train.shape[0]) params,grads,costs = optimize(w,b,X_train,Y_train,num_iterations,learning_rate,print_cost) w = params['w'] b = params['b'] Y_prediction_test = predict(w,b,X_test) Y_prediction_train = predict(w,b,X_train) print(\"train accuracy:&#123;&#125; %\".format(100-np.mean(np.abs(Y_prediction_train-Y_train))*100)) print(\"test accuracy:&#123;&#125; %\".format(100-np.mean(np.abs(Y_prediction_test-Y_test))*100)) d = &#123;\"costs\": costs, \"Y_prediction_test\": Y_prediction_test, \"Y_prediction_train\" : Y_prediction_train, \"w\" : w, \"b\" : b, \"learning_rate\" : learning_rate, \"num_iterations\": num_iterations&#125; return d 现在，可以把我们真正的样本数据传入这个模型，看它最后训练的结果：1d = model(train_set_x, train_set_y, test_set_x, test_set_y, num_iterations = 2000, learning_rate = 0.005, print_cost = True) 如果一切正常，会打印出最后模型在训练集和测试集上的准确率：12train accuracy:99.04306220095694 %test accuracy:70.0 % 验证和分析结果可以看到当前的训练结果其实是过拟合的，测试集上的准确率并不高，但暂时足够了。我们可以显示和打印出真实的图片结果进行对比。比如说这里我们打开测试集上的第5张图片，并将学习率曲线画出来：123456789index = 4plt.imshow(test_set_x[:,index].reshape([num_px,num_px,3]))print(\"real result = \"+str(test_set_y[0,index])+\" and your predict = \"+str(d['Y_prediction_test'][0,index]))plt.figure()plt.plot(np.squeeze(d['costs']))plt.ylabel('cost')plt.xlabel('iterations(per hundreds)')plt.title(\"learning rate = \"+str(d['learning_rate']))plt.show() 最后，源代码中包含了一段针对不同的学习率得到不同的训练结果的代码，大家可以参考下噢！~ o(￣▽￣)o 本文源代码：python_implement_logistic_regression.py","tags":[{"name":"Code","slug":"Code","permalink":"https://ex2tron.github.io/tags/Code/"},{"name":"神经网络","slug":"神经网络","permalink":"https://ex2tron.github.io/tags/神经网络/"},{"name":"深度学习","slug":"深度学习","permalink":"https://ex2tron.github.io/tags/深度学习/"},{"name":"logistic回归","slug":"logistic回归","permalink":"https://ex2tron.github.io/tags/logistic回归/"}]},{"title":"【利器篇】GitKraken——顶级酷炫Git图像化客户端","date":"2017-10-05T09:33:20.000Z","path":"2017/10/05/【利器篇】GitKraken——顶级酷炫Git图像化工具/","text":"不喜欢敲命令？那么这款酷炫的Git客户端让你逼格满满！ 真正的忘记是不需要努力的。——《大鱼海棠》 首先废话一段：以前我上班的时候，公司里的SCM用的是perforce，你应该、可能没听过( ╯□╰ )。总之，就是集中式版本管理系统，相比于git的分布式有很多缺陷，具体可以看廖雪峰的这篇文章：“集中式vs分布式”。但作为一款商业软件，perforce提供的优秀客户端体验还是相当不错的。使用git后，一直都是敲命令的，一是因为习惯，毕竟码代码逼格高嘛，二是因为git的GUI客户端要不很丑，要不功能捉急，总之不想用。之后，在微博上看到这款软件，又同类似的SourceTree相比体验了一下，无奈，我，还是喜欢颜值高的~ o(￣▽￣)o另外，以前外教老师提问说《加勒比海盗2》中的那个怪物叫啥，阅片无数的我，那天竟然没回答上，装逼失败，所以对这只“挪威海怪kraken”影响特别深刻。好了，开始正题吧，扯远了~ 官网/下载：GitKraken GitKraken对Windows/Linux/Mac三大主流平台都支持，其方便之处在于，它不需要安装配置，双击打开就可以了。打开之后，可以选择用Github账号登陆，需要Github授权： gitkraken_sign_in_with_github 打开/克隆/初始化GitKranken支持打开本地仓库，从指定的URL或Github、Gitlab、Bitbucket等上面直接克隆。前面我们已经用Github直接登陆了，所以，从Github克隆时，会直接列出你当前的所有仓库项目，非常方便。当然，也可以连接到Gitlab/Bitbucket平台： gitkraken_clone_from_github 初始化/新建项目也非常方便，在Init选项中，可以选择初始化一个本地仓库或类似Github之类的远程仓库。GitKraken初始化时还提供了.gitignore的文件的相关模板： gitkraken_init_github_repo 界面/功能打开一个仓库后，主界面如下图，酷炫简洁，顶部提供了常用的Git功能，就不细说了。我主要提及一下，如何进行版本差分： gitkraken_main_ui 在提交日志的主界面，如果要比较任意两个版本之间的差分，按住Ctrl键，选择要比较的版本，右边会自动列出两个版本之间所修改的文件，点击文件就可以看到diff了： gitkraken_view_commits_diff gitkraken_view_file_diff 当然，最新版本（本文使用的是3.1版本）的GitKraken提供了Merge和Diff工具的自定义（File-Preferences-General中设置），比如说我最常用的Merge工具是WinMerge，就可以在这里配置。 抛砖引玉，大致介绍了一下，其实熟悉Git的话，这个工具使用起来还是蛮简单的~ o(￣▽￣)o","tags":[{"name":"Code","slug":"Code","permalink":"https://ex2tron.github.io/tags/Code/"},{"name":"利器篇","slug":"利器篇","permalink":"https://ex2tron.github.io/tags/利器篇/"},{"name":"Git","slug":"Git","permalink":"https://ex2tron.github.io/tags/Git/"},{"name":"GitKraken","slug":"GitKraken","permalink":"https://ex2tron.github.io/tags/GitKraken/"}]},{"title":"小白深度学习笔记1：logistic回归","date":"2017-10-02T13:06:32.000Z","path":"2017/10/02/小白深度学习笔记1：logistic回归/","text":"开启神经网络与深度学习之坑！本篇内容包含部分数学公式，需要用MathJax脚本渲染，所以页面需等待加载完成后，才可完整显示公式。 When life ends up breathtakingly fucked, you can generally trace it back to one big, bad decision.——《DeadPool》当你的生活变成一坨屎的时候，通常都是因为你当时做的傻逼决定。——《死侍》 本文是我在观看吴恩达老师的《神经网络和深度学习》视频课程时，相关的笔记整理，大佬勿喷！ 二类分类比如说分析一张图片中有猫还是没猫，这就是一个二类分类（Binary Classification）问题。这里，我们用输出y=1表示有猫，y=0表示没有猫。输入是一张图片，做过图像处理的同学应该知道图片是以RGB三个矩阵存储的，把RGB三分量的值提取出来，作为X，如下图： rgb_convert_input_x 那么当有m个样本时，X就是一个(nx,m)，即nx行、m列的矩阵，而输出Y的形状（形状就是指矩阵的行数和列数）是(1,m)。 logistic回归logistic回归（Logistic Regression）就是一个用于二类分类的学习算法：假定给出输入的特征向量\\(x_1\\)（如一张图片），我们希望程序给出一个预测值\\(\\hat{y}\\)，它指出这张图片中有猫还是没猫的概率，即：$$\\hat{y}=P(y=1\\ or\\ 0\\mid x)$$ 既然\\(\\hat{y}\\)是一个概率，那么\\(\\hat{y}\\in[0,1]\\)。如果按照线性回归，输出值应该是：\\(\\hat{y}=w^Tx+b\\)，w形状是(nx,1)，b形状是(1,1)，但是这个值可能远比1大或者出现负数，所以，需要用一个sigmoid函数做限定，最终输出为：$$\\hat{y}=\\sigma(w^Tx+b)$$ 观察sigmoid函数\\(\\sigma(z)=\\frac{1}{1+e^{-z}}\\)的曲线图： \\(z\\rightarrow\\infty,\\sigma(z)\\rightarrow1;z\\rightarrow-\\infty,\\sigma(z)\\rightarrow0;z=0,\\sigma(z)=0.5\\) sigmoid_function_graph 损失函数既然我们的目标就是训练得到logistic回归函数中的w和b参数，那么怎么衡量算法的运行情况呢？我们可以用损失函数（Loss Function）L表示预测值与真值的接近程度。最简单的损失函数可以定义成\\(L(\\hat{y},y)=\\hat{y}-y\\)。但是不会这样用，因为要考虑到优化算法的运算速度和效率，排除多个局部最优解。一般，损失函数定义为：$$L(\\hat{y},y)=-[y\\log\\hat{y}+(1-y)\\log(1-\\hat{y})]$$ 显然，损失函数越小，结果越好。那么这个损失函数如何起作用的呢？ 假设真值y=1，那么上式就会变成：\\(L(\\hat{y},1)=-\\log\\hat{y}\\)，要让损失函数尽量小，那么\\(\\log\\hat{y}\\)尽量大，也就是说\\(\\hat{y}\\)尽量大，由于\\(\\hat{y}\\in[0,1]\\)，所以，这个损失函数会使预测值\\(\\hat{y}\\)尽量接近1，即真值。同样，大家可以推一下真值y=0的情况。 成本函数前面所说的损失函数是针对单个训练样本定义的，我们可以用成本函数（Cost Function）来定义全体训练样本上的算法运行情况，定义如下：$$J(w,b)=\\frac{1}{m}\\sum_{i=1}^mL(\\hat{y^i},y^i)$$ 梯度下降法好，到这里，先总结一下： logistic回归模型是用于二类分类的一种学习算法 损失函数衡量参数w和b在单个训练样本的效果 成本函数衡量参数w和b在全体训练样本的效果 训练目标：找到使成本函数J尽可能小的参数w和b 那么w和b参数是怎么调整的呢？为了说明梯度下降法（Gradient Descent），吴恩达老师假定w和b都是实数，那么J(w,b)的函数图形类似下图： cost_function_graph 一般，先随机初始化w和b，然后朝着最快下降的方向不断按下面的公式调整w和b参数，最后得到最优解（:=表示更新w的值）： $$w:=w-\\alpha\\frac{dJ(w,b)}{dw}$$$$b:=b-\\alpha\\frac{dJ(w,b)}{db}$$ \\(\\alpha\\)成为学习率（Learning Rate），表示梯度下降法的步长。 好了，这就是相关的logistic回归的简单理论笔记。","tags":[{"name":"Code","slug":"Code","permalink":"https://ex2tron.github.io/tags/Code/"},{"name":"神经网络","slug":"神经网络","permalink":"https://ex2tron.github.io/tags/神经网络/"},{"name":"深度学习","slug":"深度学习","permalink":"https://ex2tron.github.io/tags/深度学习/"},{"name":"logistic回归","slug":"logistic回归","permalink":"https://ex2tron.github.io/tags/logistic回归/"}]},{"title":"【算法贴】三点定位算法","date":"2017-09-29T10:58:31.000Z","path":"2017/09/29/【算法贴】三点定位算法/","text":"已知三个点的坐标和未知点到这三个点的距离，求未知点？ 过去的如果就这么过去了，以后只会越来越糟。——《驴得水》 p.s.本文引用了mathjax脚本用来显示数学公式，所以需等待加载完成才能显示正常。 算法解析如下图所示，以三个已知点为圆心，d1,d2,d3为半径作圆，交点便是要求解的未知点： trilateration_sample 刚开始百度了一下，各种稀奇的算法，包括将三角形平移、旋转啥的，其实不用这么麻烦，直接通过勾股定理死算就可以了。 $$(x_1-x_0)^2+(y_1-y_0)^2=d_1^2$$ $$(x_2-x_0)^2+(y_2-y_0)^2=d_2^2$$ $$(x_3-x_0)^2+(y_3-y_0)^2=d_3^2$$ 将上面三个式子展开： $$x_1^2+x_0^2-2x_0x_1+y_1^2+y_0^2-2y_0y_1=d_1^2 ①$$$$x_2^2+x_0^2-2x_0x_2+y_2^2+y_0^2-2y_0y_2=d_2^2 ②$$$$x_3^2+x_0^2-2x_0x_3+y_3^2+y_0^2-2y_0y_3=d_3^2 ③$$ 显然通过三个式子中的任意两个相减，比如①-③和②-③就可以得到两个未知数的两个式子： $$x_1^2-x_3^2-2x_0(x_1-x_3)+y_1^2-y_3^2-2y_0(y_1-y_3)=d_1^2-d_3^2$$$$x_2^2-x_3^2-2x_0(x_2-x_3)+y_2^2-y_3^2-2y_0(y_2-y_3)=d_2^2-d_3^2$$ 接下来就不用说了，其实这都是初中数学的问题( ╯□╰ ) 算法实现CSharp根据上面的推导，我们的算法就很好写了。先定义一个Point的结构体或类，然后编写一个函数，将已知的三个点和三个距离传入： 12345678910111213141516171819202122232425262728293031/// &lt;summary&gt;/// 定义Point结构体/// &lt;/summary&gt;public struct Point&#123; public double X; public double Y;&#125;static Point GetMobilePoint(Point p1, Point p2, Point p3, double d1, double d2, double d3)&#123; //相当于①式-③式 double A = p1.X - p3.X; double B = p1.Y - p3.Y; double C = Math.Pow(p1.X, 2) - Math.Pow(p3.X, 2) + Math.Pow(p1.Y, 2) - Math.Pow(p3.Y, 2) + Math.Pow(d3, 2) - Math.Pow(d1, 2); //相当于②式-③式 double D = p2.X - p3.X; double E = p2.Y - p3.Y; double F = Math.Pow(p2.X, 2) - Math.Pow(p3.X, 2) + Math.Pow(p2.Y, 2) - Math.Pow(p3.Y, 2) + Math.Pow(d3, 2) - Math.Pow(d2, 2); //计算结果 double x0 = (B * F - E * C) / (2 * B * D - 2 * A * E); double y0 = (A * F - D * C) / (2 * A * E - 2 * B * D); Point resultPoint; resultPoint.X = x0; resultPoint.Y = y0; return resultPoint;&#125;","tags":[{"name":"Code","slug":"Code","permalink":"https://ex2tron.github.io/tags/Code/"},{"name":"三角定位","slug":"三角定位","permalink":"https://ex2tron.github.io/tags/三角定位/"},{"name":"算法贴","slug":"算法贴","permalink":"https://ex2tron.github.io/tags/算法贴/"}]},{"title":"构建法、杀死变量","date":"2017-09-28T13:23:45.000Z","path":"2017/09/28/构建法、杀死变量/","text":"如果你仔细回想一下，平日阅读代码的时候，是什么占用了你大量的时间和精力？毫无疑问：变量。 Why do we fall, Bruce? So we can learn to pick ourselves up. ——《Batman Begins》我们为何会跌倒？这样我们才可以学会自己爬起来。——《蝙蝠侠：侠影之谜》 如果一个变量在代码中很分散，阅读者在同一时间内考虑的代码行数势必会增加，编写者引入Bug的概率也会增大。那么，该如何从减少变量的作用域角度提高代码质量呢？ p.s.本文相关内容仍旧是我阅读《代码大全》时的笔记与总结，大佬勿喷！ 变量跨度与存活时间建议一：把对变量的引用尽可能集中在一起，使变量局部化12345a = 0; b = 0;c = 0;a = b + c;b += 1; 跨度（span）是衡量变量不同引用点靠近程度的一种方法。比如说上面的代码，对a的第一次引用和第二次引用之间有2行代码，那么变量a的跨度就是2。引用多次的话，可以取平均跨度。如b的第一次和第二次引用之间行数为1，第二次和第三次引用之间行数为0，所以平均跨度span(b)=(1+0)/2=0.5。 另外一个概念是：存活时间（live time）。跟跨度类似，不过存活时间只跟变量第一次和最后一次引用有关。比如对于上面代码中的b变量，跨度是0.5，但是存活时间是4条语句。 显然，我们的目标就是缩短变量的跨度和存活时间。如果用这两个概念考察全局变量，就会发现全局变量的跨度和存活时间都很长，这也是为什么避免使用全局变量的原因之一。 减小作用域的建议建议二：把相关语句放在一起把变量的引用点集中在一起，使代码易于自上而下的阅读，举例来说： 12345678910111213141516//跳来跳去的糟糕代码MarketingData marketingData;SalesData salesData;TravelData travelData;travelData.ComputeWeekly();salesData.ComputeWeekly();marketingData.ComputeWeekly();salesData.ComputeAnnually();travelData.ComputeAnnually();marketingData.ComputeAnnually();salesData.print();travelData.print();marketingData.print(); 显然，如果你要想知道marketingData的计算流程，就必须在这段代码的不同行数跳跃。所以，这样组织代码会更好： 123456789101112131415//组织良好，从上而下阅读MarketingData marketingData;marketingData.ComputeWeekly();marketingData.ComputeAnnually();marketingData.print();SalesData salesData;salesData.ComputeWeekly();salesData.ComputeAnnually();salesData.print();TravelData travelData;travelData.ComputeWeekly();travelData.ComputeAnnually();travelData.print(); 《代码大全》中介绍了一种简便的检查相关语句是否组成得当的方法，把你的代码片段打印出来，然后把相关的语句画上框，组织得当的话， 这些框是不会重叠的： good_grouping_related_statements 建议三：把相关语句提取成单独的子程序更短的子程序相比长的子程序，变量的跨度和存活时间更小。比如，可以尝试这样重构上面的代码： 123456//重构，提取子程序ComputeMarketingData();ComputeSalesData();ComputeTravelData(); 建议四：开始使用最小的作用域，然后根据需求再扩展一句话解释就是：把全局变量转换为成员局部变量要比局部变量转换为全局变量难的多。因此，在设计程序时，如果对变量的作用域犹豫不决时，优先倾向于最小的作用域。 建议五：循环开始之前再去初始化循环变量一个不好的编程习惯就是在程序开头初始化好循环所使用的变量，如int i = 0,j = 0;。而在很后面才使用到循环。这样做的坏处一是查看循环时需要跳到开头才知道循环变量的值，另外，如果要修改这个循环，往往会忘记同时修改循环变量。 往期【构建法】系列回顾： 构建法、单点控制 构建法、表驱动法","tags":[{"name":"Code","slug":"Code","permalink":"https://ex2tron.github.io/tags/Code/"},{"name":"构建法","slug":"构建法","permalink":"https://ex2tron.github.io/tags/构建法/"},{"name":"变量","slug":"变量","permalink":"https://ex2tron.github.io/tags/变量/"},{"name":"作用域","slug":"作用域","permalink":"https://ex2tron.github.io/tags/作用域/"}]},{"title":"【片单】诺兰神作集","date":"2017-09-24T12:37:41.000Z","path":"2017/09/24/【片单】诺兰神作集/","text":"有的导演，虽然没拿过奥斯卡，作品不多，但每部却都被影迷奉为神作。没错，说的就是诺神：克里斯托弗·诺兰 克里斯托弗·诺兰今天周末，回顾了下诺神的蝙蝠侠和盗梦空间，加上前段时间刚看完敦刻尔克，按耐不住，就分享下诺兰的神作电影下载链接吧。 作品按时间排序，点击片名或者右键复制链接即可： 敦刻尔克 | Dunkirk Dunkirk 星际穿越 | Interstellar Interstellar 蝙蝠侠：黑暗骑士崛起 | The Dark Knight Rises The Dark Knight Rises 盗梦空间 | Inception Inception 蝙蝠侠：黑暗骑士 | The Dark Knight The Dark Knight 致命魔术 | The Prestige The Prestige 蝙蝠侠.侠影之谜 | Batman Begins Batman Begins 记忆碎片 | Memento Memento p.s.本文所有的图片均来自TMDB，如果你觉得很酷炫的话，我会在后期开发一款专门下载影视壁纸的APP，敬请期待！","tags":[{"name":"Lens","slug":"Lens","permalink":"https://ex2tron.github.io/tags/Lens/"},{"name":"片单","slug":"片单","permalink":"https://ex2tron.github.io/tags/片单/"},{"name":"诺兰","slug":"诺兰","permalink":"https://ex2tron.github.io/tags/诺兰/"},{"name":"蝙蝠侠","slug":"蝙蝠侠","permalink":"https://ex2tron.github.io/tags/蝙蝠侠/"},{"name":"敦刻尔克","slug":"敦刻尔克","permalink":"https://ex2tron.github.io/tags/敦刻尔克/"},{"name":"盗梦空间","slug":"盗梦空间","permalink":"https://ex2tron.github.io/tags/盗梦空间/"},{"name":"星际穿越","slug":"星际穿越","permalink":"https://ex2tron.github.io/tags/星际穿越/"}]},{"title":"【利器篇】七牛云——用做每月免费10G的图床","date":"2017-09-18T11:55:38.000Z","path":"2017/09/18/【利器篇】七牛云——用做每月免费10G的图床/","text":"随着越来越多的人开始使用Markdown写自己的独立博客，一个好用稳定的图床是必不可少的了。 对比在七牛云之前，我使用过国外的Cloud App和阿里云的oss对象存储。 首先，国外的东西在国内稳定性和速度都是相对较差的，我试着在阿里云和Cloud App上上传同一张图片并生成外链，Cloud App要比阿里的加载速度延迟1-2s，阿里基本秒开。 阿里的oss对象存储虽然很稳定，但是并不提供免费的空间。相对来说，七牛云提供的每月10G免费流量，对于博客来说，绰绰有余了。 另外，七牛云提供了诸多的图片处理接口，如水印、格式转换、缩放等，很实用，很强大。 使用注册并登陆七牛云，在七牛云的产品列表中，添加一个对象存储，如这里取名为picblog： create_new_bucket 创建好之后，七牛云会自动生成一个测试域名： test_domain_name 这个域名就是你文件的前缀了。比如，我们点击内容管理，点击上传文件，选择一幅图片上传。上传完成后，复制该文件的外链地址： copy_file_link 这个地址就是你的图片地址辣，你可以在浏览器中访问该地址，比如你可以访问我的这个：mysql_demo 绑定域名添加二级域名如同前面那张图上所说，七牛云默认的测试域名有很多限制。所以，你如果已经购买了域名的话，可以在这里绑定自己的二级域名，这样既好记又方便管理。 比如，这里我已经在万网上购买了ex2tron.xin的域名，这里我演示如何将七牛云的存储空间绑定pic.ex2tron.xin这个域名。 在七牛云的存储空间页面，点击绑定域名，只需要在加速域名处填写要绑定的域名，其他项保持默认即可：1加速域名： pic.ex2tron.xin bucket_binding_domain_name 创建后，系统会配置一段时间，等待处理完成，会显示一个诸如xxx.qiniudns.com的CNAME记录值，记下此值，后面要用到。 cname_for_binding 添加域名解析打开万网的域名控制台，添加一条CNAME的解析：1234记录类型：CNAME主机记录：pic记录值：xxx.qiniudns.com# 其他选型保持默认 add_dns_for_qiniu 这样，你上传的图片外链就是：http://pic.ex2tron.xin/filename.png之类的了。 添加图片样式利用七牛云做图床的另外一个强大之处在于丰富的图片样式。点击图片样式-新建图片样式，七牛云提供了如下很多种场景： api_for_image_process 比如，这里我们选择指定宽高，强行缩放+打图片水印，然后添加一个文字水印，可以调整文字的字体样式，位置等等： add_water_mark_api 调整好之后，为样式取个名称，如webpic，这样，只要在原来外链的后面添加-webpic就可以了： 1http://pic.ex2tron.xin/filename.png-webpic 其中-这个连接符可以通过存储空间控制面板的样式分隔符设置中进行修改。 图床工具对于七牛云，每张图片都在网页端上传还是比较麻烦的，所以用一些图床客户端工具会更加快速。 这里推荐使用MPic图床神器。打开软件后，设置好自己的AK和SK（可在七牛云的个人中心-密钥管理中看到）。MPic支持文件拖拽上传，点击复制就可以复制外链，非常方便： mpic_qiniu","tags":[{"name":"Code","slug":"Code","permalink":"https://ex2tron.github.io/tags/Code/"},{"name":"利器篇","slug":"利器篇","permalink":"https://ex2tron.github.io/tags/利器篇/"},{"name":"qiniu","slug":"qiniu","permalink":"https://ex2tron.github.io/tags/qiniu/"},{"name":"七牛云","slug":"七牛云","permalink":"https://ex2tron.github.io/tags/七牛云/"},{"name":"图床","slug":"图床","permalink":"https://ex2tron.github.io/tags/图床/"}]},{"title":"Hexo+Github Pages轻松搭博客(2)——在Github上部署","date":"2017-09-13T12:15:47.000Z","path":"2017/09/13/Hexo-Github-Pages轻松搭博客-2-——在Github上部署/","text":"使用免费的Github Pages服务或者部署在自己服务器上，别人就可以访问你的博客啦！ 如果你已经有配置好的云服务器，直接可以将Hexo博客生成的public目录文件放在服务器上就好了。比如我购买的是阿里云服务器（apache），只需要将public下的文件放在/var/www/html/下面就可以用你服务器地址访问博客了。很容易，不过，考虑到云服务器的价格，这里我们还是用免费的Github吧。 关联Github首先登陆Github，没有账号的话，先注册一个。新建一个名为username.github.io的仓库，username必须与你的账户名相同，比如我的就是ex2tron.github.io，这就是你博客的域名地址了（绑定独立域名之后再说）。新建时注意勾选”Initialize this repository with a README“，因为这个仓库必须不能为空。 如果你是git新用户的话，推荐看：廖雪峰的Git教程-远程仓库 create_github_pages_repository 接下来打开博客目录下的_config.yml配置文件，定位到最后的deploy选项，修改如下：1234deploy: type: git repository: git@github.com:ex2tron/ex2tron.github.io.git branch: master 注意冒号后面有个空格，不然会出错滴~~~配置好之后，使用下面的命令就可以部署到Github上了：123$ hexo clean$ hexo g$ hexo d 这样通过Github提供的域名地址（如我的：https://ex2tron.github.io）就可以访问你的博客了，简单快速高效！ 发布新博客博客搭建起来之后，就可以用Markdown写博客辣，使用下面的命令，创建新博客（如名为：我的第一篇博客）：1$ hexo new '我的第一篇博客' 此命令会在博客目录\\source_posts\\h下生成“我的第一篇博客.md”文件，这就是你的博客源文件啦，文件开头如下，记得冒号后面有空格噢，不然会出错：12345---title: 我的第一篇博客date: 2017-09-13 20:15:47tags: #文章标签，格式：[1,2,3]--- 不熟悉Markdown语法的可以看：Markdown 语法说明。写完之后依然使用之前的三条命令发布：123$ hexo clean$ hexo g$ hexo d 后面两条指令也可以简化为一条：1$ hexo g -d 常出现的问题 在hexo d进行部署时，如果出现ERROR Deployer not found: git的问题，可以先用下面的命令修复： 1$ npm install hexo-deployer-git --save 如果你没配置过ssh导致部署失败（可以通过ssh -T username@example.com来测试ssh有无配置成功），可以参考这篇文章：针对github权限导致hexo部署失败的解决方案","tags":[{"name":"Code","slug":"Code","permalink":"https://ex2tron.github.io/tags/Code/"},{"name":"Hexo","slug":"Hexo","permalink":"https://ex2tron.github.io/tags/Hexo/"},{"name":"Github","slug":"Github","permalink":"https://ex2tron.github.io/tags/Github/"}]},{"title":"Hexo+Github Pages轻松搭博客(1)","date":"2017-09-13T08:07:06.000Z","path":"2017/09/13/Hexo-Github-Pages轻松搭博客-1/","text":"想用Github Pages轻松搭建自己的博客，用Hexo，10分钟！ 废话区域：我在接触Hexo（可以读作Hack So）之前，绝对没少尝试建立一个完全自由、自己说了算的独立博客：WordPress定位重量级，功能强大，生成的是动态网站，依赖数据库……太繁琐了，放弃~而Jekyll和Hexo都是静态建站工具，但Jekyll的依赖项也很多，也不简约，不想用~最后才是名气相对不高的Hexo，相信我，熟练的情况下，10分钟就可以搭出来： 简介Hexo是一个免费的静态Blog生成工具。简单来说，就是把你写的Markdown博客文件生成静态网页，把这个网页放在Github或者你自己的服务器上就可以快速访问了。软件界，从来不缺自动化工具(ง •_•)ง 安装官网文档：Hexo Docs Hexo安装前，你的电脑上需要先有下面这两个东西： Node.js Git 如果已经安装了的话，命令行下一句话就好啦：1$ npm install -g hexo-cli 初始化博客目录在你的本地新建一个存放博客的目录，比如”D:\\MyHexoBlog“，然后在这个目录右键，选择”Git Bash Here“，输入下面两条命令进行初始化：12$ hexo init$ npm install 初始化完成之后，你的目录结构应该是这样的：12345678.├── _config.yml├── package.json├── scaffolds├── source| ├── _drafts| └── _posts└── themes 如果没有出错的话，继续执行下面的指令启动服务：12$ hexo g $ hexo s 启动之后，在浏览器中访问：http://localhost:4000/，是不是看到了漂亮的Hexo博客页面了。不过目前这个博客还是运行在你本机上的，下篇我们看一下怎么样让别人也能访问这个博客。 default_hexo_index 参考资料： Hexo Docs Hexo+Github搭建个人博客(一)——开始搭建","tags":[{"name":"Code","slug":"Code","permalink":"https://ex2tron.github.io/tags/Code/"},{"name":"Hexo","slug":"Hexo","permalink":"https://ex2tron.github.io/tags/Hexo/"},{"name":"Github","slug":"Github","permalink":"https://ex2tron.github.io/tags/Github/"}]},{"title":"【利器篇】用VS Code写Markdown","date":"2017-09-11T07:11:22.000Z","path":"2017/09/11/【利器篇】用VSCode写Markdown/","text":"Markdown以其简洁、优雅整齐的风格，成为目前非常流行的博客文件格式。甚至有人说：每个人都应该用Markdown写博客。关于Markdown相较富文本的优势，我就不细说了。 Markdown编辑器支持Markdown的工具有很多，大家可以参考网上，如这篇文章：码字必备：18 款优秀的 Markdown 写作工具 | 2015 年度盘点。就我自己目前在Windows上使用的而言有：简书、有道云笔记、Typora、VSCode 简书本身就是一个博客平台，有道云笔记是类似OneNote和印象笔迹的应用。如果你已经在使用这两个平台的话，就不用多说了。但如果只是想用一个单纯的Markdown编辑器的话，推荐极致简洁的Typora。虽说界面简洁，但功能强大，不仅内置了常见的一些Markdown样式，还支持PDF/HTML等多种格式导出： markdown_in_typora 你是一枚文青的话，千万不要错过这款编辑器。不过，对于程序猿来说，VSCode才显得更有味道。 用VSCode写MarkdownVSCode就不过多介绍了，我之前也写过关于它的介绍： Visual Studio Code Preview初体验 Visual Studio Code Preview深度体验、使用技巧 现在版本的VSCode默认已经支持Markdown预览，不需要下载插件。用VSCode打开md文件或将当前文件更改为Markdown格式就可以开始书写了： markdown_in_vscode VSCode支持两种预览方式： 按下Ctrl+K V，像上图一样左右同步实时预览 按下Ctrl+Shift+V，只预览最终渲染结果 editor_preview_Synchronization 如上图，编写和预览界面是实时同步的，不需要的话，可以按下Ctrl+,组合键，添加如下两条设置： 12\"markdown.preview.scrollEditorWithPreview\": false,\"markdown.preview.scrollPreviewWithEditorSelection\": false 另外，目前VSCode预览样式中，中文的显示很别扭，这里推荐下载Github风格的CSS 下载完成后，配置css文件的设置如下即可： 123\"markdown.styles\": [ \"file:///D:/markdown-github.css\"] 另外，VSCode中有很多Markdown相关的插件，如”Markdown All in One”和”Markdown Theme Kit”等，大家可以下载下来尝试一下哈！ 参考资料：Markdown editing with Visual Studio Code","tags":[{"name":"Code","slug":"Code","permalink":"https://ex2tron.github.io/tags/Code/"},{"name":"利器篇","slug":"利器篇","permalink":"https://ex2tron.github.io/tags/利器篇/"},{"name":"Markdown","slug":"Markdown","permalink":"https://ex2tron.github.io/tags/Markdown/"},{"name":"VSCode","slug":"VSCode","permalink":"https://ex2tron.github.io/tags/VSCode/"}]},{"title":"【利器篇】MyCLI——自动补全和语法高亮的MySQL命令行工具","date":"2017-09-11T06:32:14.000Z","path":"2017/09/11/【利器篇】MyCLI——自动补全和语法高亮的MySQL命令行工具/","text":"mycli是MySQL命令行工具，支持关键字语法高亮和自动补全，看下面的动图你就知道了： mycli_demo mycli不仅会提示MySQL的关键字，更牛掰的是数据库名、表名、字段名都可以提示，非常方便。如果你经常在命令行里码MySQL命令，相信这款工具一定会让你满意。 官网：MyCLI 安装其实mycli是一个Python的包，所以你已经安装了Python(pip)的话，用下面一条指令就好了： 1&gt; pip install mycli 如果出现问题，可以参考官网，有详细的说明。 install_mycli 使用安装好之后，在cmd下，将以往登陆MySQL用的mysql换成mycli就可以了： login_with_mycli 好了，大家觉得好用的话，欢迎扩散噢！ Never give up. Never stop fighting. Excelsior!","tags":[{"name":"Code","slug":"Code","permalink":"https://ex2tron.github.io/tags/Code/"},{"name":"利器篇","slug":"利器篇","permalink":"https://ex2tron.github.io/tags/利器篇/"},{"name":"MyCLI","slug":"MyCLI","permalink":"https://ex2tron.github.io/tags/MyCLI/"},{"name":"MySQL","slug":"MySQL","permalink":"https://ex2tron.github.io/tags/MySQL/"}]},{"title":"博客新篇章！Brave New World","date":"2017-08-23T12:56:32.000Z","path":"2017/08/23/博客新篇章！/","text":"从2014/08/23在lofter上写我的第一篇博客开始，已经过去了整整三年…… 再见，lofterlofter是一个非常不错的轻博客平台，我喜欢它的设计和定位。但lofter终究不适合程序猿，长久以来不支持markdown也让我很头痛。现在，终于还是要说再见了! http://ex2tron.lofter.com 旧的66篇博客【Code/编程/开发】构建法、单点控制 构建法、表驱动法 【云端漫步】一起上“阿里云”（1）、购买学生党套餐 【云端漫步】一起上“阿里云”（2）、远程登陆服务器 【云端漫步】一起上“阿里云”（3）、LAMP环境搭建 【云端漫步】一起上“阿里云”（4）、搭建Git服务器 【云端漫步】一起上“阿里云”（5）、域名购买和解析 Python多字节二进制文件读取 C#中集合List的深浅拷贝 C#中常用的集合List去重方法 C#多字节二进制文件读取 深入理解C#（01）：堆栈、值类型和引用类型、值传递和引用传递 宽字符 编程命名法 编程字体推荐 Json序列化与反序列化（1）-JavaScriptSerializer Json序列化与反序列化（2）-Json.Net Json序列化与反序列化（3）-DataContractJsonSerializer CR与LF（操作系统“下一行”的不同） Visual Studio Code Preview初体验 Visual Studio Code Preview深度体验、使用技巧 Brand7-品牌漆上架商店啦！ UWP应用Brand7开发小记（1）、判断App是否是第一次启动 UWP应用Brand7开发小记（2）、用Excel和Json初始化本地数据源Part1 UWP应用Brand7开发小记（2）、用Excel和Json初始化本地数据源Part2 UWP 应用Brand7开发小记（3）、判断GridView的滚动方向 UWP应用Brand7开发小记（4）、集合控件的虚拟化问题 UWP 应用Brand7开发小记（5）、控件嵌入标题栏 MySQL学习小记（1）-不能启动MySQL服务 MySQL学习小记（2）-添加远程访问权限详解 MySQL学习小记（3）-外键的使用 MySQL学习小记（4）-最大连接数 MySQL学习小记（5）-主从服务器同步 VS至强插件ReSharper指南01、安装入门 【视觉与图像】【视觉与图像】摄像头篇（1）、CCD靶面尺寸 【视觉与图像】摄像头篇（2）、焦距和视角 CMake编译OpenCV3.2（Qt平台） Qt+OpenCV环境搭建 【Design/演示/设计】玩转PPT放映第一篇、演示者视图 玩转PPT放映第二篇、快捷键 玩转PPT放映第三篇、自定义放映 【PPT动画】钟摆效果 【PPT动画】模糊渐变切换效果 【PPT动画】制作左、右浮入效果 PPT制作画中画效果 PPT绘制长阴影图标 PPT三维立体图形绘制 PPT巧用矩形等分区域（黄金分割线） 【Lens/摄影/影视】家乡 | 黑白 | PENTAX K-50 | 看见不一样 看见，时光（延时摄影短片） 我那时的“计量”（一），黑白质感 我那时的“计量”（二），迎新色彩 Lumia 1520 by iPhone6s 历届奥斯卡最佳动画长片下载（1） 历届奥斯卡最佳动画长片下载（2） 「精品」皮克斯15部动画长片下载 【Other/科普/发现】PPI与DPI USB接口类型（2.0概述） Type-C和USB3.0（3.1） 发现Win10 Bug两枚（均得微软官方确认，一枚已解决） 再战之后，这场旅途，只属于我 Win8以上系统安装PL2303驱动 硬盘容量计算的差别 硬盘整数分区原理及计算（附工具下载） 详解Windows运行组件第一篇、原理篇 详解Windows运行组件第二篇、自定义运行指令 Windows 10技术预览版体验视频 Never give up. Never stop fighting. Excelsior!","tags":[]}]